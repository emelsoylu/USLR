{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyNHqzzBCCD/H0FlCFNOcmvD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"1Lr0hEv3NnmK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torch torchvision matplotlib seaborn scikit-learn tqdm pandas numpy"],"metadata":{"id":"1E6vwdaINx9O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#1- transformer\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import os\n","import logging\n","import random\n","from collections import Counter\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Logging setup\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","# Reproducibility\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","class SimpleDiverSignDataset(Dataset):\n","    \"\"\"Simple and effective dataset class\"\"\"\n","    def __init__(self, sequences, labels, label_encoder=None, scaler=None):\n","        # Label encoding\n","        if label_encoder is None:\n","            self.label_encoder = LabelEncoder()\n","            encoded_labels = self.label_encoder.fit_transform(labels)\n","        else:\n","            self.label_encoder = label_encoder\n","            encoded_labels = self.label_encoder.transform(labels)\n","\n","        # Data scaling - StandardScaler is more stable\n","        if scaler is None:\n","            self.scaler = StandardScaler()\n","            # Reshape for scaling\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.fit_transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","        else:\n","            self.scaler = scaler\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","\n","        self.sequences = torch.FloatTensor(scaled_sequences)\n","        self.labels = torch.LongTensor(encoded_labels)\n","\n","        # Calculate class weights\n","        class_counts = Counter(encoded_labels)\n","        total_samples = len(encoded_labels)\n","        self.class_weights = torch.FloatTensor([\n","            total_samples / (len(class_counts) * class_counts[i])\n","            for i in range(len(class_counts))\n","        ])\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        return self.sequences[idx], self.labels[idx]\n","\n","    def get_label_encoder(self):\n","        return self.label_encoder\n","\n","    def get_scaler(self):\n","        return self.scaler\n","\n","    def get_class_weights(self):\n","        return self.class_weights\n","\n","class FocalLoss(nn.Module):\n","    \"\"\"Focal Loss for imbalanced classes\"\"\"\n","    def __init__(self, alpha=1, gamma=2, reduce=True):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.reduce = reduce\n","\n","    def forward(self, inputs, targets):\n","        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n","\n","        if self.reduce:\n","            return torch.mean(focal_loss)\n","        return focal_loss\n","\n","class OptimizedDiverSignTransformer(nn.Module):\n","    \"\"\"Optimized Transformer model\"\"\"\n","    def __init__(self,\n","                 input_dim=69,\n","                 d_model=256,           # Medium model size\n","                 n_heads=8,             # Standard number of heads\n","                 n_layers=6,            # Optimal depth\n","                 num_classes=10,\n","                 max_seq_length=150,\n","                 dropout=0.1):\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.d_model = d_model\n","        self.num_classes = num_classes\n","\n","        # Input projection\n","        self.input_projection = nn.Sequential(\n","            nn.Linear(input_dim, d_model),\n","            nn.LayerNorm(d_model),\n","            nn.ReLU(),\n","            nn.Dropout(dropout)\n","        )\n","\n","        # Learnable positional encoding\n","        self.pos_embedding = nn.Parameter(torch.randn(1, max_seq_length, d_model) * 0.02)\n","\n","        # Transformer encoder\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=n_heads,\n","            dim_feedforward=d_model * 4,\n","            dropout=dropout,\n","            activation='gelu',\n","            batch_first=True,\n","            norm_first=True\n","        )\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, n_layers)\n","\n","        # Global average pooling\n","        self.global_pool = nn.AdaptiveAvgPool1d(1)\n","\n","        # Classification head\n","        self.classifier = nn.Sequential(\n","            nn.LayerNorm(d_model),\n","            nn.Linear(d_model, d_model // 2),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(d_model // 2, d_model // 4),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(d_model // 4, num_classes)\n","        )\n","\n","        # Weight initialization\n","        self._init_weights()\n","\n","    def _init_weights(self):\n","        \"\"\"Xavier initialization\"\"\"\n","        for module in self.modules():\n","            if isinstance(module, nn.Linear):\n","                nn.init.xavier_uniform_(module.weight)\n","                if module.bias is not None:\n","                    nn.init.zeros_(module.bias)\n","            elif isinstance(module, nn.LayerNorm):\n","                nn.init.ones_(module.weight)\n","                nn.init.zeros_(module.bias)\n","\n","    def forward(self, x, mask=None):\n","        batch_size, seq_len, _ = x.shape\n","\n","        # Input projection\n","        x = self.input_projection(x)\n","\n","        # Add positional encoding\n","        x = x + self.pos_embedding[:, :seq_len, :]\n","\n","        # Transformer encoding\n","        encoded = self.transformer_encoder(x, src_key_padding_mask=mask)\n","\n","        # Global pooling\n","        encoded = encoded.transpose(1, 2)  # [batch, d_model, seq_len]\n","        pooled = self.global_pool(encoded).squeeze(-1)  # [batch, d_model]\n","\n","        # Classification\n","        output = self.classifier(pooled)\n","\n","        return output\n","\n","class SmartTrainer:\n","    \"\"\"Smart training class\"\"\"\n","    def __init__(self, model, class_weights=None, device='cuda' if torch.cuda.is_available() else 'cpu'):\n","        self.model = model\n","        self.device = device\n","        self.model.to(device)\n","\n","        # Loss function with class weights\n","        if class_weights is not None:\n","            class_weights = class_weights.to(device)\n","\n","        self.criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n","\n","        # Optimizer\n","        self.optimizer = optim.AdamW(\n","            model.parameters(),\n","            lr=1e-3,  # Initial learning rate\n","            weight_decay=0.01,\n","            betas=(0.9, 0.999)\n","        )\n","\n","        # Scheduler\n","        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","            self.optimizer, mode='max', factor=0.5, patience=10, verbose=True\n","        )\n","\n","        # Metrics tracking\n","        self.train_losses = []\n","        self.val_losses = []\n","        self.train_accuracies = []\n","        self.val_accuracies = []\n","        self.val_f1_scores = []\n","\n","    def train_epoch(self, dataloader):\n","        \"\"\"Single epoch training\"\"\"\n","        self.model.train()\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","\n","        for batch_idx, (data, target) in enumerate(tqdm(dataloader, desc=\"Training\")):\n","            data, target = data.to(self.device), target.to(self.device)\n","\n","            # Zero gradients\n","            self.optimizer.zero_grad()\n","\n","            # Forward pass\n","            output = self.model(data)\n","            loss = self.criterion(output, target)\n","\n","            # Backward pass\n","            loss.backward()\n","\n","            # Gradient clipping\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n","\n","            # Optimizer step\n","            self.optimizer.step()\n","\n","            # Statistics\n","            total_loss += loss.item()\n","            _, predicted = output.max(1)\n","            total += target.size(0)\n","            correct += predicted.eq(target).sum().item()\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_targets.extend(target.cpu().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","\n","        return avg_loss, accuracy, f1\n","\n","    def validate(self, dataloader):\n","        \"\"\"Validation\"\"\"\n","        self.model.eval()\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","\n","        with torch.no_grad():\n","            for data, target in tqdm(dataloader, desc=\"Validating\"):\n","                data, target = data.to(self.device), target.to(self.device)\n","\n","                output = self.model(data)\n","                loss = self.criterion(output, target)\n","\n","                total_loss += loss.item()\n","                _, predicted = output.max(1)\n","                total += target.size(0)\n","                correct += predicted.eq(target).sum().item()\n","\n","                all_preds.extend(predicted.cpu().numpy())\n","                all_targets.extend(target.cpu().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","\n","        return avg_loss, accuracy, f1, all_preds, all_targets\n","\n","    def train(self, train_loader, val_loader, epochs=100, save_path=\"best_model.pth\"):\n","        \"\"\"Complete training loop\"\"\"\n","        best_val_f1 = 0\n","        patience = 20\n","        patience_counter = 0\n","\n","        logger.info(f\"Training started: {epochs} epochs, device: {self.device}\")\n","\n","        for epoch in range(epochs):\n","            # Train\n","            train_loss, train_acc, train_f1 = self.train_epoch(train_loader)\n","\n","            # Validate\n","            val_loss, val_acc, val_f1, _, _ = self.validate(val_loader)\n","\n","            # Scheduler step\n","            self.scheduler.step(val_f1)\n","\n","            # Save metrics\n","            self.train_losses.append(train_loss)\n","            self.val_losses.append(val_loss)\n","            self.train_accuracies.append(train_acc)\n","            self.val_accuracies.append(val_acc)\n","            self.val_f1_scores.append(val_f1)\n","\n","            # Logging\n","            if (epoch + 1) % 5 == 0:\n","                logger.info(f'Epoch {epoch+1}/{epochs}:')\n","                logger.info(f'Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%, F1: {train_f1:.4f}')\n","                logger.info(f'Val - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, F1: {val_f1:.4f}')\n","                logger.info(f'LR: {self.optimizer.param_groups[0][\"lr\"]:.6f}')\n","\n","            # Save best model\n","            if val_f1 > best_val_f1:\n","                best_val_f1 = val_f1\n","                torch.save({\n","                    'epoch': epoch,\n","                    'model_state_dict': self.model.state_dict(),\n","                    'optimizer_state_dict': self.optimizer.state_dict(),\n","                    'best_val_f1': best_val_f1,\n","                    'train_losses': self.train_losses,\n","                    'val_losses': self.val_losses,\n","                    'train_accuracies': self.train_accuracies,\n","                    'val_accuracies': self.val_accuracies,\n","                    'val_f1_scores': self.val_f1_scores\n","                }, save_path)\n","                logger.info(f\"✅ New best model saved: F1 {val_f1:.4f}\")\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","\n","            # Early stopping\n","            if patience_counter >= patience:\n","                logger.info(f\"Early stopping at epoch {epoch+1}\")\n","                break\n","\n","        logger.info(f\"🎯 Training completed. Best F1 Score: {best_val_f1:.4f}\")\n","        return best_val_f1\n","\n","def smart_prepare_data(csv_path, sequence_length=150, overlap_ratio=0.3):\n","    \"\"\"Smart data preparation\"\"\"\n","    logger.info(f\"📊 Loading CSV data: {csv_path}\")\n","\n","    df = pd.read_csv(csv_path)\n","    logger.info(f\"Total rows: {len(df):,}\")\n","    logger.info(f\"Classes: {list(df['class'].unique())}\")\n","    logger.info(f\"Class distribution:\\n{df['class'].value_counts()}\")\n","\n","    # Feature columns\n","    feature_columns = [col for col in df.columns if col != 'class']\n","    logger.info(f\"Number of features: {len(feature_columns)}\")\n","\n","    # Data quality check\n","    logger.info(\"🔍 Checking data quality...\")\n","\n","    # Check for NaN and infinite values\n","    nan_count = df[feature_columns].isnull().sum().sum()\n","    inf_count = np.isinf(df[feature_columns].values).sum()\n","\n","    if nan_count > 0:\n","        logger.warning(f\"⚠️ Found {nan_count} NaN values, applying forward fill...\")\n","        df[feature_columns] = df[feature_columns].fillna(method='ffill').fillna(0)\n","\n","    if inf_count > 0:\n","        logger.warning(f\"⚠️ Found {inf_count} infinite values, applying clipping...\")\n","        df[feature_columns] = df[feature_columns].replace([np.inf, -np.inf], np.nan).fillna(0)\n","\n","    # Minimum samples per class check\n","    min_samples_per_class = sequence_length * 3  # Minimum 3 sequences per class\n","    class_counts = df['class'].value_counts()\n","    valid_classes = class_counts[class_counts >= min_samples_per_class].index\n","\n","    if len(valid_classes) < len(class_counts):\n","        dropped_classes = set(class_counts.index) - set(valid_classes)\n","        logger.warning(f\"⚠️ Dropping classes with insufficient data: {list(dropped_classes)}\")\n","        df = df[df['class'].isin(valid_classes)]\n","\n","    logger.info(f\"✅ Classes to process: {list(valid_classes)}\")\n","\n","    sequences = []\n","    labels = []\n","\n","    # Overlapping sliding window\n","    stride = int(sequence_length * (1 - overlap_ratio))\n","\n","    for class_name in valid_classes:\n","        class_data = df[df['class'] == class_name].reset_index(drop=True)\n","        class_sequences = 0\n","\n","        for i in range(0, len(class_data) - sequence_length + 1, stride):\n","            sequence = class_data.iloc[i:i+sequence_length][feature_columns].values\n","\n","            if len(sequence) == sequence_length:\n","                # Check sequence quality\n","                if not np.any(np.isnan(sequence)) and not np.any(np.isinf(sequence)):\n","                    sequences.append(sequence)\n","                    labels.append(class_name)\n","                    class_sequences += 1\n","\n","        logger.info(f\"  {class_name}: {class_sequences} sequences\")\n","\n","    sequences = np.array(sequences)\n","\n","    logger.info(f\"📈 Total sequences: {len(sequences):,}\")\n","    logger.info(f\"📐 Sequence shape: {sequences.shape}\")\n","    logger.info(f\"🎯 Final class distribution: {dict(Counter(labels))}\")\n","\n","    return sequences, labels, len(feature_columns)\n","\n","def plot_results(trainer, save_path=\"training_results.png\"):\n","    \"\"\"Visualize results\"\"\"\n","    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n","\n","    epochs = range(1, len(trainer.train_losses) + 1)\n","\n","    # Loss plot\n","    ax1.plot(epochs, trainer.train_losses, 'b-', label='Train Loss', alpha=0.8)\n","    ax1.plot(epochs, trainer.val_losses, 'r-', label='Validation Loss', alpha=0.8)\n","    ax1.set_title('Training and Validation Loss')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.legend()\n","    ax1.grid(True, alpha=0.3)\n","\n","    # Accuracy plot\n","    ax2.plot(epochs, trainer.train_accuracies, 'b-', label='Train Accuracy', alpha=0.8)\n","    ax2.plot(epochs, trainer.val_accuracies, 'r-', label='Validation Accuracy', alpha=0.8)\n","    ax2.set_title('Training and Validation Accuracy')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel('Accuracy (%)')\n","    ax2.legend()\n","    ax2.grid(True, alpha=0.3)\n","\n","    # F1 Score plot\n","    ax3.plot(epochs, trainer.val_f1_scores, 'g-', label='Validation F1', alpha=0.8, linewidth=2)\n","    ax3.set_title('Validation F1 Score')\n","    ax3.set_xlabel('Epoch')\n","    ax3.set_ylabel('F1 Score')\n","    ax3.legend()\n","    ax3.grid(True, alpha=0.3)\n","\n","    # Learning rate plot\n","    if hasattr(trainer.scheduler, 'get_last_lr'):\n","        lrs = [group['lr'] for group in trainer.optimizer.param_groups for _ in epochs][:len(epochs)]\n","        ax4.semilogy(epochs, lrs, 'purple', label='Learning Rate', alpha=0.8)\n","        ax4.set_title('Learning Rate Schedule')\n","        ax4.set_xlabel('Epoch')\n","        ax4.set_ylabel('Learning Rate (log scale)')\n","        ax4.legend()\n","        ax4.grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n","    plt.show()\n","\n","def plot_confusion_matrices(val_targets, val_preds, test_targets, test_preds, target_names):\n","    \"\"\"Plot confusion matrices for both validation and test sets\"\"\"\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n","\n","    # Validation Confusion Matrix\n","    cm_val = confusion_matrix(val_targets, val_preds)\n","    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=target_names, yticklabels=target_names, ax=ax1)\n","    ax1.set_title('Validation Confusion Matrix', fontsize=16, fontweight='bold')\n","    ax1.set_ylabel('True Label', fontsize=12)\n","    ax1.set_xlabel('Predicted Label', fontsize=12)\n","    ax1.tick_params(axis='x', rotation=45)\n","\n","    # Test Confusion Matrix\n","    cm_test = confusion_matrix(test_targets, test_preds)\n","    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens',\n","                xticklabels=target_names, yticklabels=target_names, ax=ax2)\n","    ax2.set_title('Test Confusion Matrix', fontsize=16, fontweight='bold')\n","    ax2.set_ylabel('True Label', fontsize=12)\n","    ax2.set_xlabel('Predicted Label', fontsize=12)\n","    ax2.tick_params(axis='x', rotation=45)\n","\n","    plt.tight_layout()\n","    plt.savefig('validation_test_confusion_matrices.png', dpi=150, bbox_inches='tight')\n","    plt.show()\n","\n","def main():\n","    set_seed(42)\n","\n","    # IMPROVED Hyperparameters\n","    CSV_PATH = \"\"  # Update your CSV file path here\n","    SEQUENCE_LENGTH = 150\n","    BATCH_SIZE = 12          # Smaller batch size for stable gradients\n","    EPOCHS = 150             # 🔥 Increased epochs (80 -> 150)\n","    VAL_SIZE = 0.15          # 15% validation\n","    TEST_SIZE = 0.15         # 15% test (70% remaining for train)\n","    OVERLAP_RATIO = 0.5      # 🔥 More overlap (0.3 -> 0.5)\n","\n","    logger.info(\"🚀 IMPROVED Diver Sign Language Transformer Training!\")\n","    logger.info(f\"📊 Data split: 70% Train, 15% Validation, 15% Test\")\n","\n","    # Data preparation - more data augmentation\n","    sequences, labels, feature_count = smart_prepare_data(\n","        CSV_PATH, sequence_length=SEQUENCE_LENGTH, overlap_ratio=OVERLAP_RATIO\n","    )\n","\n","    if len(sequences) == 0:\n","        logger.error(\"❌ No valid sequences found!\")\n","        return\n","\n","    # First split: train+val (85%) and test (15%)\n","    X_temp, X_test, y_temp, y_test = train_test_split(\n","        sequences, labels,\n","        test_size=TEST_SIZE,\n","        random_state=42,\n","        stratify=labels\n","    )\n","\n","    # Second split: train (70%) and val (15%) from the remaining 85%\n","    val_size_adjusted = VAL_SIZE / (1 - TEST_SIZE)  # 0.15 / 0.85 ≈ 0.176\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_temp, y_temp,\n","        test_size=val_size_adjusted,\n","        random_state=42,\n","        stratify=y_temp\n","    )\n","\n","    logger.info(f\"🔄 Train sequences: {len(X_train):,} ({len(X_train)/len(sequences)*100:.1f}%)\")\n","    logger.info(f\"🔄 Validation sequences: {len(X_val):,} ({len(X_val)/len(sequences)*100:.1f}%)\")\n","    logger.info(f\"🔄 Test sequences: {len(X_test):,} ({len(X_test)/len(sequences)*100:.1f}%)\")\n","\n","    # Create datasets\n","    train_dataset = SimpleDiverSignDataset(X_train, y_train)\n","    val_dataset = SimpleDiverSignDataset(\n","        X_val, y_val,\n","        train_dataset.get_label_encoder(),\n","        train_dataset.get_scaler()\n","    )\n","    test_dataset = SimpleDiverSignDataset(\n","        X_test, y_test,\n","        train_dataset.get_label_encoder(),\n","        train_dataset.get_scaler()\n","    )\n","\n","    # DataLoaders\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n","    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n","\n","    # IMPROVED Model - larger architecture\n","    num_classes = len(train_dataset.get_label_encoder().classes_)\n","    model = OptimizedDiverSignTransformer(\n","        input_dim=feature_count,\n","        d_model=384,             # 🔥 Increased! (256 -> 384)\n","        n_heads=12,              # 🔥 More heads! (8 -> 12)\n","        n_layers=8,              # 🔥 Deeper! (6 -> 8)\n","        num_classes=num_classes,\n","        max_seq_length=SEQUENCE_LENGTH,\n","        dropout=0.15             # Slightly increased dropout (prevent overfitting)\n","    )\n","\n","    logger.info(f\"🤖 IMPROVED Model created:\")\n","    logger.info(f\"   - Number of classes: {num_classes}\")\n","    logger.info(f\"   - Input dimension: {feature_count}\")\n","    logger.info(f\"   - Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n","\n","    # IMPROVED Trainer\n","    trainer = SmartTrainer(model, train_dataset.get_class_weights())\n","\n","    # 🔥 IMPROVED Training parameters\n","    trainer.optimizer = optim.AdamW(\n","        model.parameters(),\n","        lr=8e-4,                 # Slightly lower (1e-3 -> 8e-4)\n","        weight_decay=0.02,       # Increased regularization\n","        betas=(0.9, 0.95)        # Increased beta2\n","    )\n","\n","    # Better scheduler\n","    trainer.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","        trainer.optimizer, mode='max', factor=0.7, patience=15, verbose=True, min_lr=1e-6\n","    )\n","\n","    # Training\n","    best_f1 = trainer.train(train_loader, val_loader, epochs=EPOCHS)\n","\n","    # Load best model for final evaluation\n","    checkpoint = torch.load(\"best_model.pth\")\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    # Final validation evaluation\n","    val_loss, val_acc, val_f1, val_preds, val_targets = trainer.validate(val_loader)\n","\n","    # Final test evaluation\n","    test_loss, test_acc, test_f1, test_preds, test_targets = trainer.validate(test_loader)\n","\n","    logger.info(\"🎯 IMPROVED Final Results:\")\n","    logger.info(f\"   📊 VALIDATION:\")\n","    logger.info(f\"     - Accuracy: {val_acc:.2f}%\")\n","    logger.info(f\"     - F1 Score: {val_f1:.4f}\")\n","    logger.info(f\"   📊 TEST:\")\n","    logger.info(f\"     - Accuracy: {test_acc:.2f}%\")\n","    logger.info(f\"     - F1 Score: {test_f1:.4f}\")\n","\n","    # Classification reports\n","    target_names = train_dataset.get_label_encoder().classes_\n","\n","    print(\"\\n📊 VALIDATION Classification Report:\")\n","    print(\"=\"*60)\n","    print(classification_report(val_targets, val_preds, target_names=target_names))\n","\n","    print(\"\\n📊 TEST Classification Report:\")\n","    print(\"=\"*60)\n","    print(classification_report(test_targets, test_preds, target_names=target_names))\n","\n","    # Confusion matrices - both validation and test\n","    plot_confusion_matrices(val_targets, val_preds, test_targets, test_preds, target_names)\n","\n","    # Training history visualization\n","    plot_results(trainer, \"improved_training_results.png\")\n","\n","    logger.info(\"✅ IMPROVED Training completed successfully!\")\n","    logger.info(f\"📁 Files saved:\")\n","    logger.info(f\"   - best_model.pth: Best model checkpoint\")\n","    logger.info(f\"   - validation_test_confusion_matrices.png: Confusion matrices\")\n","    logger.info(f\"   - improved_training_results.png: Training graphs\")\n","\n","    return trainer, model, train_dataset, val_targets, val_preds, test_targets, test_preds\n","\n","if __name__ == \"__main__\":\n","    trainer, model, dataset, val_targets, val_preds, test_targets, test_preds = main()"],"metadata":{"id":"HqeDTFjQNnr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#2-LSTM+attention\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import os\n","import logging\n","import random\n","from collections import Counter\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Logging setup\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","class BalancedDiverSignDataset(Dataset):\n","    \"\"\"Balanced dataset class for diver sign language recognition\"\"\"\n","    def __init__(self, sequences, labels, label_encoder=None, scaler=None,\n","                 noise_std=0.005, train_mode=True):\n","        # Label encoding\n","        if label_encoder is None:\n","            self.label_encoder = LabelEncoder()\n","            encoded_labels = self.label_encoder.fit_transform(labels)\n","        else:\n","            self.label_encoder = label_encoder\n","            encoded_labels = self.label_encoder.transform(labels)\n","\n","        # Data scaling using StandardScaler\n","        if scaler is None:\n","            self.scaler = StandardScaler()\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.fit_transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","        else:\n","            self.scaler = scaler\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","\n","        self.sequences = torch.FloatTensor(scaled_sequences)\n","        self.labels = torch.LongTensor(encoded_labels)\n","        self.noise_std = noise_std\n","        self.train_mode = train_mode\n","\n","        # Calculate class weights for imbalanced data\n","        class_counts = Counter(encoded_labels)\n","        total_samples = len(encoded_labels)\n","        self.class_weights = torch.FloatTensor([\n","            total_samples / (len(class_counts) * class_counts[i])\n","            for i in range(len(class_counts))\n","        ])\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        sequence = self.sequences[idx]\n","        label = self.labels[idx]\n","\n","        # Add light noise during training for regularization\n","        if self.train_mode and random.random() < 0.2:\n","            noise = torch.randn_like(sequence) * self.noise_std\n","            sequence = sequence + noise\n","\n","        return sequence, label\n","\n","    def get_label_encoder(self):\n","        return self.label_encoder\n","\n","    def get_scaler(self):\n","        return self.scaler\n","\n","    def get_class_weights(self):\n","        return self.class_weights\n","\n","class AttentionLayer(nn.Module):\n","    \"\"\"Additive Attention Mechanism for sequence modeling\"\"\"\n","    def __init__(self, hidden_dim):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","\n","        # Attention network with tanh activation\n","        self.attention = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.Tanh(),\n","            nn.Linear(hidden_dim, 1, bias=False)\n","        )\n","\n","    def forward(self, lstm_output):\n","        \"\"\"\n","        Forward pass for attention mechanism\n","        Args:\n","            lstm_output: [batch_size, seq_len, hidden_dim]\n","        Returns:\n","            context: [batch_size, hidden_dim]\n","            attention_weights: [batch_size, seq_len]\n","        \"\"\"\n","        # Calculate attention scores for each time step\n","        attention_scores = self.attention(lstm_output)  # [batch, seq_len, 1]\n","        attention_scores = attention_scores.squeeze(-1)  # [batch, seq_len]\n","\n","        # Apply softmax to get normalized attention weights\n","        attention_weights = torch.softmax(attention_scores, dim=1)  # [batch, seq_len]\n","\n","        # Calculate weighted context vector using attention weights\n","        context = torch.bmm(attention_weights.unsqueeze(1), lstm_output)  # [batch, 1, hidden_dim]\n","        context = context.squeeze(1)  # [batch, hidden_dim]\n","\n","        return context, attention_weights\n","\n","class LSTMAttentionModel(nn.Module):\n","    \"\"\"LSTM + Attention Model for diver sign language recognition\"\"\"\n","    def __init__(self,\n","                 input_dim=69,\n","                 hidden_dim=192,        # LSTM hidden dimension\n","                 num_layers=3,          # Number of LSTM layers\n","                 num_classes=10,\n","                 dropout=0.2,\n","                 bidirectional=True):   # Use bidirectional LSTM\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.bidirectional = bidirectional\n","        self.num_classes = num_classes\n","\n","        # Input preprocessing layer\n","        self.input_projection = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.LayerNorm(hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(dropout)\n","        )\n","\n","        # LSTM layer for sequential processing\n","        self.lstm = nn.LSTM(\n","            input_size=hidden_dim,\n","            hidden_size=hidden_dim,\n","            num_layers=num_layers,\n","            batch_first=True,\n","            dropout=dropout if num_layers > 1 else 0,\n","            bidirectional=bidirectional\n","        )\n","\n","        # Calculate LSTM output dimension (double if bidirectional)\n","        lstm_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n","\n","        # Attention layer for focusing on important time steps\n","        self.attention = AttentionLayer(lstm_output_dim)\n","\n","        # Classification head with multiple layers\n","        self.classifier = nn.Sequential(\n","            nn.LayerNorm(lstm_output_dim),\n","            nn.Dropout(dropout),\n","            nn.Linear(lstm_output_dim, lstm_output_dim // 2),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(lstm_output_dim // 2, lstm_output_dim // 4),\n","            nn.ReLU(),\n","            nn.Dropout(dropout * 0.8),\n","            nn.Linear(lstm_output_dim // 4, num_classes)\n","        )\n","\n","        self._init_weights()\n","\n","    def _init_weights(self):\n","        \"\"\"Initialize model weights using proper initialization strategies\"\"\"\n","        for name, param in self.named_parameters():\n","            if 'weight_ih' in name:  # Input-to-hidden weights\n","                nn.init.xavier_uniform_(param.data)\n","            elif 'weight_hh' in name:  # Hidden-to-hidden weights\n","                nn.init.orthogonal_(param.data)\n","            elif 'bias' in name:  # Bias terms\n","                param.data.fill_(0)\n","            elif isinstance(param, nn.Linear):  # Linear layer weights\n","                nn.init.xavier_uniform_(param.weight)\n","                if param.bias is not None:\n","                    nn.init.zeros_(param.bias)\n","\n","    def forward(self, x, return_attention=False):\n","        \"\"\"\n","        Forward pass through the model\n","        Args:\n","            x: [batch_size, seq_len, input_dim]\n","            return_attention: Return attention weights for visualization\n","        \"\"\"\n","        batch_size, seq_len, _ = x.shape\n","\n","        # Input preprocessing\n","        x = self.input_projection(x)  # [batch, seq_len, hidden_dim]\n","\n","        # LSTM forward pass for sequential modeling\n","        lstm_output, (hidden, cell) = self.lstm(x)  # [batch, seq_len, lstm_output_dim]\n","\n","        # Apply attention mechanism to focus on important time steps\n","        context_vector, attention_weights = self.attention(lstm_output)\n","\n","        # Final classification\n","        output = self.classifier(context_vector)\n","\n","        if return_attention:\n","            return output, attention_weights\n","        return output\n","\n","    def get_attention_weights(self, x):\n","        \"\"\"Get attention weights for analysis and visualization\"\"\"\n","        self.eval()\n","        with torch.no_grad():\n","            _, attention_weights = self.forward(x, return_attention=True)\n","        return attention_weights\n","\n","class LSTMAttentionTrainer:\n","    \"\"\"Trainer class for LSTM + Attention model\"\"\"\n","    def __init__(self, model, class_weights=None, device='cuda' if torch.cuda.is_available() else 'cpu'):\n","        self.model = model\n","        self.device = device\n","        self.model.to(device)\n","\n","        # Loss function with class weights and label smoothing\n","        if class_weights is not None:\n","            class_weights = class_weights.to(device)\n","\n","        self.criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n","\n","        # Optimizer optimized for LSTM training\n","        self.optimizer = optim.AdamW(\n","            model.parameters(),\n","            lr=5e-4,                 # Slightly higher learning rate for LSTM\n","            weight_decay=0.02,\n","            betas=(0.9, 0.95)\n","        )\n","\n","        # Learning rate scheduler\n","        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","            self.optimizer, mode='max', factor=0.7, patience=15, verbose=True, min_lr=1e-6\n","        )\n","\n","        # Metrics tracking\n","        self.train_losses = []\n","        self.val_losses = []\n","        self.train_accuracies = []\n","        self.val_accuracies = []\n","        self.val_f1_scores = []\n","\n","    def train_epoch(self, dataloader):\n","        \"\"\"Training for one epoch\"\"\"\n","        self.model.train()\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","\n","        for batch_idx, (data, target) in enumerate(tqdm(dataloader, desc=\"Training\")):\n","            data, target = data.to(self.device), target.to(self.device)\n","\n","            self.optimizer.zero_grad()\n","\n","            output = self.model(data)\n","\n","            # Loss calculation with L2 regularization\n","            ce_loss = self.criterion(output, target)\n","            l2_reg = sum(param.pow(2).sum() for param in self.model.parameters())\n","            loss = ce_loss + 2e-5 * l2_reg\n","\n","            loss.backward()\n","\n","            # Gradient clipping (important for LSTM stability)\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n","\n","            self.optimizer.step()\n","\n","            # Statistics tracking\n","            total_loss += loss.item()\n","            _, predicted = output.max(1)\n","            total += target.size(0)\n","            correct += predicted.eq(target).sum().item()\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_targets.extend(target.cpu().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","\n","        return avg_loss, accuracy, f1\n","\n","    def validate(self, dataloader):\n","        \"\"\"Validation evaluation\"\"\"\n","        self.model.eval()\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","\n","        with torch.no_grad():\n","            for data, target in tqdm(dataloader, desc=\"Validating\"):\n","                data, target = data.to(self.device), target.to(self.device)\n","\n","                output = self.model(data)\n","                loss = self.criterion(output, target)\n","\n","                total_loss += loss.item()\n","                _, predicted = output.max(1)\n","                total += target.size(0)\n","                correct += predicted.eq(target).sum().item()\n","\n","                all_preds.extend(predicted.cpu().numpy())\n","                all_targets.extend(target.cpu().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","\n","        return avg_loss, accuracy, f1, all_preds, all_targets\n","\n","    def train(self, train_loader, val_loader, epochs=150):\n","        \"\"\"Complete training loop\"\"\"\n","        best_val_f1 = 0\n","        patience = 20\n","        patience_counter = 0\n","\n","        logger.info(f\"LSTM + ATTENTION Training started: {epochs} epochs\")\n","\n","        for epoch in range(epochs):\n","            train_loss, train_acc, train_f1 = self.train_epoch(train_loader)\n","            val_loss, val_acc, val_f1, _, _ = self.validate(val_loader)\n","\n","            # Monitor overfitting by tracking train-validation gap\n","            train_val_gap = train_acc - val_acc\n","\n","            self.scheduler.step(val_f1)\n","\n","            # Save metrics for visualization\n","            self.train_losses.append(train_loss)\n","            self.val_losses.append(val_loss)\n","            self.train_accuracies.append(train_acc)\n","            self.val_accuracies.append(val_acc)\n","            self.val_f1_scores.append(val_f1)\n","\n","            # Logging every 5 epochs\n","            if (epoch + 1) % 5 == 0:\n","                logger.info(f'Epoch {epoch+1}/{epochs}:')\n","                logger.info(f'Train: Loss={train_loss:.3f}, Acc={train_acc:.1f}%, F1={train_f1:.3f}')\n","                logger.info(f'Val: Loss={val_loss:.3f}, Acc={val_acc:.1f}%, F1={val_f1:.3f}')\n","                logger.info(f'Gap: {train_val_gap:.1f}%, LR: {self.optimizer.param_groups[0][\"lr\"]:.2e}')\n","\n","            # Save best model based on validation F1 score\n","            if val_f1 > best_val_f1:\n","                best_val_f1 = val_f1\n","                torch.save({\n","                    'model_state_dict': self.model.state_dict(),\n","                    'epoch': epoch,\n","                    'val_f1': val_f1,\n","                    'train_val_gap': train_val_gap,\n","                    'model_type': 'LSTM_Attention'\n","                }, \"lstm_attention_best_model.pth\")\n","                logger.info(f\"✅ New best model saved: F1={val_f1:.3f}, Gap={train_val_gap:.1f}%\")\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","\n","            # Early stopping to prevent overfitting\n","            if patience_counter >= patience:\n","                logger.info(f\"Early stopping triggered at epoch {epoch+1}\")\n","                break\n","\n","        logger.info(f\"🎯 Training completed. Best F1 Score: {best_val_f1:.3f}\")\n","        return best_val_f1\n","\n","def visualize_attention_weights(model, dataloader, class_names, device, num_samples=3):\n","    \"\"\"Visualize attention weights to understand model focus\"\"\"\n","    model.eval()\n","\n","    fig, axes = plt.subplots(num_samples, 1, figsize=(15, 4*num_samples))\n","    if num_samples == 1:\n","        axes = [axes]\n","\n","    sample_count = 0\n","    with torch.no_grad():\n","        for data, targets in dataloader:\n","            if sample_count >= num_samples:\n","                break\n","\n","            data = data.to(device)\n","\n","            for i in range(min(data.size(0), num_samples - sample_count)):\n","                single_input = data[i:i+1]  # [1, seq_len, features]\n","                target_class = targets[i].item()\n","\n","                # Get attention weights for visualization\n","                attention_weights = model.get_attention_weights(single_input)\n","                attention_weights = attention_weights[0].cpu().numpy()  # [seq_len]\n","\n","                # Create attention weight plot\n","                ax = axes[sample_count]\n","                frames = range(len(attention_weights))\n","                ax.plot(frames, attention_weights, linewidth=2, color='blue')\n","                ax.fill_between(frames, attention_weights, alpha=0.3, color='blue')\n","                ax.set_title(f'Attention Weights - Class: {class_names[target_class]}')\n","                ax.set_xlabel('Frame Index')\n","                ax.set_ylabel('Attention Weight')\n","                ax.grid(True, alpha=0.3)\n","\n","                sample_count += 1\n","                if sample_count >= num_samples:\n","                    break\n","\n","    plt.tight_layout()\n","    plt.savefig('lstm_attention_weights.png', dpi=150)\n","    plt.show()\n","\n","def prepare_balanced_data(csv_path, sequence_length=150, overlap_ratio=0.3):\n","    \"\"\"Prepare balanced dataset with sliding window approach\"\"\"\n","    logger.info(f\"📊 Loading CSV data from: {csv_path}\")\n","\n","    df = pd.read_csv(csv_path)\n","    feature_columns = [col for col in df.columns if col != 'class']\n","\n","    # Data cleaning - handle NaN and infinite values\n","    df[feature_columns] = df[feature_columns].fillna(method='ffill').fillna(0)\n","    df[feature_columns] = df[feature_columns].replace([np.inf, -np.inf], 0)\n","\n","    # Keep only classes with sufficient data for reliable training\n","    min_samples = sequence_length * 4\n","    class_counts = df['class'].value_counts()\n","    valid_classes = class_counts[class_counts >= min_samples].index\n","    df = df[df['class'].isin(valid_classes)]\n","\n","    logger.info(f\"Valid classes after filtering: {list(valid_classes)}\")\n","\n","    sequences = []\n","    labels = []\n","\n","    # Create sequences using sliding window with overlap\n","    stride = int(sequence_length * (1 - overlap_ratio))\n","\n","    for class_name in valid_classes:\n","        class_data = df[df['class'] == class_name].reset_index(drop=True)\n","\n","        for i in range(0, len(class_data) - sequence_length + 1, stride):\n","            sequence = class_data.iloc[i:i+sequence_length][feature_columns].values\n","\n","            if len(sequence) == sequence_length:\n","                sequences.append(sequence)\n","                labels.append(class_name)\n","\n","    sequences = np.array(sequences)\n","    logger.info(f\"Total sequences created: {len(sequences)}\")\n","    logger.info(f\"Class distribution: {dict(Counter(labels))}\")\n","\n","    return sequences, labels, len(feature_columns)\n","\n","def plot_training_results(trainer, model_name=\"LSTM_Attention\"):\n","    \"\"\"Visualize training results and performance metrics\"\"\"\n","    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n","\n","    epochs = range(1, len(trainer.train_losses) + 1)\n","\n","    # Loss curves\n","    ax1.plot(epochs, trainer.train_losses, 'b-', label='Training Loss', linewidth=2)\n","    ax1.plot(epochs, trainer.val_losses, 'r-', label='Validation Loss', linewidth=2)\n","    ax1.set_title(f'{model_name} - Loss Curves')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.legend()\n","    ax1.grid(True, alpha=0.3)\n","\n","    # Accuracy curves\n","    ax2.plot(epochs, trainer.train_accuracies, 'b-', label='Training Accuracy', linewidth=2)\n","    ax2.plot(epochs, trainer.val_accuracies, 'r-', label='Validation Accuracy', linewidth=2)\n","    ax2.set_title(f'{model_name} - Accuracy Curves')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel('Accuracy (%)')\n","    ax2.legend()\n","    ax2.grid(True, alpha=0.3)\n","\n","    # Train-Validation gap analysis\n","    gaps = [t - v for t, v in zip(trainer.train_accuracies, trainer.val_accuracies)]\n","    ax3.plot(epochs, gaps, 'purple', linewidth=2)\n","    ax3.axhline(y=12, color='orange', linestyle='--', label='Warning Threshold')\n","    ax3.axhline(y=8, color='green', linestyle='--', label='Good Threshold')\n","    ax3.set_title(f'{model_name} - Train-Validation Gap')\n","    ax3.set_xlabel('Epoch')\n","    ax3.set_ylabel('Accuracy Gap (%)')\n","    ax3.legend()\n","    ax3.grid(True, alpha=0.3)\n","\n","    # F1 score progression\n","    ax4.plot(epochs, trainer.val_f1_scores, 'green', linewidth=2)\n","    ax4.set_title(f'{model_name} - Validation F1 Score')\n","    ax4.set_xlabel('Epoch')\n","    ax4.set_ylabel('F1 Score')\n","    ax4.grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.savefig(f'{model_name.lower()}_results.png', dpi=150)\n","    plt.show()\n","\n","def plot_confusion_matrices(val_targets, val_preds, test_targets, test_preds, target_names):\n","    \"\"\"Plot confusion matrices for both validation and test sets\"\"\"\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n","\n","    # Validation Confusion Matrix\n","    cm_val = confusion_matrix(val_targets, val_preds)\n","    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=target_names, yticklabels=target_names, ax=ax1)\n","    ax1.set_title('Validation Confusion Matrix', fontsize=16, fontweight='bold')\n","    ax1.set_ylabel('True Label', fontsize=12)\n","    ax1.set_xlabel('Predicted Label', fontsize=12)\n","    ax1.tick_params(axis='x', rotation=45)\n","\n","    # Test Confusion Matrix\n","    cm_test = confusion_matrix(test_targets, test_preds)\n","    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens',\n","                xticklabels=target_names, yticklabels=target_names, ax=ax2)\n","    ax2.set_title('Test Confusion Matrix', fontsize=16, fontweight='bold')\n","    ax2.set_ylabel('True Label', fontsize=12)\n","    ax2.set_xlabel('Predicted Label', fontsize=12)\n","    ax2.tick_params(axis='x', rotation=45)\n","\n","    plt.tight_layout()\n","    plt.savefig('lstm_attention_confusion_matrices.png', dpi=150)\n","    plt.show()\n","\n","def main():\n","    set_seed(42)\n","\n","    # Configuration parameters\n","    CSV_PATH = \"\"  # Update with your dataset path\n","    SEQUENCE_LENGTH = 150\n","    BATCH_SIZE = 16          # Smaller batch size for LSTM stability\n","    EPOCHS = 150             # Extended training epochs\n","    VAL_SIZE = 0.15          # 15% for validation\n","    TEST_SIZE = 0.15         # 15% for test (70% remaining for training)\n","\n","    logger.info(\"🚀 LSTM + ATTENTION Model Training Started!\")\n","    logger.info(f\"📊 Data split: 70% Train, 15% Validation, 15% Test\")\n","\n","    # Data preparation with balanced approach\n","    sequences, labels, feature_count = prepare_balanced_data(\n","        CSV_PATH, SEQUENCE_LENGTH, overlap_ratio=0.3\n","    )\n","\n","    if len(sequences) == 0:\n","        logger.error(\"❌ No valid sequences found!\")\n","        return\n","\n","    # First split: train+val (85%) and test (15%)\n","    X_temp, X_test, y_temp, y_test = train_test_split(\n","        sequences, labels, test_size=TEST_SIZE, random_state=42, stratify=labels\n","    )\n","\n","    # Second split: train (70%) and val (15%) from remaining 85%\n","    val_size_adjusted = VAL_SIZE / (1 - TEST_SIZE)  # 0.15 / 0.85 ≈ 0.176\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_temp, y_temp, test_size=val_size_adjusted, random_state=42, stratify=y_temp\n","    )\n","\n","    logger.info(f\"🔄 Training sequences: {len(X_train):,} ({len(X_train)/len(sequences)*100:.1f}%)\")\n","    logger.info(f\"🔄 Validation sequences: {len(X_val):,} ({len(X_val)/len(sequences)*100:.1f}%)\")\n","    logger.info(f\"🔄 Test sequences: {len(X_test):,} ({len(X_test)/len(sequences)*100:.1f}%)\")\n","\n","    # Create datasets with appropriate modes\n","    train_dataset = BalancedDiverSignDataset(X_train, y_train, train_mode=True)\n","    val_dataset = BalancedDiverSignDataset(\n","        X_val, y_val, train_dataset.get_label_encoder(),\n","        train_dataset.get_scaler(), train_mode=False\n","    )\n","    test_dataset = BalancedDiverSignDataset(\n","        X_test, y_test, train_dataset.get_label_encoder(),\n","        train_dataset.get_scaler(), train_mode=False\n","    )\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n","    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n","\n","    # Initialize LSTM + Attention model\n","    num_classes = len(train_dataset.get_label_encoder().classes_)\n","    model = LSTMAttentionModel(\n","        input_dim=feature_count,\n","        hidden_dim=192,           # LSTM hidden dimension\n","        num_layers=3,             # Number of LSTM layers\n","        num_classes=num_classes,\n","        dropout=0.2,\n","        bidirectional=True        # Use bidirectional LSTM\n","    )\n","\n","    logger.info(f\"🤖 LSTM + ATTENTION Model Configuration:\")\n","    logger.info(f\"   - Number of classes: {num_classes}\")\n","    logger.info(f\"   - Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n","    logger.info(f\"   - LSTM hidden dimension: 192\")\n","    logger.info(f\"   - LSTM layers: 3\")\n","    logger.info(f\"   - Bidirectional: True\")\n","\n","    # Initialize trainer with class weights\n","    trainer = LSTMAttentionTrainer(model, train_dataset.get_class_weights())\n","\n","    # Start training process\n","    best_f1 = trainer.train(train_loader, val_loader, epochs=EPOCHS)\n","\n","    # Load best model for final evaluation\n","    checkpoint = torch.load(\"lstm_attention_best_model.pth\")\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    # Final validation evaluation\n","    val_loss, val_acc, val_f1, val_preds, val_targets = trainer.validate(val_loader)\n","\n","    # Final test evaluation\n","    test_loss, test_acc, test_f1, test_preds, test_targets = trainer.validate(test_loader)\n","\n","    # Calculate final training-validation gap\n","    final_train_acc = trainer.train_accuracies[-1]\n","    final_val_acc = trainer.val_accuracies[-1]\n","    accuracy_gap = final_train_acc - final_val_acc\n","\n","    logger.info(\"🎯 LSTM + ATTENTION Final Results:\")\n","    logger.info(f\"   📊 VALIDATION:\")\n","    logger.info(f\"     - Accuracy: {val_acc:.1f}%\")\n","    logger.info(f\"     - F1 Score: {val_f1:.3f}\")\n","    logger.info(f\"   📊 TEST:\")\n","    logger.info(f\"     - Accuracy: {test_acc:.1f}%\")\n","    logger.info(f\"     - F1 Score: {test_f1:.3f}\")\n","    logger.info(f\"   📊 OVERFITTING ANALYSIS:\")\n","    logger.info(f\"     - Train-Validation Gap: {accuracy_gap:.1f}%\")\n","\n","    # Detailed classification reports\n","    target_names = train_dataset.get_label_encoder().classes_\n","\n","    print(\"\\n📊 VALIDATION Classification Report:\")\n","    print(\"=\"*60)\n","    print(classification_report(val_targets, val_preds, target_names=target_names))\n","\n","    print(\"\\n📊 TEST Classification Report:\")\n","    print(\"=\"*60)\n","    print(classification_report(test_targets, test_preds, target_names=target_names))\n","\n","    # Generate confusion matrices for both validation and test\n","    plot_confusion_matrices(val_targets, val_preds, test_targets, test_preds, target_names)\n","\n","    # Plot training progress and metrics\n","    plot_training_results(trainer, \"LSTM_Attention\")\n","\n","    # Visualize attention weights for model interpretability\n","    logger.info(\"🔍 Generating attention weight visualizations...\")\n","    visualize_attention_weights(model, test_loader, target_names, trainer.device, num_samples=3)\n","\n","    logger.info(\"✅ LSTM + ATTENTION training completed successfully!\")\n","    logger.info(f\"📁 Files saved:\")\n","    logger.info(f\"   - lstm_attention_best_model.pth: Best model checkpoint\")\n","    logger.info(f\"   - lstm_attention_confusion_matrices.png: Confusion matrices\")\n","    logger.info(f\"   - lstm_attention_results.png: Training curves\")\n","    logger.info(f\"   - lstm_attention_weights.png: Attention visualizations\")\n","\n","    return trainer, model, train_dataset, val_targets, val_preds, test_targets, test_preds\n","\n","if __name__ == \"__main__\":\n","    trainer, model, dataset, val_targets, val_preds, test_targets, test_preds = main()"],"metadata":{"id":"fbxHnCTIm85Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#3-lstm+GRU\n","\n","# LSTM + GRU Hybrid Model for Diver Sign Language Recognition\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import os\n","import logging\n","import random\n","from collections import Counter\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Logging setup\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","def set_seed(seed=42):\n","    \"\"\"Set random seeds for reproducibility\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","class BalancedDiverSignDataset(Dataset):\n","    \"\"\"Balanced dataset class with data augmentation for diver sign language\"\"\"\n","    def __init__(self, sequences, labels, label_encoder=None, scaler=None,\n","                 noise_std=0.005, train_mode=True, augment_prob=0.3):\n","        # Label encoding\n","        if label_encoder is None:\n","            self.label_encoder = LabelEncoder()\n","            encoded_labels = self.label_encoder.fit_transform(labels)\n","        else:\n","            self.label_encoder = label_encoder\n","            encoded_labels = self.label_encoder.transform(labels)\n","\n","        # Data scaling using StandardScaler\n","        if scaler is None:\n","            self.scaler = StandardScaler()\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.fit_transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","        else:\n","            self.scaler = scaler\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","\n","        self.sequences = torch.FloatTensor(scaled_sequences)\n","        self.labels = torch.LongTensor(encoded_labels)\n","        self.noise_std = noise_std\n","        self.train_mode = train_mode\n","        self.augment_prob = augment_prob\n","\n","        # Calculate class weights for imbalanced data handling\n","        class_counts = Counter(encoded_labels)\n","        total_samples = len(encoded_labels)\n","        self.class_weights = torch.FloatTensor([\n","            total_samples / (len(class_counts) * class_counts[i])\n","            for i in range(len(class_counts))\n","        ])\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        sequence = self.sequences[idx].clone()\n","        label = self.labels[idx]\n","\n","        # Apply data augmentation during training\n","        if self.train_mode and random.random() < self.augment_prob:\n","            sequence = self._augment_sequence(sequence)\n","\n","        return sequence, label\n","\n","    def _augment_sequence(self, sequence):\n","        \"\"\"Apply various sequence augmentation techniques\"\"\"\n","        aug_type = random.choice(['noise', 'scale', 'shift'])\n","\n","        if aug_type == 'noise':\n","            # Add Gaussian noise for robustness\n","            noise = torch.randn_like(sequence) * self.noise_std\n","            sequence = sequence + noise\n","\n","        elif aug_type == 'scale':\n","            # Apply random scaling\n","            scale_factor = random.uniform(0.98, 1.02)\n","            sequence = sequence * scale_factor\n","\n","        elif aug_type == 'shift':\n","            # Apply temporal shifting\n","            shift = random.randint(-3, 3)\n","            sequence = torch.roll(sequence, shift, dims=0)\n","\n","        return sequence\n","\n","    def get_label_encoder(self):\n","        return self.label_encoder\n","\n","    def get_scaler(self):\n","        return self.scaler\n","\n","    def get_class_weights(self):\n","        return self.class_weights\n","\n","class LSTMGRUHybridModel(nn.Module):\n","    \"\"\"LSTM + GRU Hybrid Model for enhanced sequential pattern recognition\"\"\"\n","    def __init__(self, input_dim=69, lstm_hidden=256, gru_hidden=256,\n","                 num_classes=10, dropout=0.2, num_layers=2):\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.lstm_hidden = lstm_hidden\n","        self.gru_hidden = gru_hidden\n","        self.num_classes = num_classes\n","        self.num_layers = num_layers\n","\n","        # Input preprocessing layer\n","        self.input_projection = nn.Sequential(\n","            nn.Linear(input_dim, lstm_hidden),\n","            nn.LayerNorm(lstm_hidden),\n","            nn.ReLU(),\n","            nn.Dropout(dropout)\n","        )\n","\n","        # LSTM layers for capturing long-term dependencies\n","        self.lstm = nn.LSTM(\n","            input_size=lstm_hidden,\n","            hidden_size=lstm_hidden,\n","            num_layers=num_layers,\n","            batch_first=True,\n","            dropout=dropout if num_layers > 1 else 0,\n","            bidirectional=True\n","        )\n","\n","        # GRU layers for shorter patterns and feature refinement\n","        lstm_output_dim = lstm_hidden * 2  # Bidirectional output\n","        self.gru = nn.GRU(\n","            input_size=lstm_output_dim,\n","            hidden_size=gru_hidden,\n","            num_layers=num_layers,\n","            batch_first=True,\n","            dropout=dropout if num_layers > 1 else 0,\n","            bidirectional=True\n","        )\n","\n","        # Attention mechanism for LSTM outputs\n","        self.lstm_attention = nn.Sequential(\n","            nn.Linear(lstm_output_dim, lstm_hidden),\n","            nn.Tanh(),\n","            nn.Linear(lstm_hidden, 1, bias=False)\n","        )\n","\n","        # Attention mechanism for GRU outputs\n","        gru_output_dim = gru_hidden * 2  # Bidirectional output\n","        self.gru_attention = nn.Sequential(\n","            nn.Linear(gru_output_dim, gru_hidden),\n","            nn.Tanh(),\n","            nn.Linear(gru_hidden, 1, bias=False)\n","        )\n","\n","        # Feature fusion layer to combine LSTM and GRU representations\n","        total_features = lstm_output_dim + gru_output_dim\n","        self.feature_fusion = nn.Sequential(\n","            nn.Linear(total_features, total_features // 2),\n","            nn.LayerNorm(total_features // 2),\n","            nn.ReLU(),\n","            nn.Dropout(dropout)\n","        )\n","\n","        # Multi-layer classification head\n","        self.classifier = nn.Sequential(\n","            nn.Linear(total_features // 2, total_features // 4),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(total_features // 4, total_features // 8),\n","            nn.ReLU(),\n","            nn.Dropout(dropout * 0.5),\n","            nn.Linear(total_features // 8, num_classes)\n","        )\n","\n","        self._init_weights()\n","\n","    def _init_weights(self):\n","        \"\"\"Initialize model weights using appropriate strategies\"\"\"\n","        for name, param in self.named_parameters():\n","            if param.dim() >= 2:  # Only initialize 2D+ tensors\n","                if 'weight_ih' in name or 'weight_hh' in name:\n","                    if 'lstm' in name:\n","                        # LSTM weight initialization\n","                        if 'weight_ih' in name:\n","                            nn.init.xavier_uniform_(param.data)\n","                        else:\n","                            nn.init.orthogonal_(param.data)\n","                    elif 'gru' in name:\n","                        # GRU weight initialization\n","                        if 'weight_ih' in name:\n","                            nn.init.xavier_uniform_(param.data)\n","                        else:\n","                            nn.init.orthogonal_(param.data)\n","                elif 'weight' in name:\n","                    nn.init.xavier_uniform_(param.data)\n","            elif 'bias' in name:\n","                nn.init.constant_(param.data, 0)\n","\n","    def forward(self, x, return_attention=False):\n","        \"\"\"\n","        Forward pass through the hybrid model\n","        Args:\n","            x: [batch_size, seq_len, input_dim]\n","            return_attention: Whether to return attention weights\n","        \"\"\"\n","        batch_size, seq_len, _ = x.shape\n","\n","        # Input preprocessing\n","        x = self.input_projection(x)  # [batch, seq_len, lstm_hidden]\n","\n","        # LSTM processing for long-term dependency capture\n","        lstm_output, _ = self.lstm(x)  # [batch, seq_len, lstm_hidden*2]\n","\n","        # LSTM attention mechanism\n","        lstm_attn_scores = self.lstm_attention(lstm_output).squeeze(-1)  # [batch, seq_len]\n","        lstm_attn_weights = torch.softmax(lstm_attn_scores, dim=1)\n","        lstm_attended = torch.bmm(lstm_attn_weights.unsqueeze(1), lstm_output).squeeze(1)\n","\n","        # GRU processing for pattern refinement and shorter dependencies\n","        gru_output, _ = self.gru(lstm_output)  # [batch, seq_len, gru_hidden*2]\n","\n","        # GRU attention mechanism\n","        gru_attn_scores = self.gru_attention(gru_output).squeeze(-1)  # [batch, seq_len]\n","        gru_attn_weights = torch.softmax(gru_attn_scores, dim=1)\n","        gru_attended = torch.bmm(gru_attn_weights.unsqueeze(1), gru_output).squeeze(1)\n","\n","        # Feature fusion: combine LSTM and GRU representations\n","        combined_features = torch.cat([lstm_attended, gru_attended], dim=1)\n","        fused_features = self.feature_fusion(combined_features)\n","\n","        # Final classification\n","        output = self.classifier(fused_features)\n","\n","        if return_attention:\n","            return output, lstm_attn_weights, gru_attn_weights\n","        return output\n","\n","    def get_attention_weights(self, x):\n","        \"\"\"Extract attention weights for visualization\"\"\"\n","        self.eval()\n","        with torch.no_grad():\n","            _, lstm_attn, gru_attn = self.forward(x, return_attention=True)\n","        return lstm_attn, gru_attn\n","\n","class LSTMGRUTrainer:\n","    \"\"\"Trainer class for LSTM-GRU hybrid model\"\"\"\n","    def __init__(self, model, class_weights=None, device='cuda' if torch.cuda.is_available() else 'cpu'):\n","        self.model = model\n","        self.device = device\n","        self.model.to(device)\n","\n","        # Loss function with class balancing\n","        if class_weights is not None:\n","            class_weights = class_weights.to(device)\n","\n","        self.criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n","\n","        # Optimizer configuration\n","        self.optimizer = optim.AdamW(\n","            self.model.parameters(),\n","            lr=1e-3,\n","            weight_decay=0.01,\n","            betas=(0.9, 0.95)\n","        )\n","\n","        # Learning rate scheduler\n","        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","            self.optimizer, mode='max', factor=0.7, patience=12, verbose=True, min_lr=1e-6\n","        )\n","\n","        # Metrics tracking\n","        self.train_losses = []\n","        self.val_losses = []\n","        self.train_accuracies = []\n","        self.val_accuracies = []\n","        self.val_f1_scores = []\n","\n","    def train_epoch(self, dataloader):\n","        \"\"\"Execute one training epoch\"\"\"\n","        self.model.train()\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","\n","        for batch_idx, (data, target) in enumerate(tqdm(dataloader, desc=\"Training\")):\n","            data, target = data.to(self.device), target.to(self.device)\n","\n","            self.optimizer.zero_grad()\n","\n","            output = self.model(data)\n","\n","            # Loss calculation with L2 regularization\n","            ce_loss = self.criterion(output, target)\n","            l2_reg = sum(param.pow(2).sum() for param in self.model.parameters())\n","            loss = ce_loss + 1e-5 * l2_reg\n","\n","            loss.backward()\n","\n","            # Gradient clipping for training stability\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n","\n","            self.optimizer.step()\n","\n","            # Statistics tracking\n","            total_loss += loss.item()\n","            _, predicted = output.max(1)\n","            total += target.size(0)\n","            correct += predicted.eq(target).sum().item()\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_targets.extend(target.cpu().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","\n","        return avg_loss, accuracy, f1\n","\n","    def validate(self, dataloader):\n","        \"\"\"Perform validation evaluation\"\"\"\n","        self.model.eval()\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","\n","        with torch.no_grad():\n","            for data, target in tqdm(dataloader, desc=\"Validating\"):\n","                data, target = data.to(self.device), target.to(self.device)\n","\n","                output = self.model(data)\n","                loss = self.criterion(output, target)\n","\n","                total_loss += loss.item()\n","                _, predicted = output.max(1)\n","                total += target.size(0)\n","                correct += predicted.eq(target).sum().item()\n","\n","                all_preds.extend(predicted.cpu().numpy())\n","                all_targets.extend(target.cpu().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","\n","        return avg_loss, accuracy, f1, all_preds, all_targets\n","\n","    def train(self, train_loader, val_loader, epochs=150):\n","        \"\"\"Complete training loop with validation\"\"\"\n","        best_val_f1 = 0\n","        patience = 20\n","        patience_counter = 0\n","\n","        logger.info(f\"🚀 LSTM-GRU Hybrid Training Started: {epochs} epochs\")\n","\n","        for epoch in range(epochs):\n","            train_loss, train_acc, train_f1 = self.train_epoch(train_loader)\n","            val_loss, val_acc, val_f1, _, _ = self.validate(val_loader)\n","\n","            # Learning rate scheduling\n","            self.scheduler.step(val_f1)\n","\n","            # Calculate train-validation gap for overfitting analysis\n","            train_val_gap = train_acc - val_acc\n","\n","            # Save metrics for plotting\n","            self.train_losses.append(train_loss)\n","            self.val_losses.append(val_loss)\n","            self.train_accuracies.append(train_acc)\n","            self.val_accuracies.append(val_acc)\n","            self.val_f1_scores.append(val_f1)\n","\n","            # Progress logging every 5 epochs\n","            if (epoch + 1) % 5 == 0:\n","                logger.info(f'Epoch {epoch+1}/{epochs}:')\n","                logger.info(f'  Train: Loss={train_loss:.3f}, Acc={train_acc:.1f}%, F1={train_f1:.3f}')\n","                logger.info(f'  Val:   Loss={val_loss:.3f}, Acc={val_acc:.1f}%, F1={val_f1:.3f}')\n","                logger.info(f'  Gap: {train_val_gap:.1f}%, LR: {self.optimizer.param_groups[0][\"lr\"]:.2e}')\n","\n","            # Save best model based on validation F1 score\n","            if val_f1 > best_val_f1:\n","                best_val_f1 = val_f1\n","                torch.save({\n","                    'model_state_dict': self.model.state_dict(),\n","                    'epoch': epoch,\n","                    'val_f1': val_f1,\n","                    'train_val_gap': train_val_gap,\n","                    'model_type': 'LSTM_GRU_Hybrid'\n","                }, \"lstm_gru_hybrid_best_model.pth\")\n","                logger.info(f\"  ✅ New best model saved: F1={val_f1:.3f}, Gap={train_val_gap:.1f}%\")\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","\n","            # Early stopping to prevent overfitting\n","            if patience_counter >= patience:\n","                logger.info(f\"Early stopping triggered at epoch {epoch+1}\")\n","                break\n","\n","        logger.info(f\"🎯 Training completed. Best F1 Score: {best_val_f1:.3f}\")\n","        return best_val_f1\n","\n","def visualize_dual_attention_weights(model, dataloader, class_names, device, num_samples=3):\n","    \"\"\"Visualize both LSTM and GRU attention weights for model interpretability\"\"\"\n","    model.eval()\n","\n","    fig, axes = plt.subplots(num_samples, 2, figsize=(16, 4*num_samples))\n","    if num_samples == 1:\n","        axes = axes.reshape(1, -1)\n","\n","    sample_count = 0\n","    with torch.no_grad():\n","        for data, targets in dataloader:\n","            if sample_count >= num_samples:\n","                break\n","\n","            data = data.to(device)\n","\n","            for i in range(min(data.size(0), num_samples - sample_count)):\n","                single_input = data[i:i+1]\n","                target_class = targets[i].item()\n","\n","                # Extract attention weights\n","                lstm_attn, gru_attn = model.get_attention_weights(single_input)\n","                lstm_attn = lstm_attn[0].cpu().numpy()\n","                gru_attn = gru_attn[0].cpu().numpy()\n","\n","                # Plot LSTM attention weights\n","                ax1 = axes[sample_count, 0]\n","                frames = range(len(lstm_attn))\n","                ax1.plot(frames, lstm_attn, linewidth=2, color='blue', label='LSTM Attention')\n","                ax1.fill_between(frames, lstm_attn, alpha=0.3, color='blue')\n","                ax1.set_title(f'LSTM Attention - Class: {class_names[target_class]}')\n","                ax1.set_xlabel('Frame Index')\n","                ax1.set_ylabel('Attention Weight')\n","                ax1.grid(True, alpha=0.3)\n","                ax1.legend()\n","\n","                # Plot GRU attention weights\n","                ax2 = axes[sample_count, 1]\n","                ax2.plot(frames, gru_attn, linewidth=2, color='red', label='GRU Attention')\n","                ax2.fill_between(frames, gru_attn, alpha=0.3, color='red')\n","                ax2.set_title(f'GRU Attention - Class: {class_names[target_class]}')\n","                ax2.set_xlabel('Frame Index')\n","                ax2.set_ylabel('Attention Weight')\n","                ax2.grid(True, alpha=0.3)\n","                ax2.legend()\n","\n","                sample_count += 1\n","                if sample_count >= num_samples:\n","                    break\n","\n","    plt.tight_layout()\n","    plt.savefig('lstm_gru_hybrid_attention_weights.png', dpi=150)\n","    plt.show()\n","\n","def plot_training_results(trainer, model_name=\"LSTM_GRU_Hybrid\"):\n","    \"\"\"Visualize comprehensive training results and metrics\"\"\"\n","    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n","\n","    epochs = range(1, len(trainer.train_losses) + 1)\n","\n","    # Loss curves\n","    ax1.plot(epochs, trainer.train_losses, 'b-', label='Training Loss', linewidth=2)\n","    ax1.plot(epochs, trainer.val_losses, 'r-', label='Validation Loss', linewidth=2)\n","    ax1.set_title(f'{model_name} - Loss Curves')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.legend()\n","    ax1.grid(True, alpha=0.3)\n","\n","    # Accuracy curves\n","    ax2.plot(epochs, trainer.train_accuracies, 'b-', label='Training Accuracy', linewidth=2)\n","    ax2.plot(epochs, trainer.val_accuracies, 'r-', label='Validation Accuracy', linewidth=2)\n","    ax2.set_title(f'{model_name} - Accuracy Curves')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel('Accuracy (%)')\n","    ax2.legend()\n","    ax2.grid(True, alpha=0.3)\n","\n","    # F1 Score progression\n","    ax3.plot(epochs, trainer.val_f1_scores, 'green', linewidth=2)\n","    ax3.set_title(f'{model_name} - Validation F1 Score')\n","    ax3.set_xlabel('Epoch')\n","    ax3.set_ylabel('F1 Score')\n","    ax3.grid(True, alpha=0.3)\n","\n","    # Overfitting analysis through train-validation gap\n","    gaps = [t - v for t, v in zip(trainer.train_accuracies, trainer.val_accuracies)]\n","    ax4.plot(epochs, gaps, 'purple', linewidth=2)\n","    ax4.axhline(y=10, color='orange', linestyle='--', label='Warning Threshold')\n","    ax4.axhline(y=5, color='green', linestyle='--', label='Good Threshold')\n","    ax4.set_title(f'{model_name} - Train-Validation Gap')\n","    ax4.set_xlabel('Epoch')\n","    ax4.set_ylabel('Accuracy Gap (%)')\n","    ax4.legend()\n","    ax4.grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.savefig(f'{model_name.lower()}_training_results.png', dpi=150)\n","    plt.show()\n","\n","def prepare_balanced_dataset(csv_path, sequence_length=150, overlap_ratio=0.3):\n","    \"\"\"Prepare balanced dataset with sliding window approach\"\"\"\n","    logger.info(f\"📊 Loading data from: {csv_path}\")\n","\n","    df = pd.read_csv(csv_path)\n","    feature_columns = [col for col in df.columns if col != 'class']\n","\n","    # Data cleaning: handle missing and infinite values\n","    df[feature_columns] = df[feature_columns].fillna(method='ffill').fillna(0)\n","    df[feature_columns] = df[feature_columns].replace([np.inf, -np.inf], 0)\n","\n","    # Filter classes with sufficient data for reliable training\n","    min_samples = sequence_length * 4\n","    class_counts = df['class'].value_counts()\n","    valid_classes = class_counts[class_counts >= min_samples].index\n","    df = df[df['class'].isin(valid_classes)]\n","\n","    logger.info(f\"Valid classes after filtering: {list(valid_classes)}\")\n","\n","    sequences = []\n","    labels = []\n","\n","    # Create sequences using sliding window with overlap\n","    stride = int(sequence_length * (1 - overlap_ratio))\n","\n","    for class_name in valid_classes:\n","        class_data = df[df['class'] == class_name].reset_index(drop=True)\n","\n","        for i in range(0, len(class_data) - sequence_length + 1, stride):\n","            sequence = class_data.iloc[i:i+sequence_length][feature_columns].values\n","\n","            if len(sequence) == sequence_length:\n","                sequences.append(sequence)\n","                labels.append(class_name)\n","\n","    sequences = np.array(sequences)\n","    logger.info(f\"Total sequences created: {len(sequences)}\")\n","    logger.info(f\"Class distribution: {dict(Counter(labels))}\")\n","\n","    return sequences, labels, len(feature_columns)\n","\n","def plot_confusion_matrices(val_targets, val_preds, test_targets, test_preds, target_names):\n","    \"\"\"Plot confusion matrices for both validation and test sets\"\"\"\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n","\n","    # Validation Confusion Matrix\n","    cm_val = confusion_matrix(val_targets, val_preds)\n","    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=target_names, yticklabels=target_names, ax=ax1)\n","    ax1.set_title('Validation Confusion Matrix', fontsize=16, fontweight='bold')\n","    ax1.set_ylabel('True Label', fontsize=12)\n","    ax1.set_xlabel('Predicted Label', fontsize=12)\n","    ax1.tick_params(axis='x', rotation=45)\n","\n","    # Test Confusion Matrix\n","    cm_test = confusion_matrix(test_targets, test_preds)\n","    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens',\n","                xticklabels=target_names, yticklabels=target_names, ax=ax2)\n","    ax2.set_title('Test Confusion Matrix', fontsize=16, fontweight='bold')\n","    ax2.set_ylabel('True Label', fontsize=12)\n","    ax2.set_xlabel('Predicted Label', fontsize=12)\n","    ax2.tick_params(axis='x', rotation=45)\n","\n","    plt.tight_layout()\n","    plt.savefig('lstm_gru_hybrid_confusion_matrices.png', dpi=150)\n","    plt.show()\n","\n","def main():\n","    set_seed(42)\n","\n","    # Configuration parameters\n","    CSV_PATH = \"\"  # Update with your dataset path\n","    SEQUENCE_LENGTH = 150\n","    BATCH_SIZE = 20\n","    EPOCHS = 150             # Extended training epochs\n","    VAL_SIZE = 0.15          # 15% for validation\n","    TEST_SIZE = 0.15         # 15% for test (70% remaining for training)\n","\n","    logger.info(\"🚀 LSTM-GRU HYBRID Model Training Started!\")\n","    logger.info(f\"📊 Data split: 70% Train, 15% Validation, 15% Test\")\n","\n","    # Data preparation with balanced approach\n","    sequences, labels, feature_count = prepare_balanced_dataset(\n","        CSV_PATH, SEQUENCE_LENGTH, overlap_ratio=0.3\n","    )\n","\n","    if len(sequences) == 0:\n","        logger.error(\"❌ No valid sequences found!\")\n","        return\n","\n","    # First split: train+val (85%) and test (15%)\n","    X_temp, X_test, y_temp, y_test = train_test_split(\n","        sequences, labels, test_size=TEST_SIZE, random_state=42, stratify=labels\n","    )\n","\n","    # Second split: train (70%) and val (15%) from remaining 85%\n","    val_size_adjusted = VAL_SIZE / (1 - TEST_SIZE)  # 0.15 / 0.85 ≈ 0.176\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_temp, y_temp, test_size=val_size_adjusted, random_state=42, stratify=y_temp\n","    )\n","\n","    logger.info(f\"🔄 Training sequences: {len(X_train):,} ({len(X_train)/len(sequences)*100:.1f}%)\")\n","    logger.info(f\"🔄 Validation sequences: {len(X_val):,} ({len(X_val)/len(sequences)*100:.1f}%)\")\n","    logger.info(f\"🔄 Test sequences: {len(X_test):,} ({len(X_test)/len(sequences)*100:.1f}%)\")\n","\n","    # Create datasets with appropriate modes\n","    train_dataset = BalancedDiverSignDataset(X_train, y_train, train_mode=True)\n","    val_dataset = BalancedDiverSignDataset(\n","        X_val, y_val, train_dataset.get_label_encoder(),\n","        train_dataset.get_scaler(), train_mode=False\n","    )\n","    test_dataset = BalancedDiverSignDataset(\n","        X_test, y_test, train_dataset.get_label_encoder(),\n","        train_dataset.get_scaler(), train_mode=False\n","    )\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n","    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n","\n","    # Initialize LSTM-GRU hybrid model\n","    num_classes = len(train_dataset.get_label_encoder().classes_)\n","    model = LSTMGRUHybridModel(\n","        input_dim=feature_count,\n","        lstm_hidden=256,\n","        gru_hidden=256,\n","        num_classes=num_classes,\n","        dropout=0.2,\n","        num_layers=2\n","    )\n","\n","    logger.info(f\"🤖 LSTM-GRU Hybrid Model Configuration:\")\n","    logger.info(f\"   - Number of classes: {num_classes}\")\n","    logger.info(f\"   - Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n","    logger.info(f\"   - LSTM hidden dimension: 256\")\n","    logger.info(f\"   - GRU hidden dimension: 256\")\n","    logger.info(f\"   - Number of layers: 2\")\n","\n","    # Initialize trainer with class weights\n","    trainer = LSTMGRUTrainer(model, train_dataset.get_class_weights())\n","\n","    # Start training process\n","    best_f1 = trainer.train(train_loader, val_loader, epochs=EPOCHS)\n","\n","    # Load best model for final evaluation\n","    checkpoint = torch.load(\"lstm_gru_hybrid_best_model.pth\")\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    # Final validation evaluation\n","    val_loss, val_acc, val_f1, val_preds, val_targets = trainer.validate(val_loader)\n","\n","    # Final test evaluation\n","    test_loss, test_acc, test_f1, test_preds, test_targets = trainer.validate(test_loader)\n","\n","    # Calculate training analysis metrics\n","    final_train_acc = trainer.train_accuracies[-1]\n","    final_val_acc = trainer.val_accuracies[-1]\n","    accuracy_gap = final_train_acc - final_val_acc\n","\n","    logger.info(\"🎯 LSTM-GRU Hybrid Final Results:\")\n","    logger.info(f\"   📊 VALIDATION:\")\n","    logger.info(f\"     - Accuracy: {val_acc:.1f}%\")\n","    logger.info(f\"     - F1 Score: {val_f1:.3f}\")\n","    logger.info(f\"   📊 TEST:\")\n","    logger.info(f\"     - Accuracy: {test_acc:.1f}%\")\n","    logger.info(f\"     - F1 Score: {test_f1:.3f}\")\n","    logger.info(f\"   📊 OVERFITTING ANALYSIS:\")\n","    logger.info(f\"     - Train-Validation Gap: {accuracy_gap:.1f}%\")\n","\n","    # Detailed classification reports\n","    target_names = train_dataset.get_label_encoder().classes_\n","\n","    print(\"\\n📊 VALIDATION Classification Report:\")\n","    print(\"=\"*60)\n","    print(classification_report(val_targets, val_preds, target_names=target_names))\n","\n","    print(\"\\n📊 TEST Classification Report:\")\n","    print(\"=\"*60)\n","    print(classification_report(test_targets, test_preds, target_names=target_names))\n","\n","    # Generate confusion matrices for both validation and test\n","    plot_confusion_matrices(val_targets, val_preds, test_targets, test_preds, target_names)\n","\n","    # Plot comprehensive training results\n","    plot_training_results(trainer, \"LSTM_GRU_Hybrid\")\n","\n","    # Visualize dual attention weights for model interpretability\n","    logger.info(\"🔍 Generating dual attention weight visualizations...\")\n","    visualize_dual_attention_weights(model, test_loader, target_names, trainer.device, num_samples=3)\n","\n","    logger.info(\"✅ LSTM-GRU Hybrid training completed successfully!\")\n","    logger.info(f\"📁 Files saved:\")\n","    logger.info(f\"   - lstm_gru_hybrid_best_model.pth: Best model checkpoint\")\n","    logger.info(f\"   - lstm_gru_hybrid_confusion_matrices.png: Confusion matrices\")\n","    logger.info(f\"   - lstm_gru_hybrid_training_results.png: Training curves\")\n","    logger.info(f\"   - lstm_gru_hybrid_attention_weights.png: Attention visualizations\")\n","\n","    return trainer, model, train_dataset, val_targets, val_preds, test_targets, test_preds\n","\n","if __name__ == \"__main__\":\n","    trainer, model, dataset, val_targets, val_preds, test_targets, test_preds = main()"],"metadata":{"id":"N4xv8RDLnAgf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#4-residual lstm\n","\n","# Enhanced Deep Learning Model for Diver Sign Language Recognition\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import os\n","import logging\n","import random\n","from collections import Counter\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Logging setup\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","def set_seed(seed=42):\n","    \"\"\"Set random seeds for reproducibility\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","class EnhancedDiverSignDataset(Dataset):\n","    \"\"\"Enhanced dataset with advanced augmentation and intelligent balancing\"\"\"\n","    def __init__(self, sequences, labels, label_encoder=None, scaler=None,\n","                 train_mode=True, augment_prob=0.4):\n","\n","        # Label encoding with enhanced error handling\n","        if label_encoder is None:\n","            self.label_encoder = LabelEncoder()\n","            encoded_labels = self.label_encoder.fit_transform(labels)\n","        else:\n","            self.label_encoder = label_encoder\n","            encoded_labels = self.label_encoder.transform(labels)\n","\n","        # Advanced scaling with robust normalization\n","        if scaler is None:\n","            self.scaler = StandardScaler()\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.fit_transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","        else:\n","            self.scaler = scaler\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","\n","        self.sequences = torch.FloatTensor(scaled_sequences)\n","        self.labels = torch.LongTensor(encoded_labels)\n","        self.train_mode = train_mode\n","        self.augment_prob = augment_prob\n","\n","        # Enhanced class weights using effective number of samples\n","        class_counts = Counter(encoded_labels)\n","        total_samples = len(encoded_labels)\n","\n","        # Calculate effective number of samples for better class weighting\n","        beta = 0.999\n","        effective_nums = [(1 - beta**class_counts[i]) / (1 - beta) for i in range(len(class_counts))]\n","        weights = [1.0 / effective_nums[i] for i in range(len(class_counts))]\n","\n","        # Normalize weights for balanced training\n","        sum_weights = sum(weights)\n","        self.class_weights = torch.FloatTensor([w * len(weights) / sum_weights for w in weights])\n","\n","        # Store class indices for intelligent sampling\n","        self.class_indices = {}\n","        for i, label in enumerate(encoded_labels):\n","            if label not in self.class_indices:\n","                self.class_indices[label] = []\n","            self.class_indices[label].append(i)\n","\n","        logger.info(f\"Dataset created: {len(self.sequences)} samples, {len(class_counts)} classes\")\n","        logger.info(f\"Class distribution: {dict(class_counts)}\")\n","\n","    def __len__(self):\n","        # Oversample minority classes during training for better balance\n","        if self.train_mode:\n","            return len(self.sequences) + len(self.sequences) // 3\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        # Intelligent balanced sampling for training\n","        if self.train_mode and idx >= len(self.sequences):\n","            # Sample from minority classes more frequently\n","            class_sizes = [(k, len(v)) for k, v in self.class_indices.items()]\n","            minority_threshold = np.median([size for _, size in class_sizes])\n","            minority_classes = [k for k, size in class_sizes if size <= minority_threshold]\n","\n","            if minority_classes and random.random() < 0.7:\n","                selected_class = random.choice(minority_classes)\n","                idx = random.choice(self.class_indices[selected_class])\n","            else:\n","                idx = random.randint(0, len(self.sequences) - 1)\n","        else:\n","            idx = idx % len(self.sequences)\n","\n","        sequence = self.sequences[idx].clone()\n","        label = self.labels[idx]\n","\n","        # Apply enhanced augmentation for better generalization\n","        if self.train_mode and random.random() < self.augment_prob:\n","            sequence = self._apply_enhanced_augmentation(sequence, label)\n","\n","        return sequence, label\n","\n","    def _apply_enhanced_augmentation(self, sequence, label):\n","        \"\"\"Apply multiple sophisticated augmentation techniques\"\"\"\n","        aug_types = random.sample(['noise', 'smooth', 'scale', 'shift'], k=random.randint(1, 2))\n","\n","        for aug_type in aug_types:\n","            if aug_type == 'noise':\n","                # Adaptive noise based on sequence statistics\n","                seq_std = torch.std(sequence, dim=0, keepdim=True)\n","                noise = torch.randn_like(sequence) * seq_std * 0.02\n","                sequence = sequence + noise\n","\n","            elif aug_type == 'smooth':\n","                # Temporal smoothing with Gaussian kernel\n","                kernel_size = 3\n","                sequence_padded = F.pad(sequence.transpose(0, 1), (1, 1), mode='reflect')\n","                smoothed = F.avg_pool1d(sequence_padded.unsqueeze(0), kernel_size, stride=1, padding=0)\n","                sequence = smoothed.squeeze(0).transpose(0, 1)\n","\n","            elif aug_type == 'scale':\n","                # Feature-wise scaling for robustness\n","                scale_factors = torch.normal(1.0, 0.03, size=(1, sequence.size(1)))\n","                sequence = sequence * scale_factors.clamp(0.95, 1.05)\n","\n","            elif aug_type == 'shift':\n","                # Temporal shifting for invariance\n","                shift = random.randint(-5, 5)\n","                sequence = torch.roll(sequence, shift, dims=0)\n","\n","        return sequence\n","\n","    def get_label_encoder(self):\n","        return self.label_encoder\n","\n","    def get_scaler(self):\n","        return self.scaler\n","\n","    def get_class_weights(self):\n","        return self.class_weights\n","\n","class EnhancedDeepModel(nn.Module):\n","    \"\"\"Enhanced deep learning model with superior capacity and regularization\"\"\"\n","    def __init__(self, input_dim=69, hidden_dim=160, num_classes=12, dropout=0.25):\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","        self.num_classes = num_classes\n","\n","        # Enhanced input processing with residual connections\n","        self.input_norm = nn.LayerNorm(input_dim)\n","        self.input_projection = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout * 0.5),\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout)\n","        )\n","\n","        # Input skip connection for gradient flow\n","        self.input_skip = nn.Linear(input_dim, hidden_dim)\n","\n","        # Enhanced LSTM with increased capacity\n","        self.lstm = nn.LSTM(\n","            input_size=hidden_dim,\n","            hidden_size=hidden_dim,\n","            num_layers=3,\n","            batch_first=True,\n","            dropout=dropout,\n","            bidirectional=True\n","        )\n","\n","        # Multi-head attention for superior representation learning\n","        self.multihead_attention = nn.MultiheadAttention(\n","            embed_dim=hidden_dim * 2,\n","            num_heads=8,\n","            dropout=dropout,\n","            batch_first=True\n","        )\n","\n","        # Enhanced attention pooling mechanism\n","        self.attention_pool = nn.Sequential(\n","            nn.Linear(hidden_dim * 2, hidden_dim),\n","            nn.Tanh(),\n","            nn.Dropout(dropout * 0.5),\n","            nn.Linear(hidden_dim, 1, bias=False)\n","        )\n","\n","        # Advanced classifier with batch normalization\n","        self.classifier = nn.Sequential(\n","            nn.LayerNorm(hidden_dim * 2),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim * 2, hidden_dim),\n","            nn.GELU(),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Dropout(dropout * 0.7),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.GELU(),\n","            nn.BatchNorm1d(hidden_dim // 2),\n","            nn.Dropout(dropout * 0.5),\n","            nn.Linear(hidden_dim // 2, num_classes)\n","        )\n","\n","        # Initialize weights with proper strategies\n","        self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        \"\"\"Advanced weight initialization for optimal training\"\"\"\n","        for name, param in self.named_parameters():\n","            if param.dim() >= 2:\n","                if 'lstm' in name and 'weight' in name:\n","                    nn.init.orthogonal_(param)\n","                elif 'weight' in name and 'norm' not in name and 'batch' not in name:\n","                    nn.init.xavier_uniform_(param)\n","            elif 'bias' in name:\n","                nn.init.zeros_(param)\n","                if 'lstm' in name and 'bias_hh' in name:\n","                    n = param.size(0)\n","                    param.data[n//4:n//2].fill_(1.0)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass through the enhanced model\n","        Args:\n","            x: Input tensor of shape [batch_size, seq_len, input_dim]\n","        Returns:\n","            output: Classification logits\n","        \"\"\"\n","        batch_size, seq_len, features = x.shape\n","\n","        # Enhanced input processing with residual connections\n","        x_norm = self.input_norm(x)\n","        x_proj = self.input_projection(x_norm)\n","        x_skip = self.input_skip(x_norm)\n","        x_input = x_proj + x_skip\n","\n","        # LSTM processing for sequential modeling\n","        lstm_out, _ = self.lstm(x_input)\n","\n","        # Multi-head self-attention for enhanced representation\n","        attn_out, _ = self.multihead_attention(lstm_out, lstm_out, lstm_out)\n","\n","        # Combine LSTM and attention outputs\n","        combined = lstm_out + attn_out\n","\n","        # Attention pooling for sequence aggregation\n","        attn_scores = self.attention_pool(combined).squeeze(-1)\n","        attn_weights = F.softmax(attn_scores, dim=1)\n","\n","        # Weighted pooling to create final representation\n","        pooled = torch.bmm(attn_weights.unsqueeze(1), combined).squeeze(1)\n","\n","        # Final classification\n","        output = self.classifier(pooled)\n","\n","        return output\n","\n","class EnhancedModelTrainer:\n","    \"\"\"Enhanced trainer with advanced loss functions and optimization strategies\"\"\"\n","    def __init__(self, model, class_weights=None, device='cuda' if torch.cuda.is_available() else 'cpu'):\n","        self.model = model\n","        self.device = device\n","        self.model.to(device)\n","\n","        # Enhanced loss function with class balancing\n","        if class_weights is not None:\n","            class_weights = class_weights.to(device)\n","\n","        self.criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n","\n","        # Advanced optimizer with different learning rates for different components\n","        self.optimizer = optim.AdamW([\n","            {'params': [p for n, p in model.named_parameters() if 'classifier' in n], 'lr': 2e-3},\n","            {'params': [p for n, p in model.named_parameters() if 'lstm' in n], 'lr': 8e-4},\n","            {'params': [p for n, p in model.named_parameters() if 'attention' in n], 'lr': 1e-3},\n","            {'params': [p for n, p in model.named_parameters() if not any(x in n for x in ['classifier', 'lstm', 'attention'])], 'lr': 1e-3}\n","        ], weight_decay=1e-4, betas=(0.9, 0.95))\n","\n","        # Enhanced scheduler with cosine annealing warm restarts\n","        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","            self.optimizer, T_0=15, T_mult=2, eta_min=1e-6\n","        )\n","\n","        # Comprehensive metrics tracking\n","        self.train_losses = []\n","        self.val_losses = []\n","        self.train_accuracies = []\n","        self.val_accuracies = []\n","        self.val_f1_scores = []\n","\n","    def focal_loss(self, pred, target, alpha=1.0, gamma=2.0):\n","        \"\"\"Focal loss implementation for handling hard examples\"\"\"\n","        ce_loss = F.cross_entropy(pred, target, reduction='none')\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = alpha * (1 - pt) ** gamma * ce_loss\n","        return focal_loss.mean()\n","\n","    def train_epoch(self, dataloader):\n","        \"\"\"Enhanced training epoch with focal loss integration\"\"\"\n","        self.model.train()\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","\n","        for batch_idx, (data, target) in enumerate(tqdm(dataloader, desc=\"Training\")):\n","            data, target = data.to(self.device), target.to(self.device)\n","\n","            self.optimizer.zero_grad()\n","\n","            output = self.model(data)\n","\n","            # Combined loss: CrossEntropy + Focal Loss for better hard example handling\n","            ce_loss = self.criterion(output, target)\n","            focal_loss = self.focal_loss(output, target, alpha=2.0, gamma=2.0)\n","            loss = 0.7 * ce_loss + 0.3 * focal_loss\n","\n","            # L2 regularization for preventing overfitting\n","            l2_reg = sum(param.pow(2).sum() for param in self.model.parameters())\n","            loss = loss + 1e-5 * l2_reg\n","\n","            loss.backward()\n","\n","            # Gradient clipping for training stability\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.5)\n","\n","            self.optimizer.step()\n","\n","            # Statistics tracking\n","            total_loss += loss.item()\n","            _, predicted = output.max(1)\n","            total += target.size(0)\n","            correct += predicted.eq(target).sum().item()\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_targets.extend(target.cpu().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","\n","        return avg_loss, accuracy, f1\n","\n","    def validate(self, dataloader):\n","        \"\"\"Standard validation with comprehensive metrics\"\"\"\n","        self.model.eval()\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","\n","        with torch.no_grad():\n","            for data, target in tqdm(dataloader, desc=\"Validating\"):\n","                data, target = data.to(self.device), target.to(self.device)\n","\n","                output = self.model(data)\n","                loss = self.criterion(output, target)\n","\n","                total_loss += loss.item()\n","                _, predicted = output.max(1)\n","                total += target.size(0)\n","                correct += predicted.eq(target).sum().item()\n","\n","                all_preds.extend(predicted.cpu().numpy())\n","                all_targets.extend(target.cpu().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","\n","        return avg_loss, accuracy, f1, all_preds, all_targets\n","\n","    def train(self, train_loader, val_loader, epochs=150):\n","        \"\"\"Enhanced training loop with comprehensive monitoring\"\"\"\n","        best_val_f1 = 0\n","        patience = 20\n","        patience_counter = 0\n","\n","        logger.info(f\"🚀 Enhanced Model Training Started: {epochs} epochs\")\n","\n","        for epoch in range(epochs):\n","            train_loss, train_acc, train_f1 = self.train_epoch(train_loader)\n","            val_loss, val_acc, val_f1, _, _ = self.validate(val_loader)\n","\n","            # Learning rate scheduling\n","            self.scheduler.step()\n","\n","            # Save comprehensive metrics\n","            self.train_losses.append(train_loss)\n","            self.val_losses.append(val_loss)\n","            self.train_accuracies.append(train_acc)\n","            self.val_accuracies.append(val_acc)\n","            self.val_f1_scores.append(val_f1)\n","\n","            # Regular progress logging\n","            if (epoch + 1) % 5 == 0:\n","                logger.info(f'Epoch {epoch+1}/{epochs}:')\n","                logger.info(f'  Train: Loss={train_loss:.3f}, Acc={train_acc:.1f}%, F1={train_f1:.3f}')\n","                logger.info(f'  Val:   Loss={val_loss:.3f}, Acc={val_acc:.1f}%, F1={val_f1:.3f}')\n","                logger.info(f'  LR: {self.optimizer.param_groups[0][\"lr\"]:.2e}')\n","\n","            # Save best model based on validation F1\n","            if val_f1 > best_val_f1:\n","                best_val_f1 = val_f1\n","                torch.save({\n","                    'model_state_dict': self.model.state_dict(),\n","                    'epoch': epoch,\n","                    'val_f1': val_f1,\n","                    'model_type': 'Enhanced_Deep_Model'\n","                }, \"enhanced_deep_model_best.pth\")\n","                logger.info(f\"  ✅ New best model saved: F1={val_f1:.3f}\")\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","\n","            # Early stopping for optimal training\n","            if patience_counter >= patience:\n","                logger.info(f\"Early stopping triggered at epoch {epoch+1}\")\n","                break\n","\n","        logger.info(f\"🎯 Training completed. Best F1 Score: {best_val_f1:.3f}\")\n","        return best_val_f1\n","\n","def plot_comprehensive_training_results(trainer, model_name=\"Enhanced_Deep_Model\"):\n","    \"\"\"Plot comprehensive training results and analysis\"\"\"\n","    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n","\n","    epochs = range(1, len(trainer.train_losses) + 1)\n","\n","    # Loss curves with enhanced styling\n","    ax1.plot(epochs, trainer.train_losses, 'b-', label='Training Loss', linewidth=2)\n","    ax1.plot(epochs, trainer.val_losses, 'r-', label='Validation Loss', linewidth=2)\n","    ax1.set_title(f'{model_name} - Loss Curves')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.legend()\n","    ax1.grid(True, alpha=0.3)\n","\n","    # Accuracy curves with detailed visualization\n","    ax2.plot(epochs, trainer.train_accuracies, 'b-', label='Training Accuracy', linewidth=2)\n","    ax2.plot(epochs, trainer.val_accuracies, 'r-', label='Validation Accuracy', linewidth=2)\n","    ax2.set_title(f'{model_name} - Accuracy Curves')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel('Accuracy (%)')\n","    ax2.legend()\n","    ax2.grid(True, alpha=0.3)\n","\n","    # F1 Score progression\n","    ax3.plot(epochs, trainer.val_f1_scores, 'green', linewidth=2)\n","    ax3.set_title(f'{model_name} - Validation F1 Score')\n","    ax3.set_xlabel('Epoch')\n","    ax3.set_ylabel('F1 Score')\n","    ax3.grid(True, alpha=0.3)\n","\n","    # Overfitting analysis through train-validation gap\n","    gaps = [t - v for t, v in zip(trainer.train_accuracies, trainer.val_accuracies)]\n","    ax4.plot(epochs, gaps, 'purple', linewidth=2)\n","    ax4.axhline(y=10, color='orange', linestyle='--', label='Warning Threshold')\n","    ax4.axhline(y=5, color='green', linestyle='--', label='Good Threshold')\n","    ax4.set_title(f'{model_name} - Train-Validation Gap Analysis')\n","    ax4.set_xlabel('Epoch')\n","    ax4.set_ylabel('Accuracy Gap (%)')\n","    ax4.legend()\n","    ax4.grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.savefig(f'{model_name.lower()}_comprehensive_results.png', dpi=150)\n","    plt.show()\n","\n","def prepare_balanced_dataset(csv_path, sequence_length=150, overlap_ratio=0.3):\n","    \"\"\"Prepare balanced dataset with intelligent preprocessing\"\"\"\n","    logger.info(f\"📊 Loading data from: {csv_path}\")\n","\n","    df = pd.read_csv(csv_path)\n","    feature_columns = [col for col in df.columns if col != 'class']\n","\n","    # Advanced data cleaning\n","    df[feature_columns] = df[feature_columns].fillna(method='ffill').fillna(0)\n","    df[feature_columns] = df[feature_columns].replace([np.inf, -np.inf], 0)\n","\n","    # Filter classes with sufficient data for reliable training\n","    min_samples = sequence_length * 3\n","    class_counts = df['class'].value_counts()\n","    valid_classes = class_counts[class_counts >= min_samples].index\n","    df = df[df['class'].isin(valid_classes)]\n","\n","    logger.info(f\"Valid classes after filtering: {list(valid_classes)}\")\n","    logger.info(f\"Class distribution: {dict(class_counts[valid_classes])}\")\n","\n","    sequences = []\n","    labels = []\n","\n","    # Create overlapping sequences for data augmentation\n","    stride = int(sequence_length * (1 - overlap_ratio))\n","\n","    for class_name in valid_classes:\n","        class_data = df[df['class'] == class_name].reset_index(drop=True)\n","\n","        for i in range(0, len(class_data) - sequence_length + 1, stride):\n","            sequence = class_data.iloc[i:i+sequence_length][feature_columns].values\n","\n","            if len(sequence) == sequence_length:\n","                sequences.append(sequence)\n","                labels.append(class_name)\n","\n","    sequences = np.array(sequences)\n","    logger.info(f\"Total sequences created: {len(sequences)}\")\n","    logger.info(f\"Final distribution: {dict(Counter(labels))}\")\n","\n","    return sequences, labels, len(feature_columns)\n","\n","def plot_confusion_matrices(val_targets, val_preds, test_targets, test_preds, target_names):\n","    \"\"\"Plot enhanced confusion matrices for both validation and test sets\"\"\"\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n","\n","    # Validation Confusion Matrix\n","    cm_val = confusion_matrix(val_targets, val_preds)\n","    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=target_names, yticklabels=target_names, ax=ax1)\n","    ax1.set_title('Validation Confusion Matrix', fontsize=16, fontweight='bold')\n","    ax1.set_ylabel('True Label', fontsize=12)\n","    ax1.set_xlabel('Predicted Label', fontsize=12)\n","    ax1.tick_params(axis='x', rotation=45)\n","\n","    # Test Confusion Matrix\n","    cm_test = confusion_matrix(test_targets, test_preds)\n","    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens',\n","                xticklabels=target_names, yticklabels=target_names, ax=ax2)\n","    ax2.set_title('Test Confusion Matrix', fontsize=16, fontweight='bold')\n","    ax2.set_ylabel('True Label', fontsize=12)\n","    ax2.set_xlabel('Predicted Label', fontsize=12)\n","    ax2.tick_params(axis='x', rotation=45)\n","\n","    plt.tight_layout()\n","    plt.savefig('enhanced_deep_model_confusion_matrices.png', dpi=150)\n","    plt.show()\n","\n","def main():\n","    set_seed(42)\n","\n","    # Enhanced configuration parameters\n","    CSV_PATH = \"/content/drive/MyDrive/dalgic_egitim/dataset.csv\"  # Update with your dataset path\n","    SEQUENCE_LENGTH = 150\n","    BATCH_SIZE = 32\n","    EPOCHS = 150             # Extended training epochs\n","    VAL_SIZE = 0.15          # 15% for validation\n","    TEST_SIZE = 0.15         # 15% for test (70% remaining for training)\n","\n","    logger.info(\"🚀 Enhanced Deep Learning Model Training Started!\")\n","    logger.info(f\"📊 Data split: 70% Train, 15% Validation, 15% Test\")\n","    logger.info(\"=\"*60)\n","\n","    # Advanced data preparation with intelligent preprocessing\n","    sequences, labels, feature_count = prepare_balanced_dataset(\n","        CSV_PATH, SEQUENCE_LENGTH, overlap_ratio=0.3\n","    )\n","\n","    if len(sequences) == 0:\n","        logger.error(\"❌ No valid sequences found!\")\n","        return\n","\n","    # First split: train+val (85%) and test (15%)\n","    X_temp, X_test, y_temp, y_test = train_test_split(\n","        sequences, labels, test_size=TEST_SIZE, random_state=42, stratify=labels\n","    )\n","\n","    # Second split: train (70%) and val (15%) from remaining 85%\n","    val_size_adjusted = VAL_SIZE / (1 - TEST_SIZE)  # 0.15 / 0.85 ≈ 0.176\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_temp, y_temp, test_size=val_size_adjusted, random_state=42, stratify=y_temp\n","    )\n","\n","    logger.info(f\"\\n📊 Dataset Summary:\")\n","    logger.info(f\"   - Input Features: {feature_count}\")\n","    logger.info(f\"   - Sequence Length: {SEQUENCE_LENGTH}\")\n","    logger.info(f\"   - Training sequences: {len(X_train):,} ({len(X_train)/len(sequences)*100:.1f}%)\")\n","    logger.info(f\"   - Validation sequences: {len(X_val):,} ({len(X_val)/len(sequences)*100:.1f}%)\")\n","    logger.info(f\"   - Test sequences: {len(X_test):,} ({len(X_test)/len(sequences)*100:.1f}%)\")\n","\n","    # Create enhanced datasets with advanced augmentation\n","    train_dataset = EnhancedDiverSignDataset(X_train, y_train, train_mode=True, augment_prob=0.5)\n","    val_dataset = EnhancedDiverSignDataset(\n","        X_val, y_val,\n","        train_dataset.get_label_encoder(),\n","        train_dataset.get_scaler(),\n","        train_mode=False\n","    )\n","    test_dataset = EnhancedDiverSignDataset(\n","        X_test, y_test,\n","        train_dataset.get_label_encoder(),\n","        train_dataset.get_scaler(),\n","        train_mode=False\n","    )\n","\n","    # Create optimized data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, pin_memory=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n","    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n","\n","    num_classes = len(train_dataset.get_label_encoder().classes_)\n","    class_names = train_dataset.get_label_encoder().classes_\n","\n","    logger.info(f\"   - Number of Classes: {num_classes}\")\n","    logger.info(f\"   - Class Names: {list(class_names)}\")\n","\n","    # Initialize enhanced deep learning model\n","    model = EnhancedDeepModel(\n","        input_dim=feature_count,\n","        hidden_dim=160,\n","        num_classes=num_classes,\n","        dropout=0.25\n","    )\n","\n","    total_params = sum(p.numel() for p in model.parameters())\n","    logger.info(f\"\\n🤖 Enhanced Deep Learning Model Configuration:\")\n","    logger.info(f\"   - Total Parameters: {total_params:,}\")\n","    logger.info(f\"   - Hidden Dimension: 160\")\n","    logger.info(f\"   - LSTM Layers: 3 (bidirectional)\")\n","    logger.info(f\"   - Multi-Head Attention: 8 heads\")\n","    logger.info(f\"   - Dropout Rate: 0.25\")\n","\n","    # Initialize enhanced trainer with advanced optimization\n","    trainer = EnhancedModelTrainer(\n","        model=model,\n","        class_weights=train_dataset.get_class_weights()\n","    )\n","\n","    logger.info(f\"\\n🔥 Starting Enhanced Training ({EPOCHS} epochs)...\")\n","    logger.info(\"=\"*60)\n","\n","    # Execute comprehensive training with advanced techniques\n","    best_f1 = trainer.train(train_loader, val_loader, epochs=EPOCHS)\n","\n","    # Load best model for final evaluation\n","    checkpoint = torch.load(\"enhanced_deep_model_best.pth\")\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    # Final validation evaluation\n","    val_loss, val_acc, val_f1, val_preds, val_targets = trainer.validate(val_loader)\n","\n","    # Final test evaluation\n","    test_loss, test_acc, test_f1, test_preds, test_targets = trainer.validate(test_loader)\n","\n","    logger.info(f\"\\n📊 Enhanced Model Final Results:\")\n","    logger.info(\"=\"*45)\n","    logger.info(f\"   📊 VALIDATION:\")\n","    logger.info(f\"     - Accuracy: {val_acc:.2f}%\")\n","    logger.info(f\"     - F1 Score: {val_f1:.4f}\")\n","    logger.info(f\"   📊 TEST:\")\n","    logger.info(f\"     - Accuracy: {test_acc:.2f}%\")\n","    logger.info(f\"     - F1 Score: {test_f1:.4f}\")\n","    logger.info(f\"   📊 TRAINING:\")\n","    logger.info(f\"     - Best Validation F1: {best_f1:.4f}\")\n","\n","    # Comprehensive classification reports\n","    target_names = train_dataset.get_label_encoder().classes_\n","\n","    print(f\"\\n📋 VALIDATION Classification Report:\")\n","    print(\"=\"*70)\n","    print(classification_report(val_targets, val_preds, target_names=target_names, digits=3))\n","\n","    print(f\"\\n📋 TEST Classification Report:\")\n","    print(\"=\"*70)\n","    print(classification_report(test_targets, test_preds, target_names=target_names, digits=3))\n","\n","    # Per-class performance analysis\n","    per_class_f1 = f1_score(test_targets, test_preds, average=None)\n","\n","    print(f\"\\n📊 Per-Class Performance Analysis:\")\n","    print(\"=\"*60)\n","    print(f\"{'Class':<20} {'F1-Score':<10} {'Performance Status':<20}\")\n","    print(\"-\" * 60)\n","\n","    for i, (class_name, f1_score_val) in enumerate(zip(class_names, per_class_f1)):\n","        if f1_score_val >= 0.85:\n","            status = \"🟢 Excellent\"\n","        elif f1_score_val >= 0.75:\n","            status = \"🟡 Good\"\n","        elif f1_score_val >= 0.65:\n","            status = \"🟠 Fair\"\n","        else:\n","            status = \"🔴 Needs Improvement\"\n","\n","        print(f\"{class_name:<20} {f1_score_val:<10.3f} {status:<20}\")\n","\n","    # Generate enhanced confusion matrices for both validation and test\n","    plot_confusion_matrices(val_targets, val_preds, test_targets, test_preds, target_names)\n","\n","    # Plot comprehensive training results\n","    plot_comprehensive_training_results(trainer, \"Enhanced_Deep_Model\")\n","\n","    # Enhanced confusion matrix with percentages\n","    plt.figure(figsize=(14, 10))\n","    cm = confusion_matrix(test_targets, test_preds)\n","\n","    # Calculate percentages for better visualization\n","    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n","\n","    # Create enhanced heatmap\n","    sns.heatmap(\n","        cm_percent,\n","        annot=True,\n","        fmt='.1f',\n","        cmap='RdYlBu_r',\n","        xticklabels=class_names,\n","        yticklabels=class_names,\n","        cbar_kws={'label': 'Percentage (%)'},\n","        linewidths=0.5\n","    )\n","\n","    plt.title('Enhanced Deep Model - Test Confusion Matrix (%)', fontsize=18, fontweight='bold', pad=20)\n","    plt.xlabel('Predicted Label', fontsize=14)\n","    plt.ylabel('True Label', fontsize=14)\n","    plt.xticks(rotation=45, ha='right')\n","    plt.yticks(rotation=0)\n","\n","    # Add comprehensive model information\n","    model_info = (f'Enhanced Deep Model | Parameters: {total_params:,} | '\n","                  f'Accuracy: {test_acc:.1f}% | F1: {test_f1:.3f}')\n","    plt.figtext(0.02, 0.02, model_info, fontsize=11,\n","                bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='lightgreen', alpha=0.8))\n","\n","    plt.tight_layout()\n","    plt.savefig('enhanced_deep_model_detailed_confusion_matrix.png', dpi=150, bbox_inches='tight')\n","    plt.show()\n","\n","    # Calculate training-validation gap for overfitting analysis\n","    final_train_acc = trainer.train_accuracies[-1]\n","    final_val_acc = trainer.val_accuracies[-1]\n","    accuracy_gap = final_train_acc - final_val_acc\n","\n","    # Comprehensive model performance summary\n","    logger.info(f\"\\n🏆 ENHANCED MODEL PERFORMANCE SUMMARY:\")\n","    logger.info(\"=\"*50)\n","    logger.info(f\"   📈 Final Results:\")\n","    logger.info(f\"     - Test Accuracy: {test_acc:.2f}%\")\n","    logger.info(f\"     - Test F1 Score: {test_f1:.4f}\")\n","    logger.info(f\"     - Validation F1: {val_f1:.4f}\")\n","    logger.info(f\"   📊 Training Analysis:\")\n","    logger.info(f\"     - Train-Validation Gap: {accuracy_gap:.1f}%\")\n","    logger.info(f\"     - Total Parameters: {total_params:,}\")\n","    logger.info(f\"     - Training Epochs: {len(trainer.train_losses)}\")\n","\n","    # Performance status assessment\n","    if test_f1 >= 0.85:\n","        performance_status = \"🎉 Excellent Performance Achieved!\"\n","    elif test_f1 >= 0.75:\n","        performance_status = \"✅ Good Performance Achieved!\"\n","    elif test_f1 >= 0.65:\n","        performance_status = \"👍 Satisfactory Performance\"\n","    else:\n","        performance_status = \"⚠️ Performance Needs Improvement\"\n","\n","    logger.info(f\"   🎯 Overall Assessment: {performance_status}\")\n","\n","    # Overfitting analysis\n","    if accuracy_gap <= 5:\n","        overfitting_status = \"🟢 No Overfitting Detected\"\n","    elif accuracy_gap <= 10:\n","        overfitting_status = \"🟡 Mild Overfitting\"\n","    else:\n","        overfitting_status = \"🔴 Significant Overfitting Detected\"\n","\n","    logger.info(f\"   📉 Overfitting Status: {overfitting_status}\")\n","\n","    logger.info(\"\\n✅ Enhanced Deep Learning Model training completed successfully!\")\n","    logger.info(f\"📁 Files saved:\")\n","    logger.info(f\"   - enhanced_deep_model_best.pth: Best model checkpoint\")\n","    logger.info(f\"   - enhanced_deep_model_confusion_matrices.png: Dual confusion matrices\")\n","    logger.info(f\"   - enhanced_deep_model_comprehensive_results.png: Training curves\")\n","    logger.info(f\"   - enhanced_deep_model_detailed_confusion_matrix.png: Detailed test matrix\")\n","\n","    return trainer, model, train_dataset, val_targets, val_preds, test_targets, test_preds\n","\n","if __name__ == \"__main__\":\n","    trainer, model, dataset, val_targets, val_preds, test_targets, test_preds = main()"],"metadata":{"id":"VtPNeWOgq66o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5-TPA-Net (Temporal Pyramid Attention Network) for Diver Sign Language Recognition\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import os\n","import logging\n","import random\n","from collections import Counter\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Logging setup\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","def set_seed(seed=42):\n","    \"\"\"Set random seeds for reproducibility\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","class AdvancedDiverSignDataset(Dataset):\n","    \"\"\"Advanced dataset with sophisticated augmentation techniques\"\"\"\n","    def __init__(self, sequences, labels, label_encoder=None, scaler=None,\n","                 noise_std=0.005, train_mode=True, augment_prob=0.3):\n","\n","        # Label encoding with error handling\n","        if label_encoder is None:\n","            self.label_encoder = LabelEncoder()\n","            encoded_labels = self.label_encoder.fit_transform(labels)\n","        else:\n","            self.label_encoder = label_encoder\n","            encoded_labels = self.label_encoder.transform(labels)\n","\n","        # Robust data scaling\n","        if scaler is None:\n","            self.scaler = StandardScaler()\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.fit_transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","        else:\n","            self.scaler = scaler\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","\n","        self.sequences = torch.FloatTensor(scaled_sequences)\n","        self.labels = torch.LongTensor(encoded_labels)\n","        self.noise_std = noise_std\n","        self.train_mode = train_mode\n","        self.augment_prob = augment_prob\n","\n","        # Calculate class weights for imbalanced data handling\n","        class_counts = Counter(encoded_labels)\n","        total_samples = len(encoded_labels)\n","        self.class_weights = torch.FloatTensor([\n","            total_samples / (len(class_counts) * class_counts[i])\n","            for i in range(len(class_counts))\n","        ])\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        sequence = self.sequences[idx].clone()\n","        label = self.labels[idx]\n","\n","        # Apply advanced augmentation during training\n","        if self.train_mode and random.random() < self.augment_prob:\n","            sequence = self._apply_advanced_augmentation(sequence)\n","\n","        return sequence, label\n","\n","    def _apply_advanced_augmentation(self, sequence):\n","        \"\"\"Apply sophisticated sequence augmentation techniques\"\"\"\n","        aug_type = random.choice(['noise', 'scale', 'shift', 'dropout', 'mixup'])\n","\n","        if aug_type == 'noise':\n","            # Adaptive noise based on sequence variance\n","            seq_std = sequence.std(dim=0, keepdim=True)\n","            noise = torch.randn_like(sequence) * seq_std * 0.02\n","            sequence = sequence + noise\n","\n","        elif aug_type == 'scale':\n","            # Feature-wise random scaling for robustness\n","            scale_factors = torch.normal(1.0, 0.02, size=(1, sequence.size(1)))\n","            sequence = sequence * scale_factors\n","\n","        elif aug_type == 'shift':\n","            # Temporal shifting with circular padding\n","            shift = random.randint(-5, 5)\n","            sequence = torch.roll(sequence, shift, dims=0)\n","\n","        elif aug_type == 'dropout':\n","            # Structured dropout (entire time steps)\n","            mask = torch.rand(sequence.size(0), 1) > 0.05\n","            sequence = sequence * mask\n","\n","        elif aug_type == 'mixup':\n","            # Temporal mixup within sequence for regularization\n","            alpha = 0.2\n","            lam = np.random.beta(alpha, alpha)\n","            rand_idx = torch.randperm(sequence.size(0))\n","            sequence = lam * sequence + (1 - lam) * sequence[rand_idx]\n","\n","        return sequence\n","\n","    def get_label_encoder(self):\n","        return self.label_encoder\n","\n","    def get_scaler(self):\n","        return self.scaler\n","\n","    def get_class_weights(self):\n","        return self.class_weights\n","\n","class TemporalPyramidBlock(nn.Module):\n","    \"\"\"Temporal Pyramid Block - captures multi-scale temporal patterns\"\"\"\n","    def __init__(self, input_dim, hidden_dim, scales=[1, 3, 5, 7], dropout=0.2):\n","        super().__init__()\n","\n","        self.scales = scales\n","        self.hidden_dim = hidden_dim\n","\n","        # Multi-scale convolutions for different temporal receptive fields\n","        self.conv_layers = nn.ModuleList()\n","        for scale in scales:\n","            conv_block = nn.Sequential(\n","                nn.Conv1d(input_dim, hidden_dim // len(scales),\n","                         kernel_size=scale, padding=scale//2),\n","                nn.BatchNorm1d(hidden_dim // len(scales)),\n","                nn.GELU(),\n","                nn.Dropout(dropout)\n","            )\n","            self.conv_layers.append(conv_block)\n","\n","        # Global average pooling branch for long-range dependencies\n","        self.global_branch = nn.Sequential(\n","            nn.AdaptiveAvgPool1d(1),\n","            nn.Conv1d(input_dim, hidden_dim // len(scales), 1),\n","            nn.GELU()\n","        )\n","\n","        # Feature fusion layer\n","        total_channels = hidden_dim + hidden_dim // len(scales)\n","        self.fusion = nn.Sequential(\n","            nn.Conv1d(total_channels, hidden_dim, 1),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout)\n","        )\n","\n","        # Squeeze-and-Excitation attention mechanism\n","        self.se = nn.Sequential(\n","            nn.AdaptiveAvgPool1d(1),\n","            nn.Conv1d(hidden_dim, hidden_dim // 4, 1),\n","            nn.ReLU(),\n","            nn.Conv1d(hidden_dim // 4, hidden_dim, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass through temporal pyramid block\n","        Args:\n","            x: Input tensor [batch, seq_len, features]\n","        Returns:\n","            Processed tensor with multi-scale temporal features\n","        \"\"\"\n","        # Transform to [batch, features, seq_len] for 1D convolution\n","        x = x.transpose(1, 2)\n","\n","        # Apply multi-scale convolutions\n","        multi_scale_features = []\n","        for conv_layer in self.conv_layers:\n","            feature = conv_layer(x)\n","            multi_scale_features.append(feature)\n","\n","        # Global branch for long-range dependencies\n","        global_feature = self.global_branch(x)\n","        global_feature = global_feature.expand(-1, -1, x.size(2))\n","\n","        # Concatenate all multi-scale features\n","        all_features = torch.cat(multi_scale_features + [global_feature], dim=1)\n","\n","        # Feature fusion\n","        fused = self.fusion(all_features)\n","\n","        # Apply Squeeze-and-Excitation attention\n","        se_weights = self.se(fused)\n","        attended = fused * se_weights\n","\n","        # Transform back to [batch, seq_len, features]\n","        return attended.transpose(1, 2)\n","\n","class CrossScaleAttention(nn.Module):\n","    \"\"\"Cross-Scale Attention mechanism for multi-resolution processing\"\"\"\n","    def __init__(self, hidden_dim, num_heads=8, dropout=0.1):\n","        super().__init__()\n","\n","        self.hidden_dim = hidden_dim\n","        self.num_heads = num_heads\n","        self.head_dim = hidden_dim // num_heads\n","\n","        # Multi-head attention components\n","        self.q_linear = nn.Linear(hidden_dim, hidden_dim)\n","        self.k_linear = nn.Linear(hidden_dim, hidden_dim)\n","        self.v_linear = nn.Linear(hidden_dim, hidden_dim)\n","\n","        # Cross-scale projections for different temporal resolutions\n","        self.scale_projections = nn.ModuleList([\n","            nn.Linear(hidden_dim, hidden_dim) for _ in range(3)\n","        ])\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.out_proj = nn.Linear(hidden_dim, hidden_dim)\n","\n","        # Scale fusion layer\n","        self.scale_fusion = nn.Sequential(\n","            nn.Linear(hidden_dim * 3, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout)\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass through cross-scale attention\n","        Args:\n","            x: Input tensor [batch_size, seq_len, hidden_dim]\n","        Returns:\n","            Attended features with cross-scale information\n","        \"\"\"\n","        batch_size, seq_len, _ = x.shape\n","\n","        # Create multi-scale representations\n","        scales = []\n","\n","        # Fine scale (original resolution)\n","        scales.append(x)\n","\n","        # Medium scale (pooled for medium-range patterns)\n","        medium = F.avg_pool1d(x.transpose(1, 2), kernel_size=3, stride=1, padding=1)\n","        scales.append(medium.transpose(1, 2))\n","\n","        # Coarse scale (more pooled for long-range patterns)\n","        coarse = F.avg_pool1d(x.transpose(1, 2), kernel_size=5, stride=1, padding=2)\n","        scales.append(coarse.transpose(1, 2))\n","\n","        # Apply scale-specific projections\n","        projected_scales = []\n","        for i, scale in enumerate(scales):\n","            projected = self.scale_projections[i](scale)\n","            projected_scales.append(projected)\n","\n","        # Cross-scale attention computation\n","        attended_scales = []\n","        for i, query_scale in enumerate(projected_scales):\n","            q = self.q_linear(query_scale).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n","\n","            # Attend to all scales for comprehensive feature extraction\n","            scale_attentions = []\n","            for key_scale in projected_scales:\n","                k = self.k_linear(key_scale).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n","                v = self.v_linear(key_scale).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n","\n","                # Scaled dot-product attention\n","                scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n","                attn_weights = F.softmax(scores, dim=-1)\n","                attn_weights = self.dropout(attn_weights)\n","\n","                attended = torch.matmul(attn_weights, v)\n","                attended = attended.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_dim)\n","                scale_attentions.append(attended)\n","\n","            # Combine attentions from all scales\n","            combined = torch.mean(torch.stack(scale_attentions), dim=0)\n","            attended_scales.append(combined)\n","\n","        # Fuse multi-scale features\n","        fused_features = torch.cat(attended_scales, dim=-1)\n","        output = self.scale_fusion(fused_features)\n","        output = self.out_proj(output)\n","\n","        return output\n","\n","class AdaptiveTemporalPooling(nn.Module):\n","    \"\"\"Adaptive temporal pooling with learnable aggregation strategies\"\"\"\n","    def __init__(self, hidden_dim, pool_sizes=[2, 4, 8]):\n","        super().__init__()\n","\n","        self.pool_sizes = pool_sizes\n","        self.hidden_dim = hidden_dim\n","\n","        # Adaptive pooling layers for different temporal granularities\n","        self.adaptive_pools = nn.ModuleList([\n","            nn.AdaptiveAvgPool1d(size) for size in pool_sizes\n","        ])\n","\n","        # Pool-specific transformations\n","        self.pool_transforms = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Linear(hidden_dim, hidden_dim),\n","                nn.GELU(),\n","                nn.Dropout(0.1)\n","            ) for _ in pool_sizes\n","        ])\n","\n","        # Attention weights for adaptive pool combination\n","        self.pool_attention = nn.Sequential(\n","            nn.Linear(hidden_dim * len(pool_sizes), hidden_dim),\n","            nn.Tanh(),\n","            nn.Linear(hidden_dim, len(pool_sizes)),\n","            nn.Softmax(dim=-1)\n","        )\n","\n","        # Final projection layer\n","        self.final_proj = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.LayerNorm(hidden_dim),\n","            nn.GELU()\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass through adaptive temporal pooling\n","        Args:\n","            x: Input tensor [batch, seq_len, hidden_dim]\n","        Returns:\n","            Pooled representation and attention weights\n","        \"\"\"\n","        batch_size = x.size(0)\n","\n","        # Apply different pooling strategies\n","        pooled_features = []\n","        for i, (pool, transform) in enumerate(zip(self.adaptive_pools, self.pool_transforms)):\n","            # Adaptive pooling\n","            pooled = pool(x.transpose(1, 2))  # [batch, hidden_dim, pool_size]\n","            pooled = pooled.transpose(1, 2)   # [batch, pool_size, hidden_dim]\n","\n","            # Global average pooling over the pool dimension\n","            pooled = pooled.mean(dim=1)  # [batch, hidden_dim]\n","\n","            # Apply transformation\n","            transformed = transform(pooled)\n","            pooled_features.append(transformed)\n","\n","        # Concatenate all pooled features\n","        all_pooled = torch.cat(pooled_features, dim=-1)  # [batch, hidden_dim * num_pools]\n","\n","        # Compute attention weights for different pooling strategies\n","        pool_weights = self.pool_attention(all_pooled)  # [batch, num_pools]\n","\n","        # Weighted combination of pooled features\n","        weighted_features = sum(w.unsqueeze(-1) * feat for w, feat in zip(pool_weights.unbind(-1), pooled_features))\n","\n","        # Final projection\n","        output = self.final_proj(weighted_features)\n","\n","        return output, pool_weights\n","\n","class TPANet(nn.Module):\n","    \"\"\"Temporal Pyramid Attention Network for advanced sequence modeling\"\"\"\n","    def __init__(self, input_dim=69, hidden_dim=256, num_classes=10,\n","                 num_layers=3, dropout=0.2):\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","        self.num_classes = num_classes\n","        self.num_layers = num_layers\n","\n","        # Input embedding with residual connection\n","        self.input_embedding = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.LayerNorm(hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout)\n","        )\n","\n","        # Stack of Temporal Pyramid Blocks\n","        self.pyramid_blocks = nn.ModuleList([\n","            TemporalPyramidBlock(hidden_dim, hidden_dim, dropout=dropout)\n","            for _ in range(num_layers)\n","        ])\n","\n","        # Cross-Scale Attention mechanism\n","        self.cross_scale_attention = CrossScaleAttention(hidden_dim, num_heads=8, dropout=dropout)\n","\n","        # Adaptive Temporal Pooling\n","        self.adaptive_pooling = AdaptiveTemporalPooling(hidden_dim)\n","\n","        # Dynamic feature selection mechanism\n","        self.feature_selector = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.GELU(),\n","            nn.Linear(hidden_dim // 2, hidden_dim),\n","            nn.Sigmoid()\n","        )\n","\n","        # Advanced classification head with uncertainty estimation\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.LayerNorm(hidden_dim // 2),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","\n","            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n","            nn.LayerNorm(hidden_dim // 4),\n","            nn.GELU(),\n","            nn.Dropout(dropout * 0.5),\n","\n","            nn.Linear(hidden_dim // 4, num_classes)\n","        )\n","\n","        # Uncertainty estimation head for confidence prediction\n","        self.uncertainty_head = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim // 4),\n","            nn.GELU(),\n","            nn.Linear(hidden_dim // 4, 1),\n","            nn.Sigmoid()\n","        )\n","\n","        self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        \"\"\"Initialize model weights using appropriate strategies\"\"\"\n","        for name, param in self.named_parameters():\n","            if param.dim() >= 2:\n","                if 'conv' in name and 'weight' in name:\n","                    nn.init.kaiming_normal_(param, mode='fan_out', nonlinearity='relu')\n","                elif 'weight' in name:\n","                    nn.init.xavier_uniform_(param)\n","            elif 'bias' in name:\n","                nn.init.constant_(param, 0)\n","\n","    def forward(self, x, return_features=False):\n","        \"\"\"\n","        Forward pass through TPA-Net\n","        Args:\n","            x: Input tensor [batch_size, seq_len, input_dim]\n","            return_features: Whether to return intermediate features\n","        Returns:\n","            logits: Classification output\n","            uncertainty: Prediction uncertainty\n","            features: Intermediate features (if requested)\n","        \"\"\"\n","        batch_size, seq_len, _ = x.shape\n","\n","        # Input embedding\n","        x = self.input_embedding(x)\n","\n","        # Apply Temporal Pyramid Blocks\n","        pyramid_features = []\n","        for block in self.pyramid_blocks:\n","            x = block(x)\n","            pyramid_features.append(x)\n","\n","        # Cross-scale attention for multi-resolution processing\n","        attended = self.cross_scale_attention(x)\n","\n","        # Adaptive temporal pooling\n","        pooled, pool_weights = self.adaptive_pooling(attended)\n","\n","        # Dynamic feature selection\n","        feature_importance = self.feature_selector(pooled)\n","        selected_features = pooled * feature_importance\n","\n","        # Classification\n","        logits = self.classifier(selected_features)\n","\n","        # Uncertainty estimation\n","        uncertainty = self.uncertainty_head(selected_features)\n","\n","        if return_features:\n","            return logits, uncertainty, {\n","                'pyramid_features': pyramid_features,\n","                'pool_weights': pool_weights,\n","                'feature_importance': feature_importance,\n","                'attended_features': attended\n","            }\n","\n","        return logits, uncertainty\n","\n","    def get_attention_analysis(self, x):\n","        \"\"\"Get comprehensive attention analysis for interpretability\"\"\"\n","        self.eval()\n","        with torch.no_grad():\n","            _, _, features = self.forward(x, return_features=True)\n","        return features\n","\n","class TPANetTrainer:\n","    \"\"\"Advanced trainer for TPA-Net with sophisticated training strategies\"\"\"\n","    def __init__(self, model, class_weights=None, device='cuda' if torch.cuda.is_available() else 'cpu'):\n","        self.model = model\n","        self.device = device\n","        self.model.to(device)\n","\n","        # Loss functions\n","        if class_weights is not None:\n","            class_weights = class_weights.to(device)\n","\n","        self.classification_criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n","        self.uncertainty_criterion = nn.MSELoss()\n","\n","        # Advanced optimizer with component-specific learning rates\n","        pyramid_params = []\n","        attention_params = []\n","        classifier_params = []\n","\n","        for name, param in model.named_parameters():\n","            if 'pyramid' in name:\n","                pyramid_params.append(param)\n","            elif 'attention' in name or 'pooling' in name:\n","                attention_params.append(param)\n","            else:\n","                classifier_params.append(param)\n","\n","        self.optimizer = optim.AdamW([\n","            {'params': pyramid_params, 'lr': 8e-4, 'weight_decay': 0.01},\n","            {'params': attention_params, 'lr': 1e-3, 'weight_decay': 0.005},\n","            {'params': classifier_params, 'lr': 1e-3, 'weight_decay': 0.01}\n","        ], betas=(0.9, 0.95))\n","\n","        # Cosine annealing with warm restarts\n","        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","            self.optimizer, T_0=30, T_mult=2, eta_min=1e-6\n","        )\n","\n","        # Comprehensive metrics tracking\n","        self.train_losses = []\n","        self.val_losses = []\n","        self.train_accuracies = []\n","        self.val_accuracies = []\n","        self.val_f1_scores = []\n","        self.uncertainty_scores = []\n","\n","    def train_epoch(self, dataloader):\n","        \"\"\"Training epoch with uncertainty-aware loss function\"\"\"\n","        self.model.train()\n","        total_loss = 0\n","        total_clf_loss = 0\n","        total_unc_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","        all_uncertainties = []\n","\n","        for batch_idx, (data, target) in enumerate(tqdm(dataloader, desc=\"Training\")):\n","            data, target = data.to(self.device), target.to(self.device)\n","\n","            self.optimizer.zero_grad()\n","\n","            # Forward pass\n","            logits, uncertainty = self.model(data)\n","\n","            # Classification loss\n","            clf_loss = self.classification_criterion(logits, target)\n","\n","            # Uncertainty loss (encourage high uncertainty for wrong predictions)\n","            pred_probs = F.softmax(logits, dim=1)\n","            pred_confidence = pred_probs.max(dim=1)[0]\n","            uncertainty_target = 1.0 - pred_confidence\n","            unc_loss = self.uncertainty_criterion(uncertainty.squeeze(), uncertainty_target.detach())\n","\n","            # Combined loss\n","            total_loss_batch = clf_loss + 0.1 * unc_loss\n","\n","            # L2 regularization\n","            l2_reg = sum(param.pow(2).sum() for param in self.model.parameters())\n","            total_loss_batch += 1e-5 * l2_reg\n","\n","            total_loss_batch.backward()\n","\n","            # Gradient clipping for training stability\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n","\n","            self.optimizer.step()\n","\n","            # Statistics tracking\n","            total_loss += total_loss_batch.item()\n","            total_clf_loss += clf_loss.item()\n","            total_unc_loss += unc_loss.item()\n","\n","            _, predicted = logits.max(1)\n","            total += target.size(0)\n","            correct += predicted.eq(target).sum().item()\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_targets.extend(target.cpu().numpy())\n","            all_uncertainties.extend(uncertainty.squeeze().cpu().detach().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        avg_clf_loss = total_clf_loss / len(dataloader)\n","        avg_unc_loss = total_unc_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","        avg_uncertainty = np.mean(all_uncertainties)\n","\n","        return avg_loss, avg_clf_loss, avg_unc_loss, accuracy, f1, avg_uncertainty\n","\n","    def validate(self, dataloader):\n","        \"\"\"Validation with comprehensive uncertainty analysis\"\"\"\n","        self.model.eval()\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","        all_uncertainties = []\n","\n","        with torch.no_grad():\n","            for data, target in tqdm(dataloader, desc=\"Validating\"):\n","                data, target = data.to(self.device), target.to(self.device)\n","\n","                logits, uncertainty = self.model(data)\n","                loss = self.classification_criterion(logits, target)\n","\n","                total_loss += loss.item()\n","                _, predicted = logits.max(1)\n","                total += target.size(0)\n","                correct += predicted.eq(target).sum().item()\n","\n","                all_preds.extend(predicted.cpu().numpy())\n","                all_targets.extend(target.cpu().numpy())\n","                all_uncertainties.extend(uncertainty.squeeze().cpu().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","        avg_uncertainty = np.mean(all_uncertainties)\n","\n","        return avg_loss, accuracy, f1, all_preds, all_targets, avg_uncertainty\n","\n","    def train(self, train_loader, val_loader, epochs=150):\n","        \"\"\"Complete training loop with advanced monitoring\"\"\"\n","        best_val_f1 = 0\n","        patience = 25\n","        patience_counter = 0\n","\n","        logger.info(f\"🚀 TPA-Net Training Started: {epochs} epochs\")\n","        logger.info(f\"   - Model Parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n","\n","        for epoch in range(epochs):\n","            # Training\n","            train_loss, clf_loss, unc_loss, train_acc, train_f1, train_unc = self.train_epoch(train_loader)\n","\n","            # Validation\n","            val_loss, val_acc, val_f1, _, _, val_unc = self.validate(val_loader)\n","\n","            # Learning rate scheduling\n","            self.scheduler.step()\n","\n","            # Calculate overfitting gap\n","            train_val_gap = train_acc - val_acc\n","\n","            # Save comprehensive metrics\n","            self.train_losses.append(train_loss)\n","            self.val_losses.append(val_loss)\n","            self.train_accuracies.append(train_acc)\n","            self.val_accuracies.append(val_acc)\n","            self.val_f1_scores.append(val_f1)\n","            self.uncertainty_scores.append(val_unc)\n","\n","            # Regular progress logging\n","            if (epoch + 1) % 10 == 0:\n","                logger.info(f'Epoch {epoch+1}/{epochs}:')\n","                logger.info(f'  Train: Loss={train_loss:.3f} (Clf={clf_loss:.3f}, Unc={unc_loss:.3f})')\n","                logger.info(f'         Acc={train_acc:.1f}%, F1={train_f1:.3f}, Unc={train_unc:.3f}')\n","                logger.info(f'  Val:   Loss={val_loss:.3f}, Acc={val_acc:.1f}%, F1={val_f1:.3f}, Unc={val_unc:.3f}')\n","                logger.info(f'  Gap: {train_val_gap:.1f}%, LR: {self.optimizer.param_groups[0][\"lr\"]:.2e}')\n","\n","            # Save best model based on validation F1\n","            if val_f1 > best_val_f1:\n","                best_val_f1 = val_f1\n","                torch.save({\n","                    'model_state_dict': self.model.state_dict(),\n","                    'epoch': epoch,\n","                    'val_f1': val_f1,\n","                    'train_val_gap': train_val_gap,\n","                    'model_type': 'TPA_Net'\n","                }, \"tpa_net_best_model.pth\")\n","                logger.info(f\"  ✅ New best model saved: F1={val_f1:.3f}, Gap={train_val_gap:.1f}%\")\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","\n","            # Early stopping for optimal training\n","            if patience_counter >= patience:\n","                logger.info(f\"Early stopping triggered at epoch {epoch+1}\")\n","                break\n","\n","        logger.info(f\"🎯 Training completed. Best F1 Score: {best_val_f1:.3f}\")\n","        return best_val_f1\n","\n","def visualize_tpa_attention(model, dataloader, class_names, device, num_samples=2):\n","    \"\"\"Visualize TPA-Net attention mechanisms for interpretability\"\"\"\n","    model.eval()\n","\n","    fig, axes = plt.subplots(num_samples, 3, figsize=(18, 6*num_samples))\n","    if num_samples == 1:\n","        axes = axes.reshape(1, -1)\n","\n","    sample_count = 0\n","    with torch.no_grad():\n","        for data, targets in dataloader:\n","            if sample_count >= num_samples:\n","                break\n","\n","            data = data.to(device)\n","\n","            for i in range(min(data.size(0), num_samples - sample_count)):\n","                single_input = data[i:i+1]\n","                target_class = targets[i].item()\n","\n","                # Get comprehensive attention analysis\n","                features = model.get_attention_analysis(single_input)\n","\n","                # Adaptive pooling weights visualization\n","                ax1 = axes[sample_count, 0]\n","                pool_weights = features['pool_weights'][0].cpu().numpy()\n","                pool_names = ['Fine', 'Medium', 'Coarse']\n","                bars = ax1.bar(pool_names, pool_weights)\n","                ax1.set_title(f'Adaptive Pooling Weights\\nClass: {class_names[target_class]}')\n","                ax1.set_ylabel('Weight')\n","                for bar, weight in zip(bars, pool_weights):\n","                    height = bar.get_height()\n","                    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n","                            f'{weight:.3f}', ha='center', va='bottom')\n","\n","                # Feature importance visualization\n","                ax2 = axes[sample_count, 1]\n","                feature_importance = features['feature_importance'][0].cpu().numpy()\n","                ax2.plot(feature_importance, linewidth=2, color='red')\n","                ax2.fill_between(range(len(feature_importance)), feature_importance, alpha=0.3, color='red')\n","                ax2.set_title(f'Dynamic Feature Importance\\nClass: {class_names[target_class]}')\n","                ax2.set_xlabel('Feature Dimension')\n","                ax2.set_ylabel('Importance Score')\n","                ax2.grid(True, alpha=0.3)\n","\n","                # Pyramid layer activations evolution\n","                ax3 = axes[sample_count, 2]\n","                pyramid_activations = []\n","                for j, pyr_feat in enumerate(features['pyramid_features']):\n","                    activation = pyr_feat[0].mean(dim=-1).cpu().numpy()  # Average over features\n","                    pyramid_activations.append(activation)\n","                    ax3.plot(activation, label=f'Layer {j+1}', alpha=0.7, linewidth=2)\n","\n","                ax3.set_title(f'Pyramid Layer Activations\\nClass: {class_names[target_class]}')\n","                ax3.set_xlabel('Time Step')\n","                ax3.set_ylabel('Activation')\n","                ax3.legend()\n","                ax3.grid(True, alpha=0.3)\n","\n","                sample_count += 1\n","                if sample_count >= num_samples:\n","                    break\n","\n","    plt.tight_layout()\n","    plt.savefig('tpa_net_attention_analysis.png', dpi=150, bbox_inches='tight')\n","    plt.show()\n","\n","def plot_comprehensive_tpa_results(trainer, model_name=\"TPA_Net\"):\n","    \"\"\"Comprehensive TPA-Net results visualization\"\"\"\n","    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n","\n","    epochs = range(1, len(trainer.train_losses) + 1)\n","\n","    # Loss curves\n","    ax = axes[0, 0]\n","    ax.plot(epochs, trainer.train_losses, 'b-', label='Training Loss', linewidth=2)\n","    ax.plot(epochs, trainer.val_losses, 'r-', label='Validation Loss', linewidth=2)\n","    ax.set_title(f'{model_name} - Loss Curves')\n","    ax.set_xlabel('Epoch')\n","    ax.set_ylabel('Loss')\n","    ax.legend()\n","    ax.grid(True, alpha=0.3)\n","\n","    # Accuracy curves\n","    ax = axes[0, 1]\n","    ax.plot(epochs, trainer.train_accuracies, 'b-', label='Training Accuracy', linewidth=2)\n","    ax.plot(epochs, trainer.val_accuracies, 'r-', label='Validation Accuracy', linewidth=2)\n","    ax.set_title(f'{model_name} - Accuracy Curves')\n","    ax.set_xlabel('Epoch')\n","    ax.set_ylabel('Accuracy (%)')\n","    ax.legend()\n","    ax.grid(True, alpha=0.3)\n","\n","    # F1 Score progression\n","    ax = axes[0, 2]\n","    ax.plot(epochs, trainer.val_f1_scores, 'green', linewidth=2)\n","    ax.set_title(f'{model_name} - Validation F1 Score')\n","    ax.set_xlabel('Epoch')\n","    ax.set_ylabel('F1 Score')\n","    ax.grid(True, alpha=0.3)\n","\n","    # Uncertainty evolution\n","    ax = axes[1, 0]\n","    ax.plot(epochs, trainer.uncertainty_scores, 'purple', linewidth=2)\n","    ax.set_title(f'{model_name} - Uncertainty Evolution')\n","    ax.set_xlabel('Epoch')\n","    ax.set_ylabel('Average Uncertainty')\n","    ax.grid(True, alpha=0.3)\n","\n","    # Overfitting analysis\n","    gaps = [t - v for t, v in zip(trainer.train_accuracies, trainer.val_accuracies)]\n","    ax = axes[1, 1]\n","    ax.plot(epochs, gaps, 'orange', linewidth=2)\n","    ax.axhline(y=10, color='red', linestyle='--', label='Warning Threshold')\n","    ax.axhline(y=5, color='green', linestyle='--', label='Good Threshold')\n","    ax.set_title(f'{model_name} - Train-Validation Gap')\n","    ax.set_xlabel('Epoch')\n","    ax.set_ylabel('Gap (%)')\n","    ax.legend()\n","    ax.grid(True, alpha=0.3)\n","\n","    # Performance summary\n","    ax = axes[1, 2]\n","    final_metrics = {\n","        'Accuracy': trainer.val_accuracies[-1],\n","        'F1 Score': trainer.val_f1_scores[-1] * 100,\n","        'Best F1': max(trainer.val_f1_scores) * 100,\n","        'Confidence': (1 - trainer.uncertainty_scores[-1]) * 100  # Convert uncertainty to confidence\n","    }\n","\n","    bars = ax.bar(final_metrics.keys(), final_metrics.values(),\n","                  color=['blue', 'green', 'gold', 'purple'], alpha=0.7)\n","    ax.set_title(f'{model_name} - Final Performance Metrics')\n","    ax.set_ylabel('Score (%)')\n","    ax.set_ylim(0, 100)\n","\n","    # Add value labels on bars\n","    for bar, value in zip(bars, final_metrics.values()):\n","        height = bar.get_height()\n","        ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n","                f'{value:.1f}%', ha='center', va='bottom')\n","\n","    plt.tight_layout()\n","    plt.savefig(f'{model_name.lower()}_comprehensive_results.png', dpi=150, bbox_inches='tight')\n","    plt.show()\n","\n","def prepare_enhanced_dataset(csv_path, sequence_length=150, overlap_ratio=0.3):\n","    \"\"\"Enhanced data preparation with comprehensive preprocessing\"\"\"\n","    logger.info(f\"📊 Loading data from: {csv_path}\")\n","\n","    df = pd.read_csv(csv_path)\n","    feature_columns = [col for col in df.columns if col != 'class']\n","\n","    # Advanced data cleaning\n","    original_size = len(df)\n","    df[feature_columns] = df[feature_columns].fillna(method='ffill').fillna(method='bfill').fillna(0)\n","    df[feature_columns] = df[feature_columns].replace([np.inf, -np.inf], 0)\n","\n","    # Remove outliers (beyond 3 standard deviations)\n","    for col in feature_columns:\n","        mean_val = df[col].mean()\n","        std_val = df[col].std()\n","        df = df[np.abs(df[col] - mean_val) <= (3 * std_val)]\n","\n","    logger.info(f\"After cleaning: {len(df)} samples ({len(df)/original_size*100:.1f}% retained)\")\n","\n","    # Filter classes with sufficient data for reliable training\n","    min_samples = sequence_length * 3\n","    class_counts = df['class'].value_counts()\n","    valid_classes = class_counts[class_counts >= min_samples].index\n","    df = df[df['class'].isin(valid_classes)]\n","\n","    logger.info(f\"Valid classes after filtering: {list(valid_classes)}\")\n","\n","    sequences = []\n","    labels = []\n","\n","    # Create sequences using sliding window with overlap\n","    stride = max(1, int(sequence_length * (1 - overlap_ratio)))\n","\n","    for class_name in valid_classes:\n","        class_data = df[df['class'] == class_name].reset_index(drop=True)\n","\n","        for i in range(0, len(class_data) - sequence_length + 1, stride):\n","            sequence = class_data.iloc[i:i+sequence_length][feature_columns].values\n","\n","            if len(sequence) == sequence_length and not np.any(np.isnan(sequence)):\n","                sequences.append(sequence)\n","                labels.append(class_name)\n","\n","    sequences = np.array(sequences)\n","    logger.info(f\"Total sequences created: {len(sequences)}\")\n","    logger.info(f\"Class distribution: {dict(Counter(labels))}\")\n","\n","    return sequences, labels, len(feature_columns)\n","\n","def analyze_model_complexity(model):\n","    \"\"\"Comprehensive model complexity and efficiency analysis\"\"\"\n","    total_params = sum(p.numel() for p in model.parameters())\n","    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","    # Component-wise parameter analysis\n","    component_params = {}\n","    for name, module in model.named_modules():\n","        if len(list(module.children())) == 0:  # Leaf modules\n","            params = sum(p.numel() for p in module.parameters())\n","            if params > 0:\n","                component_params[name] = params\n","\n","    logger.info(f\"\\n🔧 Model Complexity Analysis:\")\n","    logger.info(f\"   - Total Parameters: {total_params:,}\")\n","    logger.info(f\"   - Trainable Parameters: {trainable_params:,}\")\n","    logger.info(f\"   - Model Size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n","\n","    # Top 5 largest components\n","    sorted_components = sorted(component_params.items(), key=lambda x: x[1], reverse=True)[:5]\n","    logger.info(f\"   - Largest Components:\")\n","    for name, params in sorted_components:\n","        logger.info(f\"     * {name}: {params:,} parameters ({params/total_params*100:.1f}%)\")\n","\n","    return total_params, trainable_params\n","\n","def plot_confusion_matrices(val_targets, val_preds, test_targets, test_preds, target_names):\n","    \"\"\"Plot enhanced confusion matrices for both validation and test sets\"\"\"\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n","\n","    # Validation Confusion Matrix\n","    cm_val = confusion_matrix(val_targets, val_preds)\n","    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=target_names, yticklabels=target_names, ax=ax1)\n","    ax1.set_title('Validation Confusion Matrix', fontsize=16, fontweight='bold')\n","    ax1.set_ylabel('True Label', fontsize=12)\n","    ax1.set_xlabel('Predicted Label', fontsize=12)\n","    ax1.tick_params(axis='x', rotation=45)\n","\n","    # Test Confusion Matrix\n","    cm_test = confusion_matrix(test_targets, test_preds)\n","    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens',\n","                xticklabels=target_names, yticklabels=target_names, ax=ax2)\n","    ax2.set_title('Test Confusion Matrix', fontsize=16, fontweight='bold')\n","    ax2.set_ylabel('True Label', fontsize=12)\n","    ax2.set_xlabel('Predicted Label', fontsize=12)\n","    ax2.tick_params(axis='x', rotation=45)\n","\n","    plt.tight_layout()\n","    plt.savefig('tpa_net_confusion_matrices.png', dpi=150)\n","    plt.show()\n","\n","def main():\n","    set_seed(42)\n","\n","    # Enhanced configuration parameters\n","    CSV_PATH = \"\"  # Update with your dataset path\n","    SEQUENCE_LENGTH = 150\n","    BATCH_SIZE = 16          # Smaller batch size for complex model\n","    EPOCHS = 150             # Extended training epochs\n","    VAL_SIZE = 0.15          # 15% for validation\n","    TEST_SIZE = 0.15         # 15% for test (70% remaining for training)\n","\n","    logger.info(\"🚀 TPA-Net (Temporal Pyramid Attention Network) Training Started!\")\n","    logger.info(f\"📊 Data split: 70% Train, 15% Validation, 15% Test\")\n","    logger.info(\"=\"*80)\n","\n","    # Enhanced data preparation with comprehensive preprocessing\n","    sequences, labels, feature_count = prepare_enhanced_dataset(\n","        CSV_PATH, SEQUENCE_LENGTH, overlap_ratio=0.35\n","    )\n","\n","    if len(sequences) == 0:\n","        logger.error(\"❌ No valid sequences found!\")\n","        return\n","\n","    # First split: train+val (85%) and test (15%)\n","    X_temp, X_test, y_temp, y_test = train_test_split(\n","        sequences, labels, test_size=TEST_SIZE, random_state=42, stratify=labels\n","    )\n","\n","    # Second split: train (70%) and val (15%) from remaining 85%\n","    val_size_adjusted = VAL_SIZE / (1 - TEST_SIZE)  # 0.15 / 0.85 ≈ 0.176\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_temp, y_temp, test_size=val_size_adjusted, random_state=42, stratify=y_temp\n","    )\n","\n","    logger.info(f\"\\n📊 Dataset Summary:\")\n","    logger.info(f\"   - Input Features: {feature_count}\")\n","    logger.info(f\"   - Sequence Length: {SEQUENCE_LENGTH}\")\n","    logger.info(f\"   - Training sequences: {len(X_train):,} ({len(X_train)/len(sequences)*100:.1f}%)\")\n","    logger.info(f\"   - Validation sequences: {len(X_val):,} ({len(X_val)/len(sequences)*100:.1f}%)\")\n","    logger.info(f\"   - Test sequences: {len(X_test):,} ({len(X_test)/len(sequences)*100:.1f}%)\")\n","\n","    # Create advanced datasets with sophisticated augmentation\n","    train_dataset = AdvancedDiverSignDataset(\n","        X_train, y_train,\n","        train_mode=True,\n","        augment_prob=0.5,  # Higher augmentation for complex model\n","        noise_std=0.01\n","    )\n","\n","    val_dataset = AdvancedDiverSignDataset(\n","        X_val, y_val,\n","        train_dataset.get_label_encoder(),\n","        train_dataset.get_scaler(),\n","        train_mode=False\n","    )\n","\n","    test_dataset = AdvancedDiverSignDataset(\n","        X_test, y_test,\n","        train_dataset.get_label_encoder(),\n","        train_dataset.get_scaler(),\n","        train_mode=False\n","    )\n","\n","    # Create optimized data loaders\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=False,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=False,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","\n","    num_classes = len(train_dataset.get_label_encoder().classes_)\n","    class_names = train_dataset.get_label_encoder().classes_\n","\n","    logger.info(f\"   - Number of Classes: {num_classes}\")\n","    logger.info(f\"   - Class Names: {list(class_names)}\")\n","\n","    # Create advanced TPA-Net model\n","    model = TPANet(\n","        input_dim=feature_count,\n","        hidden_dim=256,\n","        num_classes=num_classes,\n","        num_layers=3,\n","        dropout=0.25\n","    )\n","\n","    # Comprehensive model complexity analysis\n","    total_params, trainable_params = analyze_model_complexity(model)\n","\n","    logger.info(f\"\\n🤖 TPA-Net Architecture Configuration:\")\n","    logger.info(f\"   - Temporal Pyramid Blocks: 3 layers\")\n","    logger.info(f\"   - Cross-Scale Attention: 8 heads\")\n","    logger.info(f\"   - Adaptive Pooling: Multi-scale\")\n","    logger.info(f\"   - Uncertainty Estimation: Enabled\")\n","    logger.info(f\"   - Dynamic Feature Selection: Enabled\")\n","\n","    # Initialize advanced trainer\n","    trainer = TPANetTrainer(\n","        model=model,\n","        class_weights=train_dataset.get_class_weights()\n","    )\n","\n","    logger.info(f\"\\n🔥 Starting Advanced Training ({EPOCHS} epochs)...\")\n","    logger.info(\"=\"*80)\n","\n","    # Execute comprehensive training\n","    best_f1 = trainer.train(train_loader, val_loader, epochs=EPOCHS)\n","\n","    # Load best model for final evaluation\n","    checkpoint = torch.load(\"tpa_net_best_model.pth\")\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    # Final validation evaluation\n","    val_loss, val_acc, val_f1, val_preds, val_targets, val_unc = trainer.validate(val_loader)\n","\n","    # Final test evaluation\n","    test_loss, test_acc, test_f1, test_preds, test_targets, test_unc = trainer.validate(test_loader)\n","\n","    # Training analysis\n","    final_train_acc = trainer.train_accuracies[-1]\n","    final_val_acc = trainer.val_accuracies[-1]\n","    accuracy_gap = final_train_acc - final_val_acc\n","\n","    logger.info(f\"\\n📊 TPA-Net Final Results:\")\n","    logger.info(\"=\"*50)\n","    logger.info(f\"   📊 VALIDATION:\")\n","    logger.info(f\"     - Accuracy: {val_acc:.2f}%\")\n","    logger.info(f\"     - F1 Score: {val_f1:.4f}\")\n","    logger.info(f\"     - Uncertainty: {val_unc:.4f}\")\n","    logger.info(f\"     - Confidence: {(1-val_unc)*100:.1f}%\")\n","    logger.info(f\"   📊 TEST:\")\n","    logger.info(f\"     - Accuracy: {test_acc:.2f}%\")\n","    logger.info(f\"     - F1 Score: {test_f1:.4f}\")\n","    logger.info(f\"     - Uncertainty: {test_unc:.4f}\")\n","    logger.info(f\"     - Confidence: {(1-test_unc)*100:.1f}%\")\n","    logger.info(f\"   📊 TRAINING ANALYSIS:\")\n","    logger.info(f\"     - Train-Validation Gap: {accuracy_gap:.2f}%\")\n","    logger.info(f\"     - Best Validation F1: {best_f1:.4f}\")\n","\n","    # Model generalization analysis\n","    if accuracy_gap < 3:\n","        logger.info(\"   ✅ Excellent generalization achieved\")\n","    elif accuracy_gap < 7:\n","        logger.info(\"   ✅ Good generalization achieved\")\n","    elif accuracy_gap < 12:\n","        logger.info(\"   ⚠️ Moderate overfitting detected\")\n","    else:\n","        logger.info(\"   ❌ Significant overfitting detected\")\n","\n","    # Comprehensive classification reports\n","    target_names = train_dataset.get_label_encoder().classes_\n","\n","    print(f\"\\n📋 VALIDATION Classification Report:\")\n","    print(\"=\"*80)\n","    print(classification_report(val_targets, val_preds, target_names=target_names, digits=3))\n","\n","    print(f\"\\n📋 TEST Classification Report:\")\n","    print(\"=\"*80)\n","    print(classification_report(test_targets, test_preds, target_names=target_names, digits=3))\n","\n","    # Generate dual confusion matrices\n","    plot_confusion_matrices(val_targets, val_preds, test_targets, test_preds, target_names)\n","\n","    # Enhanced confusion matrix with percentages\n","    plt.figure(figsize=(12, 10))\n","    cm = confusion_matrix(test_targets, test_preds)\n","\n","    # Normalize to percentages for better interpretation\n","    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n","\n","    # Create enhanced heatmap\n","    sns.heatmap(\n","        cm_percent,\n","        annot=True,\n","        fmt='.1f',\n","        cmap='RdYlBu_r',\n","        xticklabels=class_names,\n","        yticklabels=class_names,\n","        cbar_kws={'label': 'Percentage (%)'},\n","        linewidths=0.5\n","    )\n","\n","    plt.title('TPA-Net - Test Confusion Matrix (%)', fontsize=18, fontweight='bold', pad=20)\n","    plt.xlabel('Predicted Label', fontsize=14)\n","    plt.ylabel('True Label', fontsize=14)\n","    plt.xticks(rotation=45, ha='right')\n","    plt.yticks(rotation=0)\n","\n","    # Add comprehensive model information\n","    model_info = f'TPA-Net | Params: {total_params:,} | F1: {test_f1:.3f} | Confidence: {(1-test_unc)*100:.1f}%'\n","    plt.figtext(0.02, 0.02, model_info, fontsize=10,\n","                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightblue', alpha=0.7))\n","\n","    plt.tight_layout()\n","    plt.savefig('tpa_net_detailed_confusion_matrix.png', dpi=150, bbox_inches='tight')\n","    plt.show()\n","\n","    # Comprehensive training curves visualization\n","    plot_comprehensive_tpa_results(trainer, \"TPA_Net\")\n","\n","    # Advanced attention analysis visualization\n","    logger.info(\"\\n🔍 Generating Comprehensive Attention Analysis...\")\n","    visualize_tpa_attention(model, test_loader, class_names, trainer.device, num_samples=2)\n","\n","    # Model efficiency analysis\n","    logger.info(f\"\\n⚡ Model Efficiency Analysis:\")\n","    logger.info(f\"   - Parameters per Class: {total_params // num_classes:,}\")\n","    logger.info(f\"   - Accuracy per 1K Parameters: {test_acc / (total_params / 1000):.3f}\")\n","    logger.info(f\"   - F1 Score per 1M Parameters: {test_f1 / (total_params / 1000000):.3f}\")\n","\n","    # Save comprehensive results\n","    logger.info(f\"\\n💾 Saving Comprehensive Results...\")\n","\n","    # Save complete model with all metadata\n","    torch.save({\n","        'model_state_dict': model.state_dict(),\n","        'model_config': {\n","            'input_dim': feature_count,\n","            'hidden_dim': 256,\n","            'num_classes': num_classes,\n","            'num_layers': 3,\n","            'dropout': 0.25\n","        },\n","        'training_history': {\n","            'train_losses': trainer.train_losses,\n","            'val_losses': trainer.val_losses,\n","            'train_accuracies': trainer.train_accuracies,\n","            'val_accuracies': trainer.val_accuracies,\n","            'val_f1_scores': trainer.val_f1_scores,\n","            'uncertainty_scores': trainer.uncertainty_scores\n","        },\n","        'test_results': {\n","            'test_accuracy': test_acc,\n","            'test_f1': test_f1,\n","            'test_uncertainty': test_unc,\n","            'validation_accuracy': val_acc,\n","            'validation_f1': val_f1,\n","            'validation_uncertainty': val_unc,\n","            'confusion_matrix': cm.tolist(),\n","            'class_names': class_names.tolist()\n","        },\n","        'model_analysis': {\n","            'total_parameters': total_params,\n","            'trainable_parameters': trainable_params,\n","            'accuracy_gap': accuracy_gap,\n","            'best_val_f1': best_f1\n","        }\n","    }, 'tpa_net_comprehensive_model.pth')\n","\n","    logger.info(\"\\n✅ TPA-NET TRAINING COMPLETED SUCCESSFULLY!\")\n","    logger.info(f\"📁 Files saved:\")\n","    logger.info(f\"   - tpa_net_comprehensive_model.pth: Complete model with metadata\")\n","    logger.info(f\"   - tpa_net_confusion_matrices.png: Dual confusion matrices\")\n","    logger.info(f\"   - tpa_net_comprehensive_results.png: Training curves\")\n","    logger.info(f\"   - tpa_net_attention_analysis.png: Attention visualizations\")\n","    logger.info(f\"   - tpa_net_detailed_confusion_matrix.png: Detailed test matrix\")\n","\n","    logger.info(f\"\\n🏆 FINAL PERFORMANCE SUMMARY:\")\n","    logger.info(f\"🎯 Test F1 Score: {test_f1:.4f}\")\n","    logger.info(f\"🎯 Test Accuracy: {test_acc:.2f}%\")\n","    logger.info(f\"🎯 Model Confidence: {(1-test_unc)*100:.1f}%\")\n","    logger.info(f\"🎯 Total Parameters: {total_params:,}\")\n","\n","    return trainer, model, train_dataset, val_targets, val_preds, test_targets, test_preds\n","\n","if __name__ == \"__main__\":\n","    trainer, model, dataset, val_targets, val_preds, test_targets, test_preds = main()"],"metadata":{"id":"GBPqZWzvtjgy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ConvLSTM + Vision Transformer Hybrid Model for Diver Sign Language Recognition\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import os\n","import logging\n","import random\n","from collections import Counter\n","import math\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Logging setup\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","def set_seed(seed=42):\n","    \"\"\"Set random seeds for reproducibility\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","class EnhancedDiverSignDataset(Dataset):\n","    \"\"\"Enhanced dataset with advanced augmentation for hybrid model\"\"\"\n","    def __init__(self, sequences, labels, label_encoder=None, scaler=None,\n","                 train_mode=True, augment_prob=0.4):\n","\n","        # Label encoding\n","        if label_encoder is None:\n","            self.label_encoder = LabelEncoder()\n","            encoded_labels = self.label_encoder.fit_transform(labels)\n","        else:\n","            self.label_encoder = label_encoder\n","            encoded_labels = self.label_encoder.transform(labels)\n","\n","        # Advanced data scaling\n","        if scaler is None:\n","            self.scaler = StandardScaler()\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.fit_transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","        else:\n","            self.scaler = scaler\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","\n","        self.sequences = torch.FloatTensor(scaled_sequences)\n","        self.labels = torch.LongTensor(encoded_labels)\n","        self.train_mode = train_mode\n","        self.augment_prob = augment_prob\n","\n","        # Enhanced class weights using effective number of samples\n","        class_counts = Counter(encoded_labels)\n","        total_samples = len(encoded_labels)\n","\n","        # Effective number of samples for class balancing\n","        beta = 0.9999\n","        effective_nums = [(1 - beta**class_counts[i]) / (1 - beta) for i in range(len(class_counts))]\n","        weights = [1.0 / effective_nums[i] for i in range(len(class_counts))]\n","        sum_weights = sum(weights)\n","        self.class_weights = torch.FloatTensor([w * len(weights) / sum_weights for w in weights])\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        sequence = self.sequences[idx].clone()\n","        label = self.labels[idx]\n","\n","        # Apply sophisticated augmentation during training\n","        if self.train_mode and random.random() < self.augment_prob:\n","            sequence = self._apply_hybrid_augmentation(sequence)\n","\n","        return sequence, label\n","\n","    def _apply_hybrid_augmentation(self, sequence):\n","        \"\"\"Hybrid-specific augmentation techniques\"\"\"\n","        aug_techniques = ['noise', 'temporal_mask', 'feature_dropout', 'mixup', 'gaussian_blur']\n","        selected_augs = random.sample(aug_techniques, k=random.randint(1, 2))\n","\n","        for aug_type in selected_augs:\n","            if aug_type == 'noise':\n","                # Adaptive Gaussian noise\n","                noise_std = torch.std(sequence) * 0.05\n","                noise = torch.randn_like(sequence) * noise_std\n","                sequence = sequence + noise\n","\n","            elif aug_type == 'temporal_mask':\n","                # Temporal masking (similar to SpecAugment)\n","                mask_length = random.randint(5, 15)\n","                mask_start = random.randint(0, max(0, sequence.size(0) - mask_length))\n","                sequence[mask_start:mask_start + mask_length] *= 0.1\n","\n","            elif aug_type == 'feature_dropout':\n","                # Feature channel dropout\n","                num_features_to_drop = random.randint(1, sequence.size(1) // 4)\n","                features_to_drop = random.sample(range(sequence.size(1)), num_features_to_drop)\n","                sequence[:, features_to_drop] *= 0.1\n","\n","            elif aug_type == 'mixup':\n","                # Temporal mixup within sequence\n","                alpha = 0.2\n","                lam = np.random.beta(alpha, alpha)\n","                rand_index = torch.randperm(sequence.size(0))\n","                sequence = lam * sequence + (1 - lam) * sequence[rand_index]\n","\n","            elif aug_type == 'gaussian_blur':\n","                # 1D Gaussian blur for temporal smoothing\n","                kernel_size = 3\n","                sigma = 0.5\n","                sequence = self._gaussian_blur_1d(sequence, kernel_size, sigma)\n","\n","        return torch.clamp(sequence, -5, 5)  # Prevent extreme values\n","\n","    def _gaussian_blur_1d(self, tensor, kernel_size, sigma):\n","        \"\"\"Apply 1D Gaussian blur to temporal sequence\"\"\"\n","        channels = tensor.size(1)\n","\n","        # Create Gaussian kernel\n","        x = torch.arange(kernel_size, dtype=torch.float32) - kernel_size // 2\n","        gaussian_kernel = torch.exp(-x.pow(2) / (2 * sigma**2))\n","        gaussian_kernel = gaussian_kernel / gaussian_kernel.sum()\n","\n","        # Apply convolution for each feature channel\n","        blurred = F.conv1d(\n","            tensor.transpose(0, 1).unsqueeze(0),\n","            gaussian_kernel.unsqueeze(0).unsqueeze(0).repeat(channels, 1, 1),\n","            padding=kernel_size // 2,\n","            groups=channels\n","        )\n","\n","        return blurred.squeeze(0).transpose(0, 1)\n","\n","    def get_label_encoder(self):\n","        return self.label_encoder\n","\n","    def get_scaler(self):\n","        return self.scaler\n","\n","    def get_class_weights(self):\n","        return self.class_weights\n","\n","class ConvLSTMCell(nn.Module):\n","    \"\"\"ConvLSTM Cell for spatio-temporal processing\"\"\"\n","    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True):\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","        self.kernel_size = kernel_size\n","        self.padding = kernel_size // 2\n","        self.bias = bias\n","\n","        # Convolutional gates\n","        self.conv = nn.Conv1d(\n","            in_channels=self.input_dim + self.hidden_dim,\n","            out_channels=4 * self.hidden_dim,\n","            kernel_size=self.kernel_size,\n","            padding=self.padding,\n","            bias=self.bias\n","        )\n","\n","    def forward(self, input_tensor, cur_state):\n","        h_cur, c_cur = cur_state\n","\n","        # Ensure both tensors have the same spatial dimension\n","        # input_tensor: [batch, input_dim, 1]\n","        # h_cur: [batch, hidden_dim, 1]\n","        combined = torch.cat([input_tensor, h_cur], dim=1)\n","\n","        # Convolutional gates\n","        combined_conv = self.conv(combined)\n","\n","        # Split into gates\n","        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n","\n","        # Apply gates\n","        i = torch.sigmoid(cc_i)\n","        f = torch.sigmoid(cc_f)\n","        o = torch.sigmoid(cc_o)\n","        g = torch.tanh(cc_g)\n","\n","        # Update cell state\n","        c_next = f * c_cur + i * g\n","        h_next = o * torch.tanh(c_next)\n","\n","        return h_next, c_next\n","\n","    def init_hidden(self, batch_size, device):\n","        \"\"\"Initialize hidden and cell states\"\"\"\n","        return (torch.zeros(batch_size, self.hidden_dim, 1, device=device),\n","                torch.zeros(batch_size, self.hidden_dim, 1, device=device))\n","\n","class ConvLSTM(nn.Module):\n","    \"\"\"ConvLSTM module for temporal-spatial feature extraction\"\"\"\n","    def __init__(self, input_dim, hidden_dims, kernel_sizes, num_layers,\n","                 bidirectional=True, dropout=0.2):\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.hidden_dims = hidden_dims if isinstance(hidden_dims, list) else [hidden_dims] * num_layers\n","        self.kernel_sizes = kernel_sizes if isinstance(kernel_sizes, list) else [kernel_sizes] * num_layers\n","        self.num_layers = num_layers\n","        self.bidirectional = bidirectional\n","        self.dropout = dropout\n","\n","        # Create ConvLSTM layers\n","        cell_list = []\n","        for i in range(num_layers):\n","            cur_input_dim = self.input_dim if i == 0 else self.hidden_dims[i-1]\n","            if self.bidirectional and i > 0:\n","                cur_input_dim = self.hidden_dims[i-1] * 2\n","\n","            cell_list.append(ConvLSTMCell(\n","                input_dim=cur_input_dim,\n","                hidden_dim=self.hidden_dims[i],\n","                kernel_size=self.kernel_sizes[i]\n","            ))\n","\n","        self.cell_list = nn.ModuleList(cell_list)\n","        self.dropout_layers = nn.ModuleList([nn.Dropout(dropout) for _ in range(num_layers)])\n","\n","    def forward(self, input_tensor):\n","        \"\"\"\n","        Forward pass through ConvLSTM\n","        Args:\n","            input_tensor: [batch, seq_len, features]\n","        Returns:\n","            layer_output_list: List of outputs from each layer\n","            last_state_list: List of final states\n","        \"\"\"\n","        batch_size, seq_len, _ = input_tensor.shape\n","        device = input_tensor.device\n","\n","        # Transform input for conv processing: [batch, features, seq_len]\n","        input_tensor = input_tensor.transpose(1, 2)\n","\n","        layer_output_list = []\n","        last_state_list = []\n","\n","        cur_layer_input = input_tensor\n","\n","        for layer_idx in range(self.num_layers):\n","            # Initialize hidden states\n","            h, c = self.cell_list[layer_idx].init_hidden(batch_size, device)\n","\n","            # Forward direction\n","            output_inner = []\n","            for t in range(seq_len):\n","                # Extract single timestep: [batch, features, 1]\n","                timestep_input = cur_layer_input[:, :, t:t+1]\n","                h, c = self.cell_list[layer_idx](timestep_input, (h, c))\n","                output_inner.append(h)\n","\n","            # Concatenate outputs: [batch, hidden_dim, seq_len]\n","            forward_output = torch.cat(output_inner, dim=2)\n","\n","            if self.bidirectional:\n","                # Backward direction\n","                h_back, c_back = self.cell_list[layer_idx].init_hidden(batch_size, device)\n","                output_inner_back = []\n","\n","                for t in reversed(range(seq_len)):\n","                    timestep_input = cur_layer_input[:, :, t:t+1]\n","                    h_back, c_back = self.cell_list[layer_idx](timestep_input, (h_back, c_back))\n","                    output_inner_back.append(h_back)\n","\n","                # Reverse and concatenate\n","                backward_output = torch.cat(output_inner_back[::-1], dim=2)\n","                layer_output = torch.cat([forward_output, backward_output], dim=1)\n","            else:\n","                layer_output = forward_output\n","\n","            # Apply dropout\n","            if layer_idx < self.num_layers - 1:\n","                layer_output = self.dropout_layers[layer_idx](layer_output)\n","\n","            layer_output_list.append(layer_output)\n","            last_state_list.append((h, c))\n","            cur_layer_input = layer_output\n","\n","        return layer_output_list, last_state_list\n","\n","class MultiHeadSelfAttention(nn.Module):\n","    \"\"\"Multi-head self-attention mechanism for Vision Transformer\"\"\"\n","    def __init__(self, embed_dim, num_heads, dropout=0.1):\n","        super().__init__()\n","        assert embed_dim % num_heads == 0\n","\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.head_dim = embed_dim // num_heads\n","        self.scale = self.head_dim ** -0.5\n","\n","        self.qkv = nn.Linear(embed_dim, embed_dim * 3, bias=False)\n","        self.attn_dropout = nn.Dropout(dropout)\n","        self.proj = nn.Linear(embed_dim, embed_dim)\n","        self.proj_dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        B, N, C = x.shape\n","\n","        # Generate Q, K, V\n","        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n","        q, k, v = qkv[0], qkv[1], qkv[2]\n","\n","        # Scaled dot-product attention\n","        attn = (q @ k.transpose(-2, -1)) * self.scale\n","        attn = F.softmax(attn, dim=-1)\n","        attn = self.attn_dropout(attn)\n","\n","        # Apply attention to values\n","        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n","        x = self.proj(x)\n","        x = self.proj_dropout(x)\n","\n","        return x, attn\n","\n","class TransformerBlock(nn.Module):\n","    \"\"\"Transformer block with multi-head attention and MLP\"\"\"\n","    def __init__(self, embed_dim, num_heads, mlp_ratio=4.0, dropout=0.1):\n","        super().__init__()\n","\n","        self.norm1 = nn.LayerNorm(embed_dim)\n","        self.attn = MultiHeadSelfAttention(embed_dim, num_heads, dropout)\n","\n","        self.norm2 = nn.LayerNorm(embed_dim)\n","        mlp_hidden_dim = int(embed_dim * mlp_ratio)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(embed_dim, mlp_hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(mlp_hidden_dim, embed_dim),\n","            nn.Dropout(dropout)\n","        )\n","\n","    def forward(self, x):\n","        # Multi-head self-attention with residual connection\n","        attn_out, attn_weights = self.attn(self.norm1(x))\n","        x = x + attn_out\n","\n","        # MLP with residual connection\n","        x = x + self.mlp(self.norm2(x))\n","\n","        return x, attn_weights\n","\n","class VisionTransformer(nn.Module):\n","    \"\"\"Vision Transformer for sequence modeling\"\"\"\n","    def __init__(self, seq_len, embed_dim, num_heads, num_layers,\n","                 mlp_ratio=4.0, dropout=0.1):\n","        super().__init__()\n","\n","        self.seq_len = seq_len\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.num_layers = num_layers\n","\n","        # Positional embedding\n","        self.pos_embed = nn.Parameter(torch.randn(1, seq_len, embed_dim) * 0.02)\n","        self.pos_dropout = nn.Dropout(dropout)\n","\n","        # Transformer blocks\n","        self.blocks = nn.ModuleList([\n","            TransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n","            for _ in range(num_layers)\n","        ])\n","\n","        self.norm = nn.LayerNorm(embed_dim)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass through Vision Transformer\n","        Args:\n","            x: [batch, seq_len, embed_dim]\n","        Returns:\n","            x: Processed sequence\n","            attn_weights: List of attention weights from each layer\n","        \"\"\"\n","        B, N, C = x.shape\n","\n","        # Add positional embedding\n","        x = x + self.pos_embed[:, :N, :]\n","        x = self.pos_dropout(x)\n","\n","        # Process through transformer blocks\n","        attn_weights_list = []\n","        for block in self.blocks:\n","            x, attn_weights = block(x)\n","            attn_weights_list.append(attn_weights)\n","\n","        x = self.norm(x)\n","\n","        return x, attn_weights_list\n","\n","class CrossModalAttention(nn.Module):\n","    \"\"\"Cross-modal attention for fusing ConvLSTM and ViT features\"\"\"\n","    def __init__(self, conv_dim, vit_dim, fusion_dim, num_heads=8):\n","        super().__init__()\n","\n","        self.conv_dim = conv_dim\n","        self.vit_dim = vit_dim\n","        self.fusion_dim = fusion_dim\n","        self.num_heads = num_heads\n","\n","        # Project inputs to same dimension\n","        self.conv_proj = nn.Linear(conv_dim, fusion_dim)\n","        self.vit_proj = nn.Linear(vit_dim, fusion_dim)\n","\n","        # Cross-attention layers\n","        self.conv_to_vit_attn = nn.MultiheadAttention(fusion_dim, num_heads, batch_first=True)\n","        self.vit_to_conv_attn = nn.MultiheadAttention(fusion_dim, num_heads, batch_first=True)\n","\n","        # Fusion layers\n","        self.fusion_norm = nn.LayerNorm(fusion_dim * 2)\n","        self.fusion_mlp = nn.Sequential(\n","            nn.Linear(fusion_dim * 2, fusion_dim),\n","            nn.GELU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(fusion_dim, fusion_dim)\n","        )\n","\n","    def forward(self, conv_features, vit_features):\n","        \"\"\"\n","        Cross-modal attention fusion\n","        Args:\n","            conv_features: [batch, seq_len, conv_dim]\n","            vit_features: [batch, seq_len, vit_dim]\n","        Returns:\n","            fused_features: [batch, seq_len, fusion_dim]\n","        \"\"\"\n","        # Project to same dimension\n","        conv_proj = self.conv_proj(conv_features)\n","        vit_proj = self.vit_proj(vit_features)\n","\n","        # Cross-attention: ConvLSTM features attend to ViT features\n","        conv_attended, _ = self.conv_to_vit_attn(conv_proj, vit_proj, vit_proj)\n","\n","        # Cross-attention: ViT features attend to ConvLSTM features\n","        vit_attended, _ = self.vit_to_conv_attn(vit_proj, conv_proj, conv_proj)\n","\n","        # Concatenate and fuse\n","        combined = torch.cat([conv_attended, vit_attended], dim=-1)\n","        combined = self.fusion_norm(combined)\n","        fused = self.fusion_mlp(combined)\n","\n","        # Residual connection\n","        fused = fused + conv_proj + vit_proj\n","\n","        return fused\n","\n","class ConvLSTM_ViT_Hybrid(nn.Module):\n","    \"\"\"Hybrid model combining ConvLSTM and Vision Transformer\"\"\"\n","    def __init__(self, input_dim=69, hidden_dim=128, num_classes=10,\n","                 seq_len=150, dropout=0.2):\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","        self.num_classes = num_classes\n","        self.seq_len = seq_len\n","\n","        # Input preprocessing\n","        self.input_projection = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.LayerNorm(hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout)\n","        )\n","\n","        # ConvLSTM branch for local temporal-spatial patterns\n","        self.convlstm = ConvLSTM(\n","            input_dim=hidden_dim,\n","            hidden_dims=[hidden_dim, hidden_dim],\n","            kernel_sizes=[3, 5],\n","            num_layers=2,\n","            bidirectional=True,\n","            dropout=dropout\n","        )\n","\n","        # Vision Transformer branch for global sequential patterns\n","        self.vit = VisionTransformer(\n","            seq_len=seq_len,\n","            embed_dim=hidden_dim,\n","            num_heads=8,\n","            num_layers=4,\n","            mlp_ratio=4.0,\n","            dropout=dropout\n","        )\n","\n","        # Cross-modal attention fusion\n","        conv_output_dim = hidden_dim * 2  # Bidirectional\n","        self.cross_modal_fusion = CrossModalAttention(\n","            conv_dim=conv_output_dim,\n","            vit_dim=hidden_dim,\n","            fusion_dim=hidden_dim,\n","            num_heads=8\n","        )\n","\n","        # Adaptive pooling strategies\n","        self.adaptive_pool = nn.ModuleList([\n","            nn.AdaptiveAvgPool1d(1),\n","            nn.AdaptiveMaxPool1d(1),\n","            nn.AdaptiveAvgPool1d(4)\n","        ])\n","\n","        # Attention-based pooling selection\n","        self.pool_attention = nn.Sequential(\n","            nn.Linear(hidden_dim * 3, hidden_dim),\n","            nn.Tanh(),\n","            nn.Linear(hidden_dim, 3),\n","            nn.Softmax(dim=-1)\n","        )\n","\n","        # Classification head with uncertainty estimation\n","        self.classifier = nn.Sequential(\n","            nn.LayerNorm(hidden_dim),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.GELU(),\n","            nn.Dropout(dropout * 0.5),\n","            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n","            nn.GELU(),\n","            nn.Dropout(dropout * 0.3),\n","            nn.Linear(hidden_dim // 4, num_classes)\n","        )\n","\n","        # Uncertainty head for confidence estimation\n","        self.uncertainty_head = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim // 4),\n","            nn.GELU(),\n","            nn.Linear(hidden_dim // 4, 1),\n","            nn.Sigmoid()\n","        )\n","\n","        self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        \"\"\"Initialize model weights using appropriate strategies\"\"\"\n","        for name, module in self.named_modules():\n","            if isinstance(module, nn.Linear):\n","                nn.init.xavier_uniform_(module.weight)\n","                if module.bias is not None:\n","                    nn.init.zeros_(module.bias)\n","            elif isinstance(module, nn.LayerNorm):\n","                nn.init.ones_(module.weight)\n","                nn.init.zeros_(module.bias)\n","            elif isinstance(module, nn.Conv1d):\n","                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n","\n","    def forward(self, x, return_features=False):\n","        \"\"\"\n","        Forward pass through hybrid model\n","        Args:\n","            x: Input tensor [batch, seq_len, input_dim]\n","            return_features: Whether to return intermediate features\n","        Returns:\n","            logits: Classification output\n","            uncertainty: Prediction uncertainty\n","            features: Intermediate features (if requested)\n","        \"\"\"\n","        batch_size, seq_len, _ = x.shape\n","\n","        # Input preprocessing\n","        x_proj = self.input_projection(x)\n","\n","        # ConvLSTM branch for local patterns\n","        conv_outputs, _ = self.convlstm(x_proj)\n","        conv_features = conv_outputs[-1].transpose(1, 2)  # [batch, seq_len, conv_dim]\n","\n","        # Vision Transformer branch for global patterns\n","        vit_features, vit_attention_weights = self.vit(x_proj)\n","\n","        # Cross-modal fusion\n","        fused_features = self.cross_modal_fusion(conv_features, vit_features)\n","\n","        # Adaptive pooling\n","        pooled_features = []\n","        for pool in self.adaptive_pool:\n","            if pool.output_size == 1:\n","                pooled = pool(fused_features.transpose(1, 2)).squeeze(-1)\n","            else:\n","                pooled = pool(fused_features.transpose(1, 2)).transpose(1, 2).mean(dim=1)\n","            pooled_features.append(pooled)\n","\n","        # Attention-weighted pooling\n","        all_pooled = torch.cat(pooled_features, dim=-1)\n","        pool_weights = self.pool_attention(all_pooled)\n","\n","        final_features = sum(w.unsqueeze(-1) * feat for w, feat in zip(pool_weights.unbind(-1), pooled_features))\n","\n","        # Classification and uncertainty\n","        logits = self.classifier(final_features)\n","        uncertainty = self.uncertainty_head(final_features)\n","\n","        if return_features:\n","            return logits, uncertainty, {\n","                'conv_features': conv_features,\n","                'vit_features': vit_features,\n","                'fused_features': fused_features,\n","                'vit_attention': vit_attention_weights,\n","                'pool_weights': pool_weights\n","            }\n","\n","        return logits, uncertainty\n","\n","class HybridModelTrainer:\n","    \"\"\"Trainer for ConvLSTM-ViT Hybrid model\"\"\"\n","    def __init__(self, model, class_weights=None, device='cuda' if torch.cuda.is_available() else 'cpu'):\n","        self.model = model\n","        self.device = device\n","        self.model.to(device)\n","\n","        # Loss functions\n","        if class_weights is not None:\n","            class_weights = class_weights.to(device)\n","\n","        self.classification_criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n","        self.uncertainty_criterion = nn.MSELoss()\n","\n","        # Advanced optimizer with component-specific learning rates\n","        convlstm_params = []\n","        vit_params = []\n","        fusion_params = []\n","        classifier_params = []\n","\n","        for name, param in model.named_parameters():\n","            if 'convlstm' in name:\n","                convlstm_params.append(param)\n","            elif 'vit' in name:\n","                vit_params.append(param)\n","            elif 'cross_modal' in name or 'pool' in name:\n","                fusion_params.append(param)\n","            else:\n","                classifier_params.append(param)\n","\n","        self.optimizer = optim.AdamW([\n","            {'params': convlstm_params, 'lr': 5e-4, 'weight_decay': 0.01},\n","            {'params': vit_params, 'lr': 3e-4, 'weight_decay': 0.005},\n","            {'params': fusion_params, 'lr': 8e-4, 'weight_decay': 0.01},\n","            {'params': classifier_params, 'lr': 1e-3, 'weight_decay': 0.01}\n","        ], betas=(0.9, 0.95))\n","\n","        # Learning rate scheduler\n","        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","            self.optimizer, T_0=20, T_mult=2, eta_min=1e-6\n","        )\n","\n","        # Metrics tracking\n","        self.train_losses = []\n","        self.val_losses = []\n","        self.train_accuracies = []\n","        self.val_accuracies = []\n","        self.val_f1_scores = []\n","\n","    def train_epoch(self, dataloader):\n","        \"\"\"Training epoch with advanced loss computation\"\"\"\n","        self.model.train()\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","\n","        for batch_idx, (data, target) in enumerate(tqdm(dataloader, desc=\"Training\")):\n","            data, target = data.to(self.device), target.to(self.device)\n","\n","            self.optimizer.zero_grad()\n","\n","            # Forward pass\n","            logits, uncertainty = self.model(data)\n","\n","            # Classification loss\n","            clf_loss = self.classification_criterion(logits, target)\n","\n","            # Uncertainty loss\n","            pred_probs = F.softmax(logits, dim=1)\n","            pred_confidence = pred_probs.max(dim=1)[0]\n","            uncertainty_target = 1.0 - pred_confidence\n","            unc_loss = self.uncertainty_criterion(uncertainty.squeeze(), uncertainty_target.detach())\n","\n","            # Combined loss\n","            total_loss_batch = clf_loss + 0.1 * unc_loss\n","\n","            # L2 regularization\n","            l2_reg = sum(param.pow(2).sum() for param in self.model.parameters())\n","            total_loss_batch += 1e-5 * l2_reg\n","\n","            total_loss_batch.backward()\n","\n","            # Gradient clipping\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n","\n","            self.optimizer.step()\n","\n","            # Statistics\n","            total_loss += total_loss_batch.item()\n","            _, predicted = logits.max(1)\n","            total += target.size(0)\n","            correct += predicted.eq(target).sum().item()\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_targets.extend(target.cpu().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","\n","        return avg_loss, accuracy, f1, all_preds, all_targets\n","\n","    def validate(self, dataloader):\n","        \"\"\"Validation with comprehensive metrics\"\"\"\n","        self.model.eval()\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","\n","        with torch.no_grad():\n","            for data, target in tqdm(dataloader, desc=\"Validating\"):\n","                data, target = data.to(self.device), target.to(self.device)\n","\n","                logits, uncertainty = self.model(data)\n","                loss = self.classification_criterion(logits, target)\n","\n","                total_loss += loss.item()\n","                _, predicted = logits.max(1)\n","                total += target.size(0)\n","                correct += predicted.eq(target).sum().item()\n","\n","                all_preds.extend(predicted.cpu().numpy())\n","                all_targets.extend(target.cpu().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","\n","        return avg_loss, accuracy, f1, all_preds, all_targets\n","\n","    def train(self, train_loader, val_loader, epochs=150):\n","        \"\"\"Complete training loop with advanced monitoring\"\"\"\n","        best_val_f1 = 0\n","        patience = 25\n","        patience_counter = 0\n","\n","        logger.info(f\"🚀 ConvLSTM-ViT Hybrid Training Started: {epochs} epochs\")\n","        logger.info(f\"   - Model Parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n","\n","        for epoch in range(epochs):\n","            # Training\n","            train_loss, train_acc, train_f1, _, _ = self.train_epoch(train_loader)\n","\n","            # Validation\n","            val_loss, val_acc, val_f1, _, _ = self.validate(val_loader)\n","\n","            # Learning rate scheduling\n","            self.scheduler.step()\n","\n","            # Save metrics\n","            self.train_losses.append(train_loss)\n","            self.val_losses.append(val_loss)\n","            self.train_accuracies.append(train_acc)\n","            self.val_accuracies.append(val_acc)\n","            self.val_f1_scores.append(val_f1)\n","\n","            # Progress logging\n","            if (epoch + 1) % 10 == 0:\n","                logger.info(f'Epoch {epoch+1}/{epochs}:')\n","                logger.info(f'  Train: Loss={train_loss:.3f}, Acc={train_acc:.1f}%, F1={train_f1:.3f}')\n","                logger.info(f'  Val:   Loss={val_loss:.3f}, Acc={val_acc:.1f}%, F1={val_f1:.3f}')\n","                logger.info(f'  LR: {self.optimizer.param_groups[0][\"lr\"]:.2e}')\n","\n","            # Save best model\n","            if val_f1 > best_val_f1:\n","                best_val_f1 = val_f1\n","                torch.save({\n","                    'model_state_dict': self.model.state_dict(),\n","                    'epoch': epoch,\n","                    'val_f1': val_f1,\n","                    'model_type': 'ConvLSTM_ViT_Hybrid'\n","                }, \"convlstm_vit_hybrid_best_model.pth\")\n","                logger.info(f\"  ✅ New best model saved: F1={val_f1:.3f}\")\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","\n","            # Early stopping\n","            if patience_counter >= patience:\n","                logger.info(f\"Early stopping triggered at epoch {epoch+1}\")\n","                break\n","\n","        logger.info(f\"🎯 Training completed. Best F1 Score: {best_val_f1:.3f}\")\n","        return best_val_f1\n","\n","def visualize_hybrid_attention(model, dataloader, class_names, device, num_samples=2):\n","    \"\"\"Visualize hybrid model attention mechanisms\"\"\"\n","    model.eval()\n","\n","    fig, axes = plt.subplots(num_samples, 4, figsize=(20, 6*num_samples))\n","    if num_samples == 1:\n","        axes = axes.reshape(1, -1)\n","\n","    sample_count = 0\n","    with torch.no_grad():\n","        for data, targets in dataloader:\n","            if sample_count >= num_samples:\n","                break\n","\n","            data = data.to(device)\n","\n","            for i in range(min(data.size(0), num_samples - sample_count)):\n","                single_input = data[i:i+1]\n","                target_class = targets[i].item()\n","\n","                # Get features and attention\n","                _, _, features = model(single_input, return_features=True)\n","\n","                # ConvLSTM features visualization\n","                ax1 = axes[sample_count, 0]\n","                conv_feat = features['conv_features'][0].mean(dim=-1).cpu().numpy()\n","                ax1.plot(conv_feat, linewidth=2, color='blue')\n","                ax1.fill_between(range(len(conv_feat)), conv_feat, alpha=0.3, color='blue')\n","                ax1.set_title(f'ConvLSTM Features\\nClass: {class_names[target_class]}')\n","                ax1.set_xlabel('Time Step')\n","                ax1.set_ylabel('Feature Activation')\n","                ax1.grid(True, alpha=0.3)\n","\n","                # ViT attention weights (last layer)\n","                ax2 = axes[sample_count, 1]\n","                vit_attn = features['vit_attention'][-1][0].mean(dim=0).mean(dim=0).cpu().numpy()\n","                ax2.plot(vit_attn, linewidth=2, color='red')\n","                ax2.fill_between(range(len(vit_attn)), vit_attn, alpha=0.3, color='red')\n","                ax2.set_title(f'ViT Attention Weights\\nClass: {class_names[target_class]}')\n","                ax2.set_xlabel('Time Step')\n","                ax2.set_ylabel('Attention Weight')\n","                ax2.grid(True, alpha=0.3)\n","\n","                # Fused features\n","                ax3 = axes[sample_count, 2]\n","                fused_feat = features['fused_features'][0].mean(dim=-1).cpu().numpy()\n","                ax3.plot(fused_feat, linewidth=2, color='green')\n","                ax3.fill_between(range(len(fused_feat)), fused_feat, alpha=0.3, color='green')\n","                ax3.set_title(f'Fused Features\\nClass: {class_names[target_class]}')\n","                ax3.set_xlabel('Time Step')\n","                ax3.set_ylabel('Feature Activation')\n","                ax3.grid(True, alpha=0.3)\n","\n","                # Pooling weights\n","                ax4 = axes[sample_count, 3]\n","                pool_weights = features['pool_weights'][0].cpu().numpy()\n","                pool_names = ['Avg Pool', 'Max Pool', 'Adaptive Pool']\n","                bars = ax4.bar(pool_names, pool_weights)\n","                ax4.set_title(f'Pooling Strategy Weights\\nClass: {class_names[target_class]}')\n","                ax4.set_ylabel('Weight')\n","                for bar, weight in zip(bars, pool_weights):\n","                    height = bar.get_height()\n","                    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n","                            f'{weight:.3f}', ha='center', va='bottom')\n","\n","                sample_count += 1\n","                if sample_count >= num_samples:\n","                    break\n","\n","    plt.tight_layout()\n","    plt.savefig('convlstm_vit_hybrid_attention_analysis.png', dpi=150, bbox_inches='tight')\n","    plt.show()\n","\n","def plot_comprehensive_results(trainer, model_name=\"ConvLSTM_ViT_Hybrid\"):\n","    \"\"\"Plot comprehensive training results\"\"\"\n","    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n","\n","    epochs = range(1, len(trainer.train_losses) + 1)\n","\n","    # Loss curves\n","    ax1.plot(epochs, trainer.train_losses, 'b-', label='Training Loss', linewidth=2)\n","    ax1.plot(epochs, trainer.val_losses, 'r-', label='Validation Loss', linewidth=2)\n","    ax1.set_title(f'{model_name} - Loss Curves')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.legend()\n","    ax1.grid(True, alpha=0.3)\n","\n","    # Accuracy curves\n","    ax2.plot(epochs, trainer.train_accuracies, 'b-', label='Training Accuracy', linewidth=2)\n","    ax2.plot(epochs, trainer.val_accuracies, 'r-', label='Validation Accuracy', linewidth=2)\n","    ax2.set_title(f'{model_name} - Accuracy Curves')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel('Accuracy (%)')\n","    ax2.legend()\n","    ax2.grid(True, alpha=0.3)\n","\n","    # F1 Score progression\n","    ax3.plot(epochs, trainer.val_f1_scores, 'green', linewidth=2)\n","    ax3.set_title(f'{model_name} - Validation F1 Score')\n","    ax3.set_xlabel('Epoch')\n","    ax3.set_ylabel('F1 Score')\n","    ax3.grid(True, alpha=0.3)\n","\n","    # Train-validation gap analysis\n","    gaps = [t - v for t, v in zip(trainer.train_accuracies, trainer.val_accuracies)]\n","    ax4.plot(epochs, gaps, 'purple', linewidth=2)\n","    ax4.axhline(y=10, color='orange', linestyle='--', label='Warning Threshold')\n","    ax4.axhline(y=5, color='green', linestyle='--', label='Good Threshold')\n","    ax4.set_title(f'{model_name} - Train-Validation Gap')\n","    ax4.set_xlabel('Epoch')\n","    ax4.set_ylabel('Accuracy Gap (%)')\n","    ax4.legend()\n","    ax4.grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.savefig(f'{model_name.lower()}_training_results.png', dpi=150)\n","    plt.show()\n","\n","def prepare_dataset_for_hybrid(csv_path, sequence_length=150, overlap_ratio=0.35):\n","    \"\"\"Prepare dataset optimized for hybrid model\"\"\"\n","    logger.info(f\"📊 Loading data from: {csv_path}\")\n","\n","    df = pd.read_csv(csv_path)\n","    feature_columns = [col for col in df.columns if col != 'class']\n","\n","    # Advanced data cleaning\n","    original_size = len(df)\n","    df[feature_columns] = df[feature_columns].fillna(method='ffill').fillna(method='bfill').fillna(0)\n","    df[feature_columns] = df[feature_columns].replace([np.inf, -np.inf], 0)\n","\n","    # Remove statistical outliers\n","    for col in feature_columns:\n","        Q1 = df[col].quantile(0.25)\n","        Q3 = df[col].quantile(0.75)\n","        IQR = Q3 - Q1\n","        lower_bound = Q1 - 1.5 * IQR\n","        upper_bound = Q3 + 1.5 * IQR\n","        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n","\n","    logger.info(f\"After cleaning: {len(df)} samples ({len(df)/original_size*100:.1f}% retained)\")\n","\n","    # Filter classes with sufficient data\n","    min_samples = sequence_length * 4\n","    class_counts = df['class'].value_counts()\n","    valid_classes = class_counts[class_counts >= min_samples].index\n","    df = df[df['class'].isin(valid_classes)]\n","\n","    logger.info(f\"Valid classes after filtering: {list(valid_classes)}\")\n","\n","    sequences = []\n","    labels = []\n","\n","    # Create sequences with adaptive stride\n","    stride = max(1, int(sequence_length * (1 - overlap_ratio)))\n","\n","    for class_name in valid_classes:\n","        class_data = df[df['class'] == class_name].reset_index(drop=True)\n","\n","        for i in range(0, len(class_data) - sequence_length + 1, stride):\n","            sequence = class_data.iloc[i:i+sequence_length][feature_columns].values\n","\n","            if len(sequence) == sequence_length and not np.any(np.isnan(sequence)):\n","                # Quality check: ensure sequence has reasonable variance\n","                if np.std(sequence) > 1e-6:\n","                    sequences.append(sequence)\n","                    labels.append(class_name)\n","\n","    sequences = np.array(sequences)\n","    logger.info(f\"Total sequences created: {len(sequences)}\")\n","    logger.info(f\"Final class distribution: {dict(Counter(labels))}\")\n","\n","    return sequences, labels, len(feature_columns)\n","\n","def plot_confusion_matrices(val_targets, val_preds, test_targets, test_preds, target_names):\n","    \"\"\"Plot confusion matrices for both validation and test sets\"\"\"\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n","\n","    # Validation Confusion Matrix\n","    cm_val = confusion_matrix(val_targets, val_preds)\n","    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=target_names, yticklabels=target_names, ax=ax1)\n","    ax1.set_title('Validation Confusion Matrix', fontsize=16, fontweight='bold')\n","    ax1.set_ylabel('True Label', fontsize=12)\n","    ax1.set_xlabel('Predicted Label', fontsize=12)\n","    ax1.tick_params(axis='x', rotation=45)\n","\n","    # Test Confusion Matrix\n","    cm_test = confusion_matrix(test_targets, test_preds)\n","    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens',\n","                xticklabels=target_names, yticklabels=target_names, ax=ax2)\n","    ax2.set_title('Test Confusion Matrix', fontsize=16, fontweight='bold')\n","    ax2.set_ylabel('True Label', fontsize=12)\n","    ax2.set_xlabel('Predicted Label', fontsize=12)\n","    ax2.tick_params(axis='x', rotation=45)\n","\n","    plt.tight_layout()\n","    plt.savefig('convlstm_vit_hybrid_confusion_matrices.png', dpi=150)\n","    plt.show()\n","\n","def main():\n","    set_seed(42)\n","\n","    # Configuration parameters\n","    CSV_PATH = \"\"  # Update with your dataset path\n","    SEQUENCE_LENGTH = 150\n","    BATCH_SIZE = 16          # Optimized for hybrid model\n","    EPOCHS = 150             # Extended training\n","    VAL_SIZE = 0.15          # 15% for validation\n","    TEST_SIZE = 0.15         # 15% for test (70% remaining for training)\n","\n","    logger.info(\"🚀 ConvLSTM + Vision Transformer Hybrid Model Training Started!\")\n","    logger.info(f\"📊 Data split: 70% Train, 15% Validation, 15% Test\")\n","    logger.info(\"=\"*80)\n","\n","    # Enhanced data preparation\n","    sequences, labels, feature_count = prepare_dataset_for_hybrid(\n","        CSV_PATH, SEQUENCE_LENGTH, overlap_ratio=0.35\n","    )\n","\n","    if len(sequences) == 0:\n","        logger.error(\"❌ No valid sequences found!\")\n","        return\n","\n","    # First split: train+val (85%) and test (15%)\n","    X_temp, X_test, y_temp, y_test = train_test_split(\n","        sequences, labels, test_size=TEST_SIZE, random_state=42, stratify=labels\n","    )\n","\n","    # Second split: train (70%) and val (15%) from remaining 85%\n","    val_size_adjusted = VAL_SIZE / (1 - TEST_SIZE)\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_temp, y_temp, test_size=val_size_adjusted, random_state=42, stratify=y_temp\n","    )\n","\n","    logger.info(f\"\\n📊 Dataset Summary:\")\n","    logger.info(f\"   - Input Features: {feature_count}\")\n","    logger.info(f\"   - Sequence Length: {SEQUENCE_LENGTH}\")\n","    logger.info(f\"   - Training sequences: {len(X_train):,} ({len(X_train)/len(sequences)*100:.1f}%)\")\n","    logger.info(f\"   - Validation sequences: {len(X_val):,} ({len(X_val)/len(sequences)*100:.1f}%)\")\n","    logger.info(f\"   - Test sequences: {len(X_test):,} ({len(X_test)/len(sequences)*100:.1f}%)\")\n","\n","    # Create enhanced datasets\n","    train_dataset = EnhancedDiverSignDataset(X_train, y_train, train_mode=True, augment_prob=0.6)\n","    val_dataset = EnhancedDiverSignDataset(\n","        X_val, y_val, train_dataset.get_label_encoder(),\n","        train_dataset.get_scaler(), train_mode=False\n","    )\n","    test_dataset = EnhancedDiverSignDataset(\n","        X_test, y_test, train_dataset.get_label_encoder(),\n","        train_dataset.get_scaler(), train_mode=False\n","    )\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n","                             num_workers=2, pin_memory=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n","                           num_workers=2, pin_memory=True)\n","    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n","                            num_workers=2, pin_memory=True)\n","\n","    num_classes = len(train_dataset.get_label_encoder().classes_)\n","    class_names = train_dataset.get_label_encoder().classes_\n","\n","    logger.info(f\"   - Number of Classes: {num_classes}\")\n","    logger.info(f\"   - Class Names: {list(class_names)}\")\n","\n","    # Create ConvLSTM-ViT Hybrid model\n","    model = ConvLSTM_ViT_Hybrid(\n","        input_dim=feature_count,\n","        hidden_dim=128,           # Optimized size\n","        num_classes=num_classes,\n","        seq_len=SEQUENCE_LENGTH,\n","        dropout=0.25\n","    )\n","\n","    total_params = sum(p.numel() for p in model.parameters())\n","    logger.info(f\"\\n🤖 ConvLSTM-ViT Hybrid Model Configuration:\")\n","    logger.info(f\"   - Total Parameters: {total_params:,}\")\n","    logger.info(f\"   - ConvLSTM: 2 layers, bidirectional\")\n","    logger.info(f\"   - Vision Transformer: 4 layers, 8 heads\")\n","    logger.info(f\"   - Cross-Modal Fusion: 8 heads\")\n","    logger.info(f\"   - Hidden Dimension: 128\")\n","    logger.info(f\"   - Uncertainty Estimation: Enabled\")\n","\n","    # Initialize trainer\n","    trainer = HybridModelTrainer(\n","        model=model,\n","        class_weights=train_dataset.get_class_weights()\n","    )\n","\n","    logger.info(f\"\\n🔥 Starting Hybrid Training ({EPOCHS} epochs)...\")\n","    logger.info(\"=\"*80)\n","\n","    # Train the model\n","    best_f1 = trainer.train(train_loader, val_loader, epochs=EPOCHS)\n","\n","    # Load best model for evaluation\n","    checkpoint = torch.load(\"convlstm_vit_hybrid_best_model.pth\")\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    # Final validation evaluation\n","    val_loss, val_acc, val_f1, val_preds, val_targets = trainer.validate(val_loader)\n","\n","    # Final test evaluation\n","    test_loss, test_acc, test_f1, test_preds, test_targets = trainer.validate(test_loader)\n","\n","    # Training analysis\n","    final_train_acc = trainer.train_accuracies[-1]\n","    final_val_acc = trainer.val_accuracies[-1]\n","    accuracy_gap = final_train_acc - final_val_acc\n","\n","    logger.info(f\"\\n📊 ConvLSTM-ViT Hybrid Final Results:\")\n","    logger.info(\"=\"*60)\n","    logger.info(f\"   📊 VALIDATION:\")\n","    logger.info(f\"     - Accuracy: {val_acc:.2f}%\")\n","    logger.info(f\"     - F1 Score: {val_f1:.4f}\")\n","    logger.info(f\"   📊 TEST:\")\n","    logger.info(f\"     - Accuracy: {test_acc:.2f}%\")\n","    logger.info(f\"     - F1 Score: {test_f1:.4f}\")\n","    logger.info(f\"   📊 TRAINING ANALYSIS:\")\n","    logger.info(f\"     - Train-Validation Gap: {accuracy_gap:.2f}%\")\n","    logger.info(f\"     - Best Validation F1: {best_f1:.4f}\")\n","\n","    # Performance assessment\n","    if test_f1 >= 0.80:\n","        performance_status = \"🎉 Excellent Performance!\"\n","    elif test_f1 >= 0.70:\n","        performance_status = \"✅ Good Performance!\"\n","    elif test_f1 >= 0.60:\n","        performance_status = \"👍 Satisfactory Performance\"\n","    else:\n","        performance_status = \"⚠️ Performance Needs Improvement\"\n","\n","    logger.info(f\"   🎯 Overall Assessment: {performance_status}\")\n","\n","    # Classification reports\n","    target_names = train_dataset.get_label_encoder().classes_\n","\n","    print(f\"\\n📋 VALIDATION Classification Report:\")\n","    print(\"=\"*80)\n","    print(classification_report(val_targets, val_preds, target_names=target_names, digits=3))\n","\n","    print(f\"\\n📋 TEST Classification Report:\")\n","    print(\"=\"*80)\n","    print(classification_report(test_targets, test_preds, target_names=target_names, digits=3))\n","\n","    # Generate confusion matrices\n","    plot_confusion_matrices(val_targets, val_preds, test_targets, test_preds, target_names)\n","\n","    # Plot training results\n","    plot_comprehensive_results(trainer, \"ConvLSTM_ViT_Hybrid\")\n","\n","    # Visualize attention mechanisms\n","    logger.info(\"\\n🔍 Generating Attention Analysis...\")\n","    visualize_hybrid_attention(model, test_loader, class_names, trainer.device, num_samples=2)\n","\n","    # Model efficiency analysis\n","    logger.info(f\"\\n⚡ Model Efficiency Analysis:\")\n","    logger.info(f\"   - Parameters per Class: {total_params // num_classes:,}\")\n","    logger.info(f\"   - Accuracy per 1K Parameters: {test_acc / (total_params / 1000):.3f}\")\n","    logger.info(f\"   - F1 Score per 1M Parameters: {test_f1 / (total_params / 1000000):.3f}\")\n","\n","    # Save comprehensive results\n","    logger.info(f\"\\n💾 Saving Results...\")\n","\n","    torch.save({\n","        'model_state_dict': model.state_dict(),\n","        'model_config': {\n","            'input_dim': feature_count,\n","            'hidden_dim': 128,\n","            'num_classes': num_classes,\n","            'seq_len': SEQUENCE_LENGTH,\n","            'dropout': 0.25\n","        },\n","        'training_history': {\n","            'train_losses': trainer.train_losses,\n","            'val_losses': trainer.val_losses,\n","            'train_accuracies': trainer.train_accuracies,\n","            'val_accuracies': trainer.val_accuracies,\n","            'val_f1_scores': trainer.val_f1_scores\n","        },\n","        'final_results': {\n","            'test_accuracy': test_acc,\n","            'test_f1': test_f1,\n","            'validation_accuracy': val_acc,\n","            'validation_f1': val_f1,\n","            'best_val_f1': best_f1,\n","            'accuracy_gap': accuracy_gap\n","        }\n","    }, 'convlstm_vit_hybrid_final_model.pth')\n","\n","    logger.info(\"✅ ConvLSTM-ViT Hybrid Training Completed Successfully!\")\n","    logger.info(f\"📁 Files saved:\")\n","    logger.info(f\"   - convlstm_vit_hybrid_final_model.pth: Complete model\")\n","    logger.info(f\"   - convlstm_vit_hybrid_confusion_matrices.png: Confusion matrices\")\n","    logger.info(f\"   - convlstm_vit_hybrid_training_results.png: Training curves\")\n","    logger.info(f\"   - convlstm_vit_hybrid_attention_analysis.png: Attention visualization\")\n","\n","    logger.info(f\"\\n🏆 FINAL PERFORMANCE SUMMARY:\")\n","    logger.info(f\"🎯 Test F1 Score: {test_f1:.4f}\")\n","    logger.info(f\"🎯 Test Accuracy: {test_acc:.2f}%\")\n","    logger.info(f\"🎯 Model Parameters: {total_params:,}\")\n","\n","    return trainer, model, train_dataset, val_targets, val_preds, test_targets, test_preds\n","\n","if __name__ == \"__main__\":\n","    trainer, model, dataset, val_targets, val_preds, test_targets, test_preds = main()"],"metadata":{"id":"c-VB7ztOCZOE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ConvLSTM + Vision Transformer Hybrid Model with Enhanced 5-Fold Cross Validation - COMPLETE CODE\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import os\n","import logging\n","import random\n","from collections import Counter\n","import math\n","import warnings\n","from scipy import stats\n","warnings.filterwarnings('ignore')\n","\n","# Logging setup\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","def set_seed(seed=42):\n","    \"\"\"Set random seeds for reproducibility\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","def prepare_dataset_for_hybrid(csv_path, sequence_length=150, overlap_ratio=0.35):\n","    \"\"\"Prepare dataset optimized for hybrid model\"\"\"\n","    logger.info(f\"📊 Loading data from: {csv_path}\")\n","\n","    df = pd.read_csv(csv_path)\n","    feature_columns = [col for col in df.columns if col != 'class']\n","\n","    # Advanced data cleaning\n","    original_size = len(df)\n","    df[feature_columns] = df[feature_columns].fillna(method='ffill').fillna(method='bfill').fillna(0)\n","    df[feature_columns] = df[feature_columns].replace([np.inf, -np.inf], 0)\n","\n","    # Remove statistical outliers\n","    for col in feature_columns:\n","        Q1 = df[col].quantile(0.25)\n","        Q3 = df[col].quantile(0.75)\n","        IQR = Q3 - Q1\n","        lower_bound = Q1 - 1.5 * IQR\n","        upper_bound = Q3 + 1.5 * IQR\n","        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n","\n","    logger.info(f\"After cleaning: {len(df)} samples ({len(df)/original_size*100:.1f}% retained)\")\n","\n","    # Filter classes with sufficient data\n","    min_samples = sequence_length * 4\n","    class_counts = df['class'].value_counts()\n","    valid_classes = class_counts[class_counts >= min_samples].index\n","    df = df[df['class'].isin(valid_classes)]\n","\n","    logger.info(f\"Valid classes after filtering: {list(valid_classes)}\")\n","\n","    sequences = []\n","    labels = []\n","\n","    # Create sequences with adaptive stride\n","    stride = max(1, int(sequence_length * (1 - overlap_ratio)))\n","\n","    for class_name in valid_classes:\n","        class_data = df[df['class'] == class_name].reset_index(drop=True)\n","\n","        for i in range(0, len(class_data) - sequence_length + 1, stride):\n","            sequence = class_data.iloc[i:i+sequence_length][feature_columns].values\n","\n","            if len(sequence) == sequence_length and not np.any(np.isnan(sequence)):\n","                # Quality check: ensure sequence has reasonable variance\n","                if np.std(sequence) > 1e-6:\n","                    sequences.append(sequence)\n","                    labels.append(class_name)\n","\n","    sequences = np.array(sequences)\n","    logger.info(f\"Total sequences created: {len(sequences)}\")\n","    logger.info(f\"Final class distribution: {dict(Counter(labels))}\")\n","\n","    return sequences, labels, len(feature_columns)\n","\n","class EnhancedDiverSignDataset(Dataset):\n","    \"\"\"Enhanced dataset with advanced augmentation for hybrid model\"\"\"\n","    def __init__(self, sequences, labels, label_encoder=None, scaler=None,\n","                 train_mode=True, augment_prob=0.4):\n","\n","        # Label encoding\n","        if label_encoder is None:\n","            self.label_encoder = LabelEncoder()\n","            encoded_labels = self.label_encoder.fit_transform(labels)\n","        else:\n","            self.label_encoder = label_encoder\n","            encoded_labels = self.label_encoder.transform(labels)\n","\n","        # Advanced data scaling\n","        if scaler is None:\n","            self.scaler = StandardScaler()\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.fit_transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","        else:\n","            self.scaler = scaler\n","            reshaped = sequences.reshape(-1, sequences.shape[-1])\n","            scaled_reshaped = self.scaler.transform(reshaped)\n","            scaled_sequences = scaled_reshaped.reshape(sequences.shape)\n","\n","        self.sequences = torch.FloatTensor(scaled_sequences)\n","        self.labels = torch.LongTensor(encoded_labels)\n","        self.train_mode = train_mode\n","        self.augment_prob = augment_prob\n","\n","        # Enhanced class weights using effective number of samples\n","        class_counts = Counter(encoded_labels)\n","        total_samples = len(encoded_labels)\n","\n","        # Effective number of samples for class balancing\n","        beta = 0.9999\n","        effective_nums = [(1 - beta**class_counts[i]) / (1 - beta) for i in range(len(class_counts))]\n","        weights = [1.0 / effective_nums[i] for i in range(len(class_counts))]\n","        sum_weights = sum(weights)\n","        self.class_weights = torch.FloatTensor([w * len(weights) / sum_weights for w in weights])\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        sequence = self.sequences[idx].clone()\n","        label = self.labels[idx]\n","\n","        # Apply sophisticated augmentation during training\n","        if self.train_mode and random.random() < self.augment_prob:\n","            sequence = self._apply_hybrid_augmentation(sequence)\n","\n","        return sequence, label\n","\n","    def _apply_hybrid_augmentation(self, sequence):\n","        \"\"\"Hybrid-specific augmentation techniques\"\"\"\n","        aug_techniques = ['noise', 'temporal_mask', 'feature_dropout', 'mixup', 'gaussian_blur']\n","        selected_augs = random.sample(aug_techniques, k=random.randint(1, 2))\n","\n","        for aug_type in selected_augs:\n","            if aug_type == 'noise':\n","                # Adaptive Gaussian noise\n","                noise_std = torch.std(sequence) * 0.05\n","                noise = torch.randn_like(sequence) * noise_std\n","                sequence = sequence + noise\n","\n","            elif aug_type == 'temporal_mask':\n","                # Temporal masking (similar to SpecAugment)\n","                mask_length = random.randint(5, 15)\n","                mask_start = random.randint(0, max(0, sequence.size(0) - mask_length))\n","                sequence[mask_start:mask_start + mask_length] *= 0.1\n","\n","            elif aug_type == 'feature_dropout':\n","                # Feature channel dropout\n","                num_features_to_drop = random.randint(1, sequence.size(1) // 4)\n","                features_to_drop = random.sample(range(sequence.size(1)), num_features_to_drop)\n","                sequence[:, features_to_drop] *= 0.1\n","\n","            elif aug_type == 'mixup':\n","                # Temporal mixup within sequence\n","                alpha = 0.2\n","                lam = np.random.beta(alpha, alpha)\n","                rand_index = torch.randperm(sequence.size(0))\n","                sequence = lam * sequence + (1 - lam) * sequence[rand_index]\n","\n","            elif aug_type == 'gaussian_blur':\n","                # 1D Gaussian blur for temporal smoothing\n","                kernel_size = 3\n","                sigma = 0.5\n","                sequence = self._gaussian_blur_1d(sequence, kernel_size, sigma)\n","\n","        return torch.clamp(sequence, -5, 5)  # Prevent extreme values\n","\n","    def _gaussian_blur_1d(self, tensor, kernel_size, sigma):\n","        \"\"\"Apply 1D Gaussian blur to temporal sequence\"\"\"\n","        channels = tensor.size(1)\n","\n","        # Create Gaussian kernel\n","        x = torch.arange(kernel_size, dtype=torch.float32) - kernel_size // 2\n","        gaussian_kernel = torch.exp(-x.pow(2) / (2 * sigma**2))\n","        gaussian_kernel = gaussian_kernel / gaussian_kernel.sum()\n","\n","        # Apply convolution for each feature channel\n","        blurred = F.conv1d(\n","            tensor.transpose(0, 1).unsqueeze(0),\n","            gaussian_kernel.unsqueeze(0).unsqueeze(0).repeat(channels, 1, 1),\n","            padding=kernel_size // 2,\n","            groups=channels\n","        )\n","\n","        return blurred.squeeze(0).transpose(0, 1)\n","\n","    def get_label_encoder(self):\n","        return self.label_encoder\n","\n","    def get_scaler(self):\n","        return self.scaler\n","\n","    def get_class_weights(self):\n","        return self.class_weights\n","\n","class ConvLSTMCell(nn.Module):\n","    \"\"\"ConvLSTM Cell for spatio-temporal processing\"\"\"\n","    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True):\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","        self.kernel_size = kernel_size\n","        self.padding = kernel_size // 2\n","        self.bias = bias\n","\n","        # Convolutional gates\n","        self.conv = nn.Conv1d(\n","            in_channels=self.input_dim + self.hidden_dim,\n","            out_channels=4 * self.hidden_dim,\n","            kernel_size=self.kernel_size,\n","            padding=self.padding,\n","            bias=self.bias\n","        )\n","\n","    def forward(self, input_tensor, cur_state):\n","        h_cur, c_cur = cur_state\n","\n","        # Ensure both tensors have the same spatial dimension\n","        combined = torch.cat([input_tensor, h_cur], dim=1)\n","\n","        # Convolutional gates\n","        combined_conv = self.conv(combined)\n","\n","        # Split into gates\n","        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n","\n","        # Apply gates\n","        i = torch.sigmoid(cc_i)\n","        f = torch.sigmoid(cc_f)\n","        o = torch.sigmoid(cc_o)\n","        g = torch.tanh(cc_g)\n","\n","        # Update cell state\n","        c_next = f * c_cur + i * g\n","        h_next = o * torch.tanh(c_next)\n","\n","        return h_next, c_next\n","\n","    def init_hidden(self, batch_size, device):\n","        \"\"\"Initialize hidden and cell states\"\"\"\n","        return (torch.zeros(batch_size, self.hidden_dim, 1, device=device),\n","                torch.zeros(batch_size, self.hidden_dim, 1, device=device))\n","\n","class ConvLSTM(nn.Module):\n","    \"\"\"ConvLSTM module for temporal-spatial feature extraction\"\"\"\n","    def __init__(self, input_dim, hidden_dims, kernel_sizes, num_layers,\n","                 bidirectional=True, dropout=0.2):\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.hidden_dims = hidden_dims if isinstance(hidden_dims, list) else [hidden_dims] * num_layers\n","        self.kernel_sizes = kernel_sizes if isinstance(kernel_sizes, list) else [kernel_sizes] * num_layers\n","        self.num_layers = num_layers\n","        self.bidirectional = bidirectional\n","        self.dropout = dropout\n","\n","        # Create ConvLSTM layers\n","        cell_list = []\n","        for i in range(num_layers):\n","            cur_input_dim = self.input_dim if i == 0 else self.hidden_dims[i-1]\n","            if self.bidirectional and i > 0:\n","                cur_input_dim = self.hidden_dims[i-1] * 2\n","\n","            cell_list.append(ConvLSTMCell(\n","                input_dim=cur_input_dim,\n","                hidden_dim=self.hidden_dims[i],\n","                kernel_size=self.kernel_sizes[i]\n","            ))\n","\n","        self.cell_list = nn.ModuleList(cell_list)\n","        self.dropout_layers = nn.ModuleList([nn.Dropout(dropout) for _ in range(num_layers)])\n","\n","    def forward(self, input_tensor):\n","        \"\"\"Forward pass through ConvLSTM\"\"\"\n","        batch_size, seq_len, _ = input_tensor.shape\n","        device = input_tensor.device\n","\n","        # Transform input for conv processing: [batch, features, seq_len]\n","        input_tensor = input_tensor.transpose(1, 2)\n","\n","        layer_output_list = []\n","        last_state_list = []\n","\n","        cur_layer_input = input_tensor\n","\n","        for layer_idx in range(self.num_layers):\n","            # Initialize hidden states\n","            h, c = self.cell_list[layer_idx].init_hidden(batch_size, device)\n","\n","            # Forward direction\n","            output_inner = []\n","            for t in range(seq_len):\n","                # Extract single timestep: [batch, features, 1]\n","                timestep_input = cur_layer_input[:, :, t:t+1]\n","                h, c = self.cell_list[layer_idx](timestep_input, (h, c))\n","                output_inner.append(h)\n","\n","            # Concatenate outputs: [batch, hidden_dim, seq_len]\n","            forward_output = torch.cat(output_inner, dim=2)\n","\n","            if self.bidirectional:\n","                # Backward direction\n","                h_back, c_back = self.cell_list[layer_idx].init_hidden(batch_size, device)\n","                output_inner_back = []\n","\n","                for t in reversed(range(seq_len)):\n","                    timestep_input = cur_layer_input[:, :, t:t+1]\n","                    h_back, c_back = self.cell_list[layer_idx](timestep_input, (h_back, c_back))\n","                    output_inner_back.append(h_back)\n","\n","                # Reverse and concatenate\n","                backward_output = torch.cat(output_inner_back[::-1], dim=2)\n","                layer_output = torch.cat([forward_output, backward_output], dim=1)\n","            else:\n","                layer_output = forward_output\n","\n","            # Apply dropout\n","            if layer_idx < self.num_layers - 1:\n","                layer_output = self.dropout_layers[layer_idx](layer_output)\n","\n","            layer_output_list.append(layer_output)\n","            last_state_list.append((h, c))\n","            cur_layer_input = layer_output\n","\n","        return layer_output_list, last_state_list\n","\n","class MultiHeadSelfAttention(nn.Module):\n","    \"\"\"Multi-head self-attention mechanism for Vision Transformer\"\"\"\n","    def __init__(self, embed_dim, num_heads, dropout=0.1):\n","        super().__init__()\n","        assert embed_dim % num_heads == 0\n","\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.head_dim = embed_dim // num_heads\n","        self.scale = self.head_dim ** -0.5\n","\n","        self.qkv = nn.Linear(embed_dim, embed_dim * 3, bias=False)\n","        self.attn_dropout = nn.Dropout(dropout)\n","        self.proj = nn.Linear(embed_dim, embed_dim)\n","        self.proj_dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        B, N, C = x.shape\n","\n","        # Generate Q, K, V\n","        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n","        q, k, v = qkv[0], qkv[1], qkv[2]\n","\n","        # Scaled dot-product attention\n","        attn = (q @ k.transpose(-2, -1)) * self.scale\n","        attn = F.softmax(attn, dim=-1)\n","        attn = self.attn_dropout(attn)\n","\n","        # Apply attention to values\n","        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n","        x = self.proj(x)\n","        x = self.proj_dropout(x)\n","\n","        return x, attn\n","\n","class TransformerBlock(nn.Module):\n","    \"\"\"Transformer block with multi-head attention and MLP\"\"\"\n","    def __init__(self, embed_dim, num_heads, mlp_ratio=4.0, dropout=0.1):\n","        super().__init__()\n","\n","        self.norm1 = nn.LayerNorm(embed_dim)\n","        self.attn = MultiHeadSelfAttention(embed_dim, num_heads, dropout)\n","\n","        self.norm2 = nn.LayerNorm(embed_dim)\n","        mlp_hidden_dim = int(embed_dim * mlp_ratio)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(embed_dim, mlp_hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(mlp_hidden_dim, embed_dim),\n","            nn.Dropout(dropout)\n","        )\n","\n","    def forward(self, x):\n","        # Multi-head self-attention with residual connection\n","        attn_out, attn_weights = self.attn(self.norm1(x))\n","        x = x + attn_out\n","\n","        # MLP with residual connection\n","        x = x + self.mlp(self.norm2(x))\n","\n","        return x, attn_weights\n","\n","class VisionTransformer(nn.Module):\n","    \"\"\"Vision Transformer for sequence modeling\"\"\"\n","    def __init__(self, seq_len, embed_dim, num_heads, num_layers,\n","                 mlp_ratio=4.0, dropout=0.1):\n","        super().__init__()\n","\n","        self.seq_len = seq_len\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.num_layers = num_layers\n","\n","        # Positional embedding\n","        self.pos_embed = nn.Parameter(torch.randn(1, seq_len, embed_dim) * 0.02)\n","        self.pos_dropout = nn.Dropout(dropout)\n","\n","        # Transformer blocks\n","        self.blocks = nn.ModuleList([\n","            TransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n","            for _ in range(num_layers)\n","        ])\n","\n","        self.norm = nn.LayerNorm(embed_dim)\n","\n","    def forward(self, x):\n","        \"\"\"Forward pass through Vision Transformer\"\"\"\n","        B, N, C = x.shape\n","\n","        # Add positional embedding\n","        x = x + self.pos_embed[:, :N, :]\n","        x = self.pos_dropout(x)\n","\n","        # Process through transformer blocks\n","        attn_weights_list = []\n","        for block in self.blocks:\n","            x, attn_weights = block(x)\n","            attn_weights_list.append(attn_weights)\n","\n","        x = self.norm(x)\n","\n","        return x, attn_weights_list\n","\n","class CrossModalAttention(nn.Module):\n","    \"\"\"Cross-modal attention for fusing ConvLSTM and ViT features\"\"\"\n","    def __init__(self, conv_dim, vit_dim, fusion_dim, num_heads=8):\n","        super().__init__()\n","\n","        self.conv_dim = conv_dim\n","        self.vit_dim = vit_dim\n","        self.fusion_dim = fusion_dim\n","        self.num_heads = num_heads\n","\n","        # Project inputs to same dimension\n","        self.conv_proj = nn.Linear(conv_dim, fusion_dim)\n","        self.vit_proj = nn.Linear(vit_dim, fusion_dim)\n","\n","        # Cross-attention layers\n","        self.conv_to_vit_attn = nn.MultiheadAttention(fusion_dim, num_heads, batch_first=True)\n","        self.vit_to_conv_attn = nn.MultiheadAttention(fusion_dim, num_heads, batch_first=True)\n","\n","        # Fusion layers\n","        self.fusion_norm = nn.LayerNorm(fusion_dim * 2)\n","        self.fusion_mlp = nn.Sequential(\n","            nn.Linear(fusion_dim * 2, fusion_dim),\n","            nn.GELU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(fusion_dim, fusion_dim)\n","        )\n","\n","    def forward(self, conv_features, vit_features):\n","        \"\"\"Cross-modal attention fusion\"\"\"\n","        # Project to same dimension\n","        conv_proj = self.conv_proj(conv_features)\n","        vit_proj = self.vit_proj(vit_features)\n","\n","        # Cross-attention: ConvLSTM features attend to ViT features\n","        conv_attended, _ = self.conv_to_vit_attn(conv_proj, vit_proj, vit_proj)\n","\n","        # Cross-attention: ViT features attend to ConvLSTM features\n","        vit_attended, _ = self.vit_to_conv_attn(vit_proj, conv_proj, conv_proj)\n","\n","        # Concatenate and fuse\n","        combined = torch.cat([conv_attended, vit_attended], dim=-1)\n","        combined = self.fusion_norm(combined)\n","        fused = self.fusion_mlp(combined)\n","\n","        # Residual connection\n","        fused = fused + conv_proj + vit_proj\n","\n","        return fused\n","\n","class ConvLSTM_ViT_Hybrid(nn.Module):\n","    \"\"\"Hybrid model combining ConvLSTM and Vision Transformer\"\"\"\n","    def __init__(self, input_dim=69, hidden_dim=128, num_classes=10,\n","                 seq_len=150, dropout=0.2):\n","        super().__init__()\n","\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","        self.num_classes = num_classes\n","        self.seq_len = seq_len\n","\n","        # Input preprocessing\n","        self.input_projection = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.LayerNorm(hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout)\n","        )\n","\n","        # ConvLSTM branch for local temporal-spatial patterns\n","        self.convlstm = ConvLSTM(\n","            input_dim=hidden_dim,\n","            hidden_dims=[hidden_dim, hidden_dim],\n","            kernel_sizes=[3, 5],\n","            num_layers=2,\n","            bidirectional=True,\n","            dropout=dropout\n","        )\n","\n","        # Vision Transformer branch for global sequential patterns\n","        self.vit = VisionTransformer(\n","            seq_len=seq_len,\n","            embed_dim=hidden_dim,\n","            num_heads=8,\n","            num_layers=4,\n","            mlp_ratio=4.0,\n","            dropout=dropout\n","        )\n","\n","        # Cross-modal attention fusion\n","        conv_output_dim = hidden_dim * 2  # Bidirectional\n","        self.cross_modal_fusion = CrossModalAttention(\n","            conv_dim=conv_output_dim,\n","            vit_dim=hidden_dim,\n","            fusion_dim=hidden_dim,\n","            num_heads=8\n","        )\n","\n","        # Adaptive pooling strategies\n","        self.adaptive_pool = nn.ModuleList([\n","            nn.AdaptiveAvgPool1d(1),\n","            nn.AdaptiveMaxPool1d(1),\n","            nn.AdaptiveAvgPool1d(4)\n","        ])\n","\n","        # Attention-based pooling selection\n","        self.pool_attention = nn.Sequential(\n","            nn.Linear(hidden_dim * 3, hidden_dim),\n","            nn.Tanh(),\n","            nn.Linear(hidden_dim, 3),\n","            nn.Softmax(dim=-1)\n","        )\n","\n","        # Classification head with uncertainty estimation\n","        self.classifier = nn.Sequential(\n","            nn.LayerNorm(hidden_dim),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.GELU(),\n","            nn.Dropout(dropout * 0.5),\n","            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n","            nn.GELU(),\n","            nn.Dropout(dropout * 0.3),\n","            nn.Linear(hidden_dim // 4, num_classes)\n","        )\n","\n","        # Uncertainty head for confidence estimation\n","        self.uncertainty_head = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim // 4),\n","            nn.GELU(),\n","            nn.Linear(hidden_dim // 4, 1),\n","            nn.Sigmoid()\n","        )\n","\n","        self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        \"\"\"Initialize model weights using appropriate strategies\"\"\"\n","        for name, module in self.named_modules():\n","            if isinstance(module, nn.Linear):\n","                nn.init.xavier_uniform_(module.weight)\n","                if module.bias is not None:\n","                    nn.init.zeros_(module.bias)\n","            elif isinstance(module, nn.LayerNorm):\n","                nn.init.ones_(module.weight)\n","                nn.init.zeros_(module.bias)\n","            elif isinstance(module, nn.Conv1d):\n","                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n","\n","    def forward(self, x, return_features=False):\n","        \"\"\"Forward pass through hybrid model\"\"\"\n","        batch_size, seq_len, _ = x.shape\n","\n","        # Input preprocessing\n","        x_proj = self.input_projection(x)\n","\n","        # ConvLSTM branch for local patterns\n","        conv_outputs, _ = self.convlstm(x_proj)\n","        conv_features = conv_outputs[-1].transpose(1, 2)  # [batch, seq_len, conv_dim]\n","\n","        # Vision Transformer branch for global patterns\n","        vit_features, vit_attention_weights = self.vit(x_proj)\n","\n","        # Cross-modal fusion\n","        fused_features = self.cross_modal_fusion(conv_features, vit_features)\n","\n","        # Adaptive pooling\n","        pooled_features = []\n","        for pool in self.adaptive_pool:\n","            if pool.output_size == 1:\n","                pooled = pool(fused_features.transpose(1, 2)).squeeze(-1)\n","            else:\n","                pooled = pool(fused_features.transpose(1, 2)).transpose(1, 2).mean(dim=1)\n","            pooled_features.append(pooled)\n","\n","        # Attention-weighted pooling\n","        all_pooled = torch.cat(pooled_features, dim=-1)\n","        pool_weights = self.pool_attention(all_pooled)\n","\n","        final_features = sum(w.unsqueeze(-1) * feat for w, feat in zip(pool_weights.unbind(-1), pooled_features))\n","\n","        # Classification and uncertainty\n","        logits = self.classifier(final_features)\n","        uncertainty = self.uncertainty_head(final_features)\n","\n","        if return_features:\n","            return logits, uncertainty, {\n","                'conv_features': conv_features,\n","                'vit_features': vit_features,\n","                'fused_features': fused_features,\n","                'vit_attention': vit_attention_weights,\n","                'pool_weights': pool_weights\n","            }\n","\n","        return logits, uncertainty\n","\n","class HybridModelTrainer:\n","    \"\"\"Trainer for ConvLSTM-ViT Hybrid model\"\"\"\n","    def __init__(self, model, class_weights=None, device='cuda' if torch.cuda.is_available() else 'cpu'):\n","        self.model = model\n","        self.device = device\n","        self.model.to(device)\n","\n","        # Loss functions\n","        if class_weights is not None:\n","            class_weights = class_weights.to(device)\n","\n","        self.classification_criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n","        self.uncertainty_criterion = nn.MSELoss()\n","\n","        # Advanced optimizer with component-specific learning rates\n","        convlstm_params = []\n","        vit_params = []\n","        fusion_params = []\n","        classifier_params = []\n","\n","        for name, param in model.named_parameters():\n","            if 'convlstm' in name:\n","                convlstm_params.append(param)\n","            elif 'vit' in name:\n","                vit_params.append(param)\n","            elif 'cross_modal' in name or 'pool' in name:\n","                fusion_params.append(param)\n","            else:\n","                classifier_params.append(param)\n","\n","        self.optimizer = optim.AdamW([\n","            {'params': convlstm_params, 'lr': 5e-4, 'weight_decay': 0.01},\n","            {'params': vit_params, 'lr': 3e-4, 'weight_decay': 0.005},\n","            {'params': fusion_params, 'lr': 8e-4, 'weight_decay': 0.01},\n","            {'params': classifier_params, 'lr': 1e-3, 'weight_decay': 0.01}\n","        ], betas=(0.9, 0.95))\n","\n","        # Learning rate scheduler\n","        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","            self.optimizer, T_0=20, T_mult=2, eta_min=1e-6\n","        )\n","\n","        # Metrics tracking\n","        self.train_losses = []\n","        self.val_losses = []\n","        self.train_accuracies = []\n","        self.val_accuracies = []\n","        self.val_f1_scores = []\n","\n","    def train_epoch(self, dataloader):\n","        \"\"\"Training epoch with advanced loss computation\"\"\"\n","        self.model.train()\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","\n","        for batch_idx, (data, target) in enumerate(tqdm(dataloader, desc=\"Training\", leave=False)):\n","            data, target = data.to(self.device), target.to(self.device)\n","\n","            self.optimizer.zero_grad()\n","\n","            # Forward pass\n","            logits, uncertainty = self.model(data)\n","\n","            # Classification loss\n","            clf_loss = self.classification_criterion(logits, target)\n","\n","            # Uncertainty loss\n","            pred_probs = F.softmax(logits, dim=1)\n","            pred_confidence = pred_probs.max(dim=1)[0]\n","            uncertainty_target = 1.0 - pred_confidence\n","            unc_loss = self.uncertainty_criterion(uncertainty.squeeze(), uncertainty_target.detach())\n","\n","            # Combined loss\n","            total_loss_batch = clf_loss + 0.1 * unc_loss\n","\n","            # L2 regularization\n","            l2_reg = sum(param.pow(2).sum() for param in self.model.parameters())\n","            total_loss_batch += 1e-5 * l2_reg\n","\n","            total_loss_batch.backward()\n","\n","            # Gradient clipping\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n","\n","            self.optimizer.step()\n","\n","            # Statistics\n","            total_loss += total_loss_batch.item()\n","            _, predicted = logits.max(1)\n","            total += target.size(0)\n","            correct += predicted.eq(target).sum().item()\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_targets.extend(target.cpu().numpy())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","\n","        return avg_loss, accuracy, f1, all_preds, all_targets\n","\n","    def validate(self, dataloader):\n","        \"\"\"Validation with comprehensive metrics\"\"\"\n","        self.model.eval()\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_targets = []\n","        all_uncertainties = []\n","\n","        with torch.no_grad():\n","            for data, target in tqdm(dataloader, desc=\"Validating\", leave=False):\n","                data, target = data.to(self.device), target.to(self.device)\n","\n","                logits, uncertainty = self.model(data)\n","                loss = self.classification_criterion(logits, target)\n","\n","                total_loss += loss.item()\n","                _, predicted = logits.max(1)\n","                total += target.size(0)\n","                correct += predicted.eq(target).sum().item()\n","\n","                all_preds.extend(predicted.cpu().numpy())\n","                all_targets.extend(target.cpu().numpy())\n","                all_uncertainties.extend(uncertainty.cpu().numpy().flatten())\n","\n","        avg_loss = total_loss / len(dataloader)\n","        accuracy = 100. * correct / total\n","        f1 = f1_score(all_targets, all_preds, average='weighted')\n","        precision = precision_score(all_targets, all_preds, average='weighted', zero_division=0)\n","        recall = recall_score(all_targets, all_preds, average='weighted', zero_division=0)\n","\n","        return avg_loss, accuracy, f1, precision, recall, all_preds, all_targets, all_uncertainties\n","\n","    def train(self, train_loader, val_loader, epochs=100):\n","        \"\"\"Complete training loop with advanced monitoring\"\"\"\n","        best_val_f1 = 0\n","        patience = 20\n","        patience_counter = 0\n","\n","        for epoch in range(epochs):\n","            # Training\n","            train_loss, train_acc, train_f1, _, _ = self.train_epoch(train_loader)\n","\n","            # Validation\n","            val_loss, val_acc, val_f1, val_precision, val_recall, _, _, _ = self.validate(val_loader)\n","\n","            # Learning rate scheduling\n","            self.scheduler.step()\n","\n","            # Save metrics\n","            self.train_losses.append(train_loss)\n","            self.val_losses.append(val_loss)\n","            self.train_accuracies.append(train_acc)\n","            self.val_accuracies.append(val_acc)\n","            self.val_f1_scores.append(val_f1)\n","\n","            # Save best model\n","            if val_f1 > best_val_f1:\n","                best_val_f1 = val_f1\n","                patience_counter = 0\n","                self.best_model_state = self.model.state_dict().copy()\n","            else:\n","                patience_counter += 1\n","\n","            # Early stopping\n","            if patience_counter >= patience:\n","                logger.info(f\"      Early stopping at epoch {epoch + 1}\")\n","                break\n","\n","        # Load best model\n","        if hasattr(self, 'best_model_state'):\n","            self.model.load_state_dict(self.best_model_state)\n","\n","        return best_val_f1\n","\n","    def reset_model(self):\n","        \"\"\"Reset model weights for new fold\"\"\"\n","        self.model.apply(self._reset_weights)\n","\n","        # Reset optimizer\n","        convlstm_params = []\n","        vit_params = []\n","        fusion_params = []\n","        classifier_params = []\n","\n","        for name, param in self.model.named_parameters():\n","            if 'convlstm' in name:\n","                convlstm_params.append(param)\n","            elif 'vit' in name:\n","                vit_params.append(param)\n","            elif 'cross_modal' in name or 'pool' in name:\n","                fusion_params.append(param)\n","            else:\n","                classifier_params.append(param)\n","\n","        self.optimizer = optim.AdamW([\n","            {'params': convlstm_params, 'lr': 5e-4, 'weight_decay': 0.01},\n","            {'params': vit_params, 'lr': 3e-4, 'weight_decay': 0.005},\n","            {'params': fusion_params, 'lr': 8e-4, 'weight_decay': 0.01},\n","            {'params': classifier_params, 'lr': 1e-3, 'weight_decay': 0.01}\n","        ], betas=(0.9, 0.95))\n","\n","        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","            self.optimizer, T_0=20, T_mult=2, eta_min=1e-6\n","        )\n","\n","        # Reset metrics\n","        self.train_losses = []\n","        self.val_losses = []\n","        self.train_accuracies = []\n","        self.val_accuracies = []\n","        self.val_f1_scores = []\n","\n","    def _reset_weights(self, m):\n","        \"\"\"Reset weights for layers\"\"\"\n","        if isinstance(m, nn.Linear):\n","            nn.init.xavier_uniform_(m.weight)\n","            if m.bias is not None:\n","                nn.init.zeros_(m.bias)\n","        elif isinstance(m, nn.LayerNorm):\n","            nn.init.ones_(m.weight)\n","            nn.init.zeros_(m.bias)\n","        elif isinstance(m, nn.Conv1d):\n","            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","\n","def analyze_kfold_results(fold_results, class_names):\n","    \"\"\"Comprehensive analysis of K-fold results\"\"\"\n","\n","    # Extract metrics\n","    val_accuracies = [fold['val_accuracy'] for fold in fold_results]\n","    val_f1_scores = [fold['val_f1'] for fold in fold_results]\n","    val_precisions = [fold['val_precision'] for fold in fold_results]\n","    val_recalls = [fold['val_recall'] for fold in fold_results]\n","    test_accuracies = [fold['test_accuracy'] for fold in fold_results]\n","    test_f1_scores = [fold['test_f1'] for fold in fold_results]\n","    test_precisions = [fold['test_precision'] for fold in fold_results]\n","    test_recalls = [fold['test_recall'] for fold in fold_results]\n","\n","    # Calculate statistics\n","    val_acc_mean, val_acc_std = np.mean(val_accuracies), np.std(val_accuracies)\n","    val_f1_mean, val_f1_std = np.mean(val_f1_scores), np.std(val_f1_scores)\n","    val_prec_mean, val_prec_std = np.mean(val_precisions), np.std(val_precisions)\n","    val_rec_mean, val_rec_std = np.mean(val_recalls), np.std(val_recalls)\n","\n","    test_acc_mean, test_acc_std = np.mean(test_accuracies), np.std(test_accuracies)\n","    test_f1_mean, test_f1_std = np.mean(test_f1_scores), np.std(test_f1_scores)\n","    test_prec_mean, test_prec_std = np.mean(test_precisions), np.std(test_precisions)\n","    test_rec_mean, test_rec_std = np.mean(test_recalls), np.std(test_recalls)\n","\n","    logger.info(f\"\\n🎯 ENHANCED 5-FOLD CROSS VALIDATION RESULTS\")\n","    logger.info(\"=\"*80)\n","    logger.info(f\"📊 VALIDATION METRICS:\")\n","    logger.info(f\"   - Accuracy: {val_acc_mean:.2f}% ± {val_acc_std:.2f}%\")\n","    logger.info(f\"   - Precision: {val_prec_mean:.4f} ± {val_prec_std:.4f}\")\n","    logger.info(f\"   - Recall: {val_rec_mean:.4f} ± {val_rec_std:.4f}\")\n","    logger.info(f\"   - F1 Score: {val_f1_mean:.4f} ± {val_f1_std:.4f}\")\n","    logger.info(f\"   - Range: [{min(val_accuracies):.2f}% - {max(val_accuracies):.2f}%]\")\n","\n","    logger.info(f\"\\n📊 TEST METRICS:\")\n","    logger.info(f\"   - Accuracy: {test_acc_mean:.2f}% ± {test_acc_std:.2f}%\")\n","    logger.info(f\"   - Precision: {test_prec_mean:.4f} ± {test_prec_std:.4f}\")\n","    logger.info(f\"   - Recall: {test_rec_mean:.4f} ± {test_rec_std:.4f}\")\n","    logger.info(f\"   - F1 Score: {test_f1_mean:.4f} ± {test_f1_std:.4f}\")\n","    logger.info(f\"   - Range: [{min(test_accuracies):.2f}% - {max(test_accuracies):.2f}%]\")\n","\n","    # Performance assessment\n","    if test_f1_mean >= 0.85:\n","        performance_status = \"🏆 Outstanding Performance!\"\n","    elif test_f1_mean >= 0.80:\n","        performance_status = \"🎉 Excellent Performance!\"\n","    elif test_f1_mean >= 0.70:\n","        performance_status = \"✅ Good Performance!\"\n","    elif test_f1_mean >= 0.60:\n","        performance_status = \"👍 Satisfactory Performance\"\n","    else:\n","        performance_status = \"⚠️ Performance Needs Improvement\"\n","\n","    logger.info(f\"\\n🎯 Overall Assessment: {performance_status}\")\n","\n","    # Stability analysis\n","    cv_coefficient_test_f1 = test_f1_std / test_f1_mean if test_f1_mean > 0 else float('inf')\n","    if cv_coefficient_test_f1 < 0.05:\n","        stability_status = \"🔒 Extremely Stable\"\n","    elif cv_coefficient_test_f1 < 0.1:\n","        stability_status = \"🔒 Very Stable\"\n","    elif cv_coefficient_test_f1 < 0.2:\n","        stability_status = \"✅ Stable\"\n","    else:\n","        stability_status = \"⚠️ Variable\"\n","\n","    logger.info(f\"📊 Model Stability: {stability_status} (CV = {cv_coefficient_test_f1:.3f})\")\n","\n","    return {\n","        'val_accuracy_mean': val_acc_mean,\n","        'val_accuracy_std': val_acc_std,\n","        'val_precision_mean': val_prec_mean,\n","        'val_precision_std': val_prec_std,\n","        'val_recall_mean': val_rec_mean,\n","        'val_recall_std': val_rec_std,\n","        'val_f1_mean': val_f1_mean,\n","        'val_f1_std': val_f1_std,\n","        'test_accuracy_mean': test_acc_mean,\n","        'test_accuracy_std': test_acc_std,\n","        'test_precision_mean': test_prec_mean,\n","        'test_precision_std': test_prec_std,\n","        'test_recall_mean': test_rec_mean,\n","        'test_recall_std': test_rec_std,\n","        'test_f1_mean': test_f1_mean,\n","        'test_f1_std': test_f1_std,\n","        'stability_coefficient': cv_coefficient_test_f1,\n","        'performance_status': performance_status,\n","        'stability_status': stability_status\n","    }\n","\n","def plot_individual_fold_confusion_matrices(fold_results, class_names):\n","    \"\"\"Plot individual confusion matrices for each fold\"\"\"\n","    n_folds = len(fold_results)\n","    fig, axes = plt.subplots(2, n_folds, figsize=(5*n_folds, 10))\n","\n","    if n_folds == 1:\n","        axes = axes.reshape(2, 1)\n","\n","    for fold_idx, fold_result in enumerate(fold_results):\n","        # Validation confusion matrix\n","        cm_val = confusion_matrix(fold_result['val_targets'], fold_result['val_predictions'])\n","        sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues',\n","                    xticklabels=class_names, yticklabels=class_names,\n","                    ax=axes[0, fold_idx], cbar_kws={'shrink': 0.8})\n","        axes[0, fold_idx].set_title(f'Fold {fold_idx + 1} - Validation CM\\n'\n","                                   f'Acc: {fold_result[\"val_accuracy\"]:.1f}%',\n","                                   fontsize=12, fontweight='bold')\n","        axes[0, fold_idx].set_ylabel('True Label' if fold_idx == 0 else '')\n","        axes[0, fold_idx].set_xlabel('')\n","\n","        # Test confusion matrix\n","        cm_test = confusion_matrix(fold_result['test_targets'], fold_result['test_predictions'])\n","        sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens',\n","                    xticklabels=class_names, yticklabels=class_names,\n","                    ax=axes[1, fold_idx], cbar_kws={'shrink': 0.8})\n","        axes[1, fold_idx].set_title(f'Fold {fold_idx + 1} - Test CM\\n'\n","                                   f'Acc: {fold_result[\"test_accuracy\"]:.1f}%',\n","                                   fontsize=12, fontweight='bold')\n","        axes[1, fold_idx].set_ylabel('True Label' if fold_idx == 0 else '')\n","        axes[1, fold_idx].set_xlabel('Predicted Label')\n","\n","        # Rotate x-axis labels\n","        axes[0, fold_idx].tick_params(axis='x', rotation=45)\n","        axes[1, fold_idx].tick_params(axis='x', rotation=45)\n","\n","    plt.tight_layout()\n","    plt.savefig('individual_fold_confusion_matrices.png', dpi=150, bbox_inches='tight')\n","    plt.show()\n","\n","def plot_kfold_results(fold_results, model_name=\"ConvLSTM_ViT_Hybrid\"):\n","    \"\"\"Plot comprehensive K-fold cross-validation results\"\"\"\n","    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n","\n","    # Extract metrics\n","    fold_nums = list(range(1, len(fold_results) + 1))\n","    val_accuracies = [fold['val_accuracy'] for fold in fold_results]\n","    val_f1_scores = [fold['val_f1'] for fold in fold_results]\n","    test_accuracies = [fold['test_accuracy'] for fold in fold_results]\n","    test_f1_scores = [fold['test_f1'] for fold in fold_results]\n","    val_precision = [fold['val_precision'] for fold in fold_results]\n","    val_recall = [fold['val_recall'] for fold in fold_results]\n","    test_precision = [fold['test_precision'] for fold in fold_results]\n","    test_recall = [fold['test_recall'] for fold in fold_results]\n","\n","    # Validation Accuracy across folds\n","    bars1 = ax1.bar(fold_nums, val_accuracies, alpha=0.7, color='blue', label='Validation')\n","    ax1.axhline(y=np.mean(val_accuracies), color='red', linestyle='--',\n","                label=f'Mean: {np.mean(val_accuracies):.2f}±{np.std(val_accuracies):.2f}%')\n","    ax1.set_title(f'{model_name} - Validation Accuracy by Fold', fontsize=14, fontweight='bold')\n","    ax1.set_xlabel('Fold')\n","    ax1.set_ylabel('Accuracy (%)')\n","    ax1.legend()\n","    ax1.grid(True, alpha=0.3)\n","\n","    # Add value labels on bars\n","    for bar, acc in zip(bars1, val_accuracies):\n","        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n","                f'{acc:.1f}%', ha='center', va='bottom', fontsize=10)\n","\n","    # Test Accuracy across folds\n","    bars2 = ax2.bar(fold_nums, test_accuracies, alpha=0.7, color='green', label='Test')\n","    ax2.axhline(y=np.mean(test_accuracies), color='red', linestyle='--',\n","                label=f'Mean: {np.mean(test_accuracies):.2f}±{np.std(test_accuracies):.2f}%')\n","    ax2.set_title(f'{model_name} - Test Accuracy by Fold', fontsize=14, fontweight='bold')\n","    ax2.set_xlabel('Fold')\n","    ax2.set_ylabel('Accuracy (%)')\n","    ax2.legend()\n","    ax2.grid(True, alpha=0.3)\n","\n","    # Add value labels on bars\n","    for bar, acc in zip(bars2, test_accuracies):\n","        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n","                f'{acc:.1f}%', ha='center', va='bottom', fontsize=10)\n","\n","    # All metrics comparison\n","    x = np.arange(len(fold_nums))\n","    width = 0.15\n","\n","    ax3.bar(x - width*2, val_accuracies, width, label='Val Acc', alpha=0.8, color='lightblue')\n","    ax3.bar(x - width, test_accuracies, width, label='Test Acc', alpha=0.8, color='lightgreen')\n","    ax3.bar(x, val_f1_scores, width, label='Val F1', alpha=0.8, color='blue')\n","    ax3.bar(x + width, test_f1_scores, width, label='Test F1', alpha=0.8, color='green')\n","    ax3.bar(x + width*2, [f*100 for f in val_precision], width, label='Val Prec', alpha=0.8, color='orange')\n","\n","    ax3.set_title(f'{model_name} - All Metrics by Fold', fontsize=14, fontweight='bold')\n","    ax3.set_xlabel('Fold')\n","    ax3.set_ylabel('Score')\n","    ax3.set_xticks(x)\n","    ax3.set_xticklabels(fold_nums)\n","    ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n","    ax3.grid(True, alpha=0.3)\n","\n","    # Performance distribution violin plot\n","    data_for_violin = [val_accuracies, test_accuracies,\n","                      [f*100 for f in val_f1_scores], [f*100 for f in test_f1_scores]]\n","    labels_violin = ['Val Acc', 'Test Acc', 'Val F1×100', 'Test F1×100']\n","\n","    parts = ax4.violinplot(data_for_violin, positions=range(len(labels_violin)),\n","                          showmeans=True, showmedians=True)\n","    ax4.set_xticks(range(len(labels_violin)))\n","    ax4.set_xticklabels(labels_violin)\n","    ax4.set_title(f'{model_name} - Performance Distribution', fontsize=14, fontweight='bold')\n","    ax4.set_ylabel('Score')\n","    ax4.grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.savefig(f'{model_name.lower()}_5fold_results_detailed.png', dpi=150, bbox_inches='tight')\n","    plt.show()\n","\n","def create_fold_summary_table(fold_results, class_names):\n","    \"\"\"Create comprehensive fold summary table\"\"\"\n","\n","    # Create detailed results DataFrame\n","    summary_data = []\n","    for fold in fold_results:\n","        summary_data.append({\n","            'Fold': f\"Fold {fold['fold']}\",\n","            'Val_Accuracy': f\"{fold['val_accuracy']:.2f}%\",\n","            'Val_Precision': f\"{fold['val_precision']:.4f}\",\n","            'Val_Recall': f\"{fold['val_recall']:.4f}\",\n","            'Val_F1': f\"{fold['val_f1']:.4f}\",\n","            'Test_Accuracy': f\"{fold['test_accuracy']:.2f}%\",\n","            'Test_Precision': f\"{fold['test_precision']:.4f}\",\n","            'Test_Recall': f\"{fold['test_recall']:.4f}\",\n","            'Test_F1': f\"{fold['test_f1']:.4f}\",\n","            'Best_Val_F1': f\"{fold['best_val_f1']:.4f}\"\n","        })\n","\n","    # Calculate statistics\n","    val_accs = [fold['val_accuracy'] for fold in fold_results]\n","    val_precs = [fold['val_precision'] for fold in fold_results]\n","    val_recalls = [fold['val_recall'] for fold in fold_results]\n","    val_f1s = [fold['val_f1'] for fold in fold_results]\n","    test_accs = [fold['test_accuracy'] for fold in fold_results]\n","    test_precs = [fold['test_precision'] for fold in fold_results]\n","    test_recalls = [fold['test_recall'] for fold in fold_results]\n","    test_f1s = [fold['test_f1'] for fold in fold_results]\n","    best_val_f1s = [fold['best_val_f1'] for fold in fold_results]\n","\n","    # Add mean row\n","    summary_data.append({\n","        'Fold': 'Mean',\n","        'Val_Accuracy': f\"{np.mean(val_accs):.2f}%\",\n","        'Val_Precision': f\"{np.mean(val_precs):.4f}\",\n","        'Val_Recall': f\"{np.mean(val_recalls):.4f}\",\n","        'Val_F1': f\"{np.mean(val_f1s):.4f}\",\n","        'Test_Accuracy': f\"{np.mean(test_accs):.2f}%\",\n","        'Test_Precision': f\"{np.mean(test_precs):.4f}\",\n","        'Test_Recall': f\"{np.mean(test_recalls):.4f}\",\n","        'Test_F1': f\"{np.mean(test_f1s):.4f}\",\n","        'Best_Val_F1': f\"{np.mean(best_val_f1s):.4f}\"\n","    })\n","\n","    # Add std row\n","    summary_data.append({\n","        'Fold': 'Std',\n","        'Val_Accuracy': f\"±{np.std(val_accs):.2f}%\",\n","        'Val_Precision': f\"±{np.std(val_precs):.4f}\",\n","        'Val_Recall': f\"±{np.std(val_recalls):.4f}\",\n","        'Val_F1': f\"±{np.std(val_f1s):.4f}\",\n","        'Test_Accuracy': f\"±{np.std(test_accs):.2f}%\",\n","        'Test_Precision': f\"±{np.std(test_precs):.4f}\",\n","        'Test_Recall': f\"±{np.std(test_recalls):.4f}\",\n","        'Test_F1': f\"±{np.std(test_f1s):.4f}\",\n","        'Best_Val_F1': f\"±{np.std(best_val_f1s):.4f}\"\n","    })\n","\n","    # Create DataFrame\n","    results_df = pd.DataFrame(summary_data)\n","\n","    # Display as a formatted table\n","    print(f\"\\n{'='*120}\")\n","    print(f\"{'🎯 DETAILED 5-FOLD CROSS VALIDATION RESULTS TABLE':^120}\")\n","    print(f\"{'='*120}\")\n","    print(results_df.to_string(index=False))\n","    print(f\"{'='*120}\")\n","\n","    return results_df\n","\n","def create_aggregated_confusion_matrix(all_fold_predictions, class_names):\n","    \"\"\"Create aggregated confusion matrix from all folds\"\"\"\n","\n","    # Aggregate all predictions and targets\n","    all_val_preds = []\n","    all_val_targets = []\n","    all_test_preds = []\n","    all_test_targets = []\n","\n","    for fold_pred in all_fold_predictions:\n","        all_val_preds.extend(fold_pred['val_preds'])\n","        all_val_targets.extend(fold_pred['val_targets'])\n","        all_test_preds.extend(fold_pred['test_preds'])\n","        all_test_targets.extend(fold_pred['test_targets'])\n","\n","    # Plot aggregated confusion matrices\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n","\n","    # Validation Confusion Matrix (Aggregated)\n","    cm_val = confusion_matrix(all_val_targets, all_val_preds)\n","    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=class_names, yticklabels=class_names, ax=ax1,\n","                cbar_kws={'shrink': 0.8})\n","    ax1.set_title('Aggregated Validation Confusion Matrix (5-Fold CV)',\n","                  fontsize=16, fontweight='bold')\n","    ax1.set_ylabel('True Label', fontsize=12)\n","    ax1.set_xlabel('Predicted Label', fontsize=12)\n","    ax1.tick_params(axis='x', rotation=45)\n","\n","    # Test Confusion Matrix (Aggregated)\n","    cm_test = confusion_matrix(all_test_targets, all_test_preds)\n","    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens',\n","                xticklabels=class_names, yticklabels=class_names, ax=ax2,\n","                cbar_kws={'shrink': 0.8})\n","    ax2.set_title('Aggregated Test Confusion Matrix (5-Fold CV)',\n","                  fontsize=16, fontweight='bold')\n","    ax2.set_ylabel('True Label', fontsize=12)\n","    ax2.set_xlabel('Predicted Label', fontsize=12)\n","    ax2.tick_params(axis='x', rotation=45)\n","\n","    plt.tight_layout()\n","    plt.savefig('5fold_aggregated_confusion_matrices_enhanced.png', dpi=150, bbox_inches='tight')\n","    plt.show()\n","\n","    # Print aggregated classification reports\n","    print(f\"\\n📋 AGGREGATED VALIDATION Classification Report (5-Fold CV):\")\n","    print(\"=\"*90)\n","    print(classification_report(all_val_targets, all_val_preds,\n","                               target_names=class_names, digits=4))\n","\n","    print(f\"\\n📋 AGGREGATED TEST Classification Report (5-Fold CV):\")\n","    print(\"=\"*90)\n","    print(classification_report(all_test_targets, all_test_preds,\n","                               target_names=class_names, digits=4))\n","\n","def plot_fold_training_curves(fold_trainers, fold=None):\n","    \"\"\"Plot training curves for specific fold or all folds\"\"\"\n","    if fold is not None:\n","        # Plot single fold\n","        trainer = fold_trainers[fold]\n","        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n","\n","        epochs = range(1, len(trainer.train_losses) + 1)\n","\n","        # Loss curves\n","        ax1.plot(epochs, trainer.train_losses, 'b-', label='Training Loss', linewidth=2)\n","        ax1.plot(epochs, trainer.val_losses, 'r-', label='Validation Loss', linewidth=2)\n","        ax1.set_title(f'Fold {fold+1} - Loss Curves', fontsize=14, fontweight='bold')\n","        ax1.set_xlabel('Epoch')\n","        ax1.set_ylabel('Loss')\n","        ax1.legend()\n","        ax1.grid(True, alpha=0.3)\n","\n","        # Accuracy curves\n","        ax2.plot(epochs, trainer.train_accuracies, 'b-', label='Training Accuracy', linewidth=2)\n","        ax2.plot(epochs, trainer.val_accuracies, 'r-', label='Validation Accuracy', linewidth=2)\n","        ax2.set_title(f'Fold {fold+1} - Accuracy Curves', fontsize=14, fontweight='bold')\n","        ax2.set_xlabel('Epoch')\n","        ax2.set_ylabel('Accuracy (%)')\n","        ax2.legend()\n","        ax2.grid(True, alpha=0.3)\n","\n","        # F1 Score progression\n","        ax3.plot(epochs, trainer.val_f1_scores, 'green', linewidth=2, label='Validation F1')\n","        ax3.set_title(f'Fold {fold+1} - Validation F1 Score', fontsize=14, fontweight='bold')\n","        ax3.set_xlabel('Epoch')\n","        ax3.set_ylabel('F1 Score')\n","        ax3.legend()\n","        ax3.grid(True, alpha=0.3)\n","\n","        # Train-validation gap analysis\n","        gaps = [t - v for t, v in zip(trainer.train_accuracies, trainer.val_accuracies)]\n","        ax4.plot(epochs, gaps, 'purple', linewidth=2, label='Train-Val Gap')\n","        ax4.axhline(y=10, color='orange', linestyle='--', label='Warning Threshold (10%)')\n","        ax4.axhline(y=5, color='green', linestyle='--', label='Good Threshold (5%)')\n","        ax4.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n","        ax4.set_title(f'Fold {fold+1} - Overfitting Analysis', fontsize=14, fontweight='bold')\n","        ax4.set_xlabel('Epoch')\n","        ax4.set_ylabel('Accuracy Gap (%)')\n","        ax4.legend()\n","        ax4.grid(True, alpha=0.3)\n","\n","        plt.tight_layout()\n","        plt.savefig(f'fold_{fold+1}_training_curves_detailed.png', dpi=150, bbox_inches='tight')\n","        plt.show()\n","    else:\n","        # Plot all folds together\n","        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n","\n","        colors = ['blue', 'red', 'green', 'orange', 'purple']\n","\n","        for i, trainer in enumerate(fold_trainers):\n","            epochs = range(1, len(trainer.val_losses) + 1)\n","            ax1.plot(epochs, trainer.val_losses, color=colors[i],\n","                    label=f'Fold {i+1}', linewidth=2, alpha=0.7)\n","            ax2.plot(epochs, trainer.val_f1_scores, color=colors[i],\n","                    label=f'Fold {i+1}', linewidth=2, alpha=0.7)\n","\n","        ax1.set_title('Validation Loss - All Folds', fontsize=14, fontweight='bold')\n","        ax1.set_xlabel('Epoch')\n","        ax1.set_ylabel('Loss')\n","        ax1.legend()\n","        ax1.grid(True, alpha=0.3)\n","\n","        ax2.set_title('Validation F1 Score - All Folds', fontsize=14, fontweight='bold')\n","        ax2.set_xlabel('Epoch')\n","        ax2.set_ylabel('F1 Score')\n","        ax2.legend()\n","        ax2.grid(True, alpha=0.3)\n","\n","        plt.tight_layout()\n","        plt.savefig('all_folds_training_curves_comparison.png', dpi=150, bbox_inches='tight')\n","        plt.show()\n","\n","def plot_uncertainty_analysis(fold_results, class_names):\n","    \"\"\"Analyze prediction uncertainty across folds\"\"\"\n","    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n","\n","    # Collect all uncertainties\n","    all_val_uncertainties = []\n","    all_test_uncertainties = []\n","    all_val_correct = []\n","    all_test_correct = []\n","\n","    for fold in fold_results:\n","        val_correct = [1 if p == t else 0 for p, t in zip(fold['val_predictions'], fold['val_targets'])]\n","        test_correct = [1 if p == t else 0 for p, t in zip(fold['test_predictions'], fold['test_targets'])]\n","\n","        all_val_uncertainties.extend(fold['val_uncertainties'])\n","        all_test_uncertainties.extend(fold['test_uncertainties'])\n","        all_val_correct.extend(val_correct)\n","        all_test_correct.extend(test_correct)\n","\n","    # Uncertainty distribution\n","    ax1.hist(all_val_uncertainties, bins=50, alpha=0.7, label='Validation', color='blue', density=True)\n","    ax1.hist(all_test_uncertainties, bins=50, alpha=0.7, label='Test', color='green', density=True)\n","    ax1.set_title('Prediction Uncertainty Distribution', fontsize=14, fontweight='bold')\n","    ax1.set_xlabel('Uncertainty Score')\n","    ax1.set_ylabel('Density')\n","    ax1.legend()\n","    ax1.grid(True, alpha=0.3)\n","\n","    # Uncertainty vs Accuracy (Validation)\n","    correct_uncertainties = [u for u, c in zip(all_val_uncertainties, all_val_correct) if c == 1]\n","    incorrect_uncertainties = [u for u, c in zip(all_val_uncertainties, all_val_correct) if c == 0]\n","\n","    ax2.hist(correct_uncertainties, bins=30, alpha=0.7, label='Correct', color='green', density=True)\n","    ax2.hist(incorrect_uncertainties, bins=30, alpha=0.7, label='Incorrect', color='red', density=True)\n","    ax2.set_title('Validation: Uncertainty vs Prediction Correctness', fontsize=14, fontweight='bold')\n","    ax2.set_xlabel('Uncertainty Score')\n","    ax2.set_ylabel('Density')\n","    ax2.legend()\n","    ax2.grid(True, alpha=0.3)\n","\n","    # Uncertainty vs Accuracy (Test)\n","    test_correct_uncertainties = [u for u, c in zip(all_test_uncertainties, all_test_correct) if c == 1]\n","    test_incorrect_uncertainties = [u for u, c in zip(all_test_uncertainties, all_test_correct) if c == 0]\n","\n","    ax3.hist(test_correct_uncertainties, bins=30, alpha=0.7, label='Correct', color='green', density=True)\n","    ax3.hist(test_incorrect_uncertainties, bins=30, alpha=0.7, label='Incorrect', color='red', density=True)\n","    ax3.set_title('Test: Uncertainty vs Prediction Correctness', fontsize=14, fontweight='bold')\n","    ax3.set_xlabel('Uncertainty Score')\n","    ax3.set_ylabel('Density')\n","    ax3.legend()\n","    ax3.grid(True, alpha=0.3)\n","\n","    # Uncertainty calibration\n","    uncertainty_bins = np.linspace(0, 1, 11)\n","    bin_acc_val = []\n","    bin_conf_val = []\n","\n","    for i in range(len(uncertainty_bins) - 1):\n","        mask = (np.array(all_val_uncertainties) >= uncertainty_bins[i]) & \\\n","               (np.array(all_val_uncertainties) < uncertainty_bins[i+1])\n","        if mask.sum() > 0:\n","            bin_acc = np.mean(np.array(all_val_correct)[mask])\n","            bin_conf = 1 - np.mean(np.array(all_val_uncertainties)[mask])  # Convert uncertainty to confidence\n","            bin_acc_val.append(bin_acc)\n","            bin_conf_val.append(bin_conf)\n","        else:\n","            bin_acc_val.append(0)\n","            bin_conf_val.append(0)\n","\n","    ax4.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n","    ax4.plot(bin_conf_val, bin_acc_val, 'ro-', label='Model Calibration')\n","    ax4.set_title('Uncertainty Calibration', fontsize=14, fontweight='bold')\n","    ax4.set_xlabel('Confidence Score')\n","    ax4.set_ylabel('Accuracy')\n","    ax4.legend()\n","    ax4.grid(True, alpha=0.3)\n","    ax4.set_xlim([0, 1])\n","    ax4.set_ylim([0, 1])\n","\n","    plt.tight_layout()\n","    plt.savefig('uncertainty_analysis_5fold.png', dpi=150, bbox_inches='tight')\n","    plt.show()\n","\n","def run_5fold_cross_validation(sequences, labels, feature_count, config):\n","    \"\"\"Run enhanced 5-fold cross-validation with 15% test, 15% val, 70% train split\"\"\"\n","\n","    # First separate test set (15% of total data)\n","    X_remaining, X_test, y_remaining, y_test = train_test_split(\n","        sequences, labels, test_size=0.15, random_state=42, stratify=labels\n","    )\n","\n","    # Then separate validation set (15% of total data) from remaining 85%\n","    # 15% out of 85% = 15/85 ≈ 0.176\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_remaining, y_remaining, test_size=0.176, random_state=42, stratify=y_remaining\n","    )\n","\n","    # Initialize StratifiedKFold for train data only (70% of total)\n","    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","    fold_results = []\n","    fold_trainers = []\n","    all_fold_predictions = []\n","\n","    logger.info(f\"\\n🎯 Starting Enhanced 5-Fold Cross Validation with 15%-15%-70% Split (150 Epochs)\")\n","    logger.info(f\"   - Total samples: {len(sequences):,}\")\n","    logger.info(f\"   - Train samples: {len(X_train):,} (70%)\")\n","    logger.info(f\"   - Validation samples: {len(X_val):,} (15%)\")\n","    logger.info(f\"   - Test samples: {len(X_test):,} (15%)\")\n","    logger.info(\"=\"*80)\n","\n","    # Create global datasets (validation and test are same for all folds)\n","    le_global = LabelEncoder()\n","    le_global.fit(labels)\n","    num_classes = len(le_global.classes_)\n","\n","    # Pre-create validation and test datasets once\n","    val_dataset_base = EnhancedDiverSignDataset(\n","        X_val, y_val, train_mode=False, augment_prob=0.0\n","    )\n","    test_dataset_base = EnhancedDiverSignDataset(\n","        X_test, y_test,\n","        val_dataset_base.get_label_encoder(),\n","        val_dataset_base.get_scaler(),\n","        train_mode=False, augment_prob=0.0\n","    )\n","\n","    for fold, (train_idx, _) in enumerate(skf.split(X_train, y_train)):\n","        logger.info(f\"\\n🔥 FOLD {fold + 1}/5\")\n","        logger.info(\"=\"*50)\n","\n","        # Use only training data for this fold (70% of total data gets split 5 ways)\n","        X_train_fold = X_train[train_idx]\n","        y_train_fold = [y_train[i] for i in train_idx]\n","\n","        # Calculate actual percentages relative to total dataset\n","        train_percentage = (len(X_train_fold) / len(sequences)) * 100\n","        val_percentage = (len(X_val) / len(sequences)) * 100\n","        test_percentage = (len(X_test) / len(sequences)) * 100\n","\n","        logger.info(f\"   - Train: {len(X_train_fold):,} samples ({train_percentage:.1f}% of total)\")\n","        logger.info(f\"   - Val: {len(X_val):,} samples ({val_percentage:.1f}% of total)\")\n","        logger.info(f\"   - Test: {len(X_test):,} samples ({test_percentage:.1f}% of total)\")\n","\n","        # Create train dataset for current fold\n","        train_dataset = EnhancedDiverSignDataset(\n","            X_train_fold, y_train_fold,\n","            val_dataset_base.get_label_encoder(),\n","            val_dataset_base.get_scaler(),\n","            train_mode=True, augment_prob=0.6\n","        )\n","\n","        # Use the same validation and test datasets for all folds\n","        val_dataset = EnhancedDiverSignDataset(\n","            X_val, y_val,\n","            val_dataset_base.get_label_encoder(),\n","            val_dataset_base.get_scaler(),\n","            train_mode=False, augment_prob=0.0\n","        )\n","\n","        test_dataset = EnhancedDiverSignDataset(\n","            X_test, y_test,\n","            val_dataset_base.get_label_encoder(),\n","            val_dataset_base.get_scaler(),\n","            train_mode=False, augment_prob=0.0\n","        )\n","\n","        # Create data loaders\n","        train_loader = DataLoader(train_dataset, batch_size=config['batch_size'],\n","                                 shuffle=True, num_workers=2, pin_memory=True)\n","        val_loader = DataLoader(val_dataset, batch_size=config['batch_size'],\n","                               shuffle=False, num_workers=2, pin_memory=True)\n","        test_loader = DataLoader(test_dataset, batch_size=config['batch_size'],\n","                                shuffle=False, num_workers=2, pin_memory=True)\n","\n","        # Create model for current fold\n","        model = ConvLSTM_ViT_Hybrid(\n","            input_dim=feature_count,\n","            hidden_dim=config['hidden_dim'],\n","            num_classes=num_classes,\n","            seq_len=config['sequence_length'],\n","            dropout=config['dropout']\n","        )\n","\n","        # Create trainer\n","        trainer = HybridModelTrainer(\n","            model=model,\n","            class_weights=train_dataset.get_class_weights()\n","        )\n","\n","        logger.info(f\"   - Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n","\n","        # Train model\n","        logger.info(f\"   🚀 Training Fold {fold + 1} for {config['epochs']} epochs...\")\n","        best_val_f1 = trainer.train(train_loader, val_loader, epochs=config['epochs'])\n","\n","        # Evaluate on validation set\n","        val_loss, val_acc, val_f1, val_precision, val_recall, val_preds, val_targets, val_uncertainties = trainer.validate(val_loader)\n","\n","        # Evaluate on test set\n","        test_loss, test_acc, test_f1, test_precision, test_recall, test_preds, test_targets, test_uncertainties = trainer.validate(test_loader)\n","\n","        # Store results\n","        fold_result = {\n","            'fold': fold + 1,\n","            'train_size': len(X_train_fold),\n","            'val_size': len(X_val),\n","            'test_size': len(X_test),\n","            'train_percentage': train_percentage,\n","            'val_percentage': val_percentage,\n","            'test_percentage': test_percentage,\n","            'val_accuracy': val_acc,\n","            'val_precision': val_precision,\n","            'val_recall': val_recall,\n","            'val_f1': val_f1,\n","            'test_accuracy': test_acc,\n","            'test_precision': test_precision,\n","            'test_recall': test_recall,\n","            'test_f1': test_f1,\n","            'best_val_f1': best_val_f1,\n","            'val_predictions': val_preds,\n","            'val_targets': val_targets,\n","            'test_predictions': test_preds,\n","            'test_targets': test_targets,\n","            'val_uncertainties': val_uncertainties,\n","            'test_uncertainties': test_uncertainties\n","        }\n","\n","        fold_results.append(fold_result)\n","        fold_trainers.append(trainer)\n","        all_fold_predictions.append({\n","            'val_preds': val_preds,\n","            'val_targets': val_targets,\n","            'test_preds': test_preds,\n","            'test_targets': test_targets\n","        })\n","\n","        logger.info(f\"   ✅ Fold {fold + 1} Results:\")\n","        logger.info(f\"      - Validation: Acc={val_acc:.2f}%, Prec={val_precision:.4f}, Rec={val_recall:.4f}, F1={val_f1:.4f}\")\n","        logger.info(f\"      - Test: Acc={test_acc:.2f}%, Prec={test_precision:.4f}, Rec={test_recall:.4f}, F1={test_f1:.4f}\")\n","        logger.info(f\"      - Best Val F1: {best_val_f1:.4f}\")\n","\n","    return fold_results, fold_trainers, all_fold_predictions, le_global.classes_\n","\n","def main():\n","    set_seed(42)\n","\n","    # Configuration parameters with 150 epochs\n","    config = {\n","        'csv_path': \"\",  # Update with your dataset path\n","        'sequence_length': 150,\n","        'batch_size': 16,\n","        'epochs': 150,           # Increased to 150 epochs\n","        'hidden_dim': 128,\n","        'dropout': 0.25\n","    }\n","\n","    logger.info(\"🚀 Enhanced ConvLSTM + Vision Transformer Hybrid Model - 150 Epochs Training!\")\n","    logger.info(f\"   Training Configuration: {config['epochs']} epochs per fold\")\n","    logger.info(\"=\"*80)\n","\n","    # Enhanced data preparation\n","    sequences, labels, feature_count = prepare_dataset_for_hybrid(\n","        config['csv_path'], config['sequence_length'], overlap_ratio=0.35\n","    )\n","\n","    if len(sequences) == 0:\n","        logger.error(\"❌ No valid sequences found!\")\n","        return\n","\n","    logger.info(f\"\\n📊 Dataset Summary:\")\n","    logger.info(f\"   - Input Features: {feature_count}\")\n","    logger.info(f\"   - Sequence Length: {config['sequence_length']}\")\n","    logger.info(f\"   - Total sequences: {len(sequences):,}\")\n","    logger.info(f\"   - Classes: {len(set(labels))}\")\n","    logger.info(f\"   - Class distribution: {dict(Counter(labels))}\")\n","    logger.info(f\"\\n📊 Data Split Strategy:\")\n","    logger.info(f\"   - Train Set: 70% of total data (split into 5 folds)\")\n","    logger.info(f\"   - Validation Set: 15% of total data (fixed across all folds)\")\n","    logger.info(f\"   - Test Set: 15% of total data (fixed across all folds)\")\n","    logger.info(f\"   - Per fold: ~56% train (70%/5), 15% validation, 15% test\")\n","    logger.info(f\"   - Training Duration: {config['epochs']} epochs per fold\")\n","\n","    # Run enhanced 5-fold cross validation with 15%-15%-70% split\n","    fold_results, fold_trainers, all_fold_predictions, class_names = run_5fold_cross_validation(\n","        sequences, labels, feature_count, config\n","    )\n","\n","    # Comprehensive analysis\n","    summary_stats = analyze_kfold_results(fold_results, class_names)\n","\n","    # Generate comprehensive visualizations\n","    logger.info(f\"\\n📊 Generating Comprehensive Visualizations...\")\n","\n","    # 1. Individual fold confusion matrices\n","    plot_individual_fold_confusion_matrices(fold_results, class_names)\n","\n","    # 2. Enhanced K-fold results\n","    plot_kfold_results(fold_results, \"ConvLSTM_ViT_Hybrid_150_Epochs\")\n","\n","    # 3. Training curves for all folds\n","    plot_fold_training_curves(fold_trainers)\n","\n","    # 4. Best performing fold training curves\n","    best_fold_idx = np.argmax([fold['test_f1'] for fold in fold_results])\n","    logger.info(f\"   📈 Best performing fold: {best_fold_idx + 1} (Test F1: {fold_results[best_fold_idx]['test_f1']:.4f})\")\n","    plot_fold_training_curves(fold_trainers, fold=best_fold_idx)\n","\n","    # 5. Aggregated confusion matrices\n","    create_aggregated_confusion_matrix(all_fold_predictions, class_names)\n","\n","    # 6. Uncertainty analysis\n","    plot_uncertainty_analysis(fold_results, class_names)\n","\n","    # 7. Create comprehensive fold summary table\n","    results_df = create_fold_summary_table(fold_results, class_names)\n","\n","    # Save comprehensive results\n","    logger.info(f\"\\n💾 Saving Comprehensive Results...\")\n","\n","    # Save best model from best fold\n","    best_trainer = fold_trainers[best_fold_idx]\n","    torch.save({\n","        'fold_results': fold_results,\n","        'summary_statistics': summary_stats,\n","        'best_fold': best_fold_idx + 1,\n","        'best_model_state_dict': best_trainer.model.state_dict(),\n","        'model_config': {\n","            'input_dim': feature_count,\n","            'hidden_dim': config['hidden_dim'],\n","            'num_classes': len(class_names),\n","            'seq_len': config['sequence_length'],\n","            'dropout': config['dropout']\n","        },\n","        'training_config': config,\n","        'class_names': class_names,\n","        'split_info': {\n","            'train_split': 0.70,\n","            'val_split': 0.15,\n","            'test_split': 0.15,\n","            'epochs': config['epochs'],\n","            'description': '70% train (5-fold), 15% val (fixed), 15% test (fixed) - 150 epochs'\n","        }\n","    }, 'enhanced_convlstm_vit_hybrid_150_epochs_complete_results.pth')\n","\n","    # Save detailed results to CSV\n","    results_df.to_csv('enhanced_convlstm_vit_hybrid_150_epochs_detailed_results.csv', index=False)\n","\n","    # Create additional detailed analysis with split information\n","    detailed_results = []\n","    for fold in fold_results:\n","        detailed_results.append({\n","            'Fold': fold['fold'],\n","            'Epochs': config['epochs'],\n","            'Train_Size': fold['train_size'],\n","            'Val_Size': fold['val_size'],\n","            'Test_Size': fold['test_size'],\n","            'Train_Percentage': fold['train_percentage'],\n","            'Val_Percentage': fold['val_percentage'],\n","            'Test_Percentage': fold['test_percentage'],\n","            'Val_Accuracy': fold['val_accuracy'],\n","            'Val_Precision': fold['val_precision'],\n","            'Val_Recall': fold['val_recall'],\n","            'Val_F1': fold['val_f1'],\n","            'Test_Accuracy': fold['test_accuracy'],\n","            'Test_Precision': fold['test_precision'],\n","            'Test_Recall': fold['test_recall'],\n","            'Test_F1': fold['test_f1'],\n","            'Best_Val_F1': fold['best_val_f1'],\n","            'Avg_Val_Uncertainty': np.mean(fold['val_uncertainties']),\n","            'Avg_Test_Uncertainty': np.mean(fold['test_uncertainties']),\n","            'Val_Uncertainty_Std': np.std(fold['val_uncertainties']),\n","            'Test_Uncertainty_Std': np.std(fold['test_uncertainties'])\n","        })\n","\n","    detailed_df = pd.DataFrame(detailed_results)\n","    detailed_df.to_csv('enhanced_fold_analysis_150_epochs_with_uncertainty.csv', index=False)\n","\n","    # Statistical significance analysis\n","    if len(fold_results) >= 5:\n","        test_scores = [fold['test_f1'] for fold in fold_results]\n","\n","        # One-sample t-test against a baseline\n","        baseline = 0.5  # Random performance\n","        t_stat, p_value = stats.ttest_1samp(test_scores, baseline)\n","\n","        logger.info(f\"\\n📊 Statistical Significance Analysis:\")\n","        logger.info(f\"   - T-statistic vs random (0.5): {t_stat:.4f}\")\n","        logger.info(f\"   - P-value: {p_value:.6f}\")\n","\n","        if p_value < 0.001:\n","            significance = \"Highly Significant (p < 0.001) 🎯\"\n","        elif p_value < 0.01:\n","            significance = \"Significant (p < 0.01) ✅\"\n","        elif p_value < 0.05:\n","            significance = \"Marginally Significant (p < 0.05) 👍\"\n","        else:\n","            significance = \"Not Significant (p ≥ 0.05) ⚠️\"\n","\n","        logger.info(f\"   - Significance vs Random: {significance}\")\n","\n","        # Confidence intervals\n","        confidence_level = 0.95\n","        alpha = 1 - confidence_level\n","        n = len(test_scores)\n","        mean_score = np.mean(test_scores)\n","        sem = stats.sem(test_scores)\n","        t_critical = stats.t.ppf(1 - alpha/2, n-1)\n","        ci_lower = mean_score - t_critical * sem\n","        ci_upper = mean_score + t_critical * sem\n","\n","        logger.info(f\"   - 95% Confidence Interval: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n","\n","    # Final comprehensive summary\n","    logger.info(f\"\\n🏆 FINAL COMPREHENSIVE 5-FOLD CROSS VALIDATION SUMMARY (150 Epochs):\")\n","    logger.info(\"=\"*80)\n","    logger.info(f\"📊 Training Configuration:\")\n","    logger.info(f\"   - Epochs per fold: {config['epochs']}\")\n","    logger.info(f\"   - Total training epochs: {config['epochs'] * 5}\")\n","    logger.info(f\"   - Batch size: {config['batch_size']}\")\n","    logger.info(f\"   - Hidden dimension: {config['hidden_dim']}\")\n","    logger.info(f\"   - Dropout rate: {config['dropout']}\")\n","    logger.info(f\"📊 Data Split Summary:\")\n","    logger.info(f\"   - Train Set (per fold): {np.mean([fold['train_size'] for fold in fold_results]):.0f} samples ({np.mean([fold['train_percentage'] for fold in fold_results]):.1f}%)\")\n","    logger.info(f\"   - Validation Set: {fold_results[0]['val_size']:,} samples (15.0%)\")\n","    logger.info(f\"   - Test Set: {fold_results[0]['test_size']:,} samples (15.0%)\")\n","    logger.info(f\"🎯 Average Test Performance:\")\n","    logger.info(f\"   - Accuracy: {summary_stats['test_accuracy_mean']:.2f}% ± {summary_stats['test_accuracy_std']:.2f}%\")\n","    logger.info(f\"   - Precision: {summary_stats['test_precision_mean']:.4f} ± {summary_stats['test_precision_std']:.4f}\")\n","    logger.info(f\"   - Recall: {summary_stats['test_recall_mean']:.4f} ± {summary_stats['test_recall_std']:.4f}\")\n","    logger.info(f\"   - F1 Score: {summary_stats['test_f1_mean']:.4f} ± {summary_stats['test_f1_std']:.4f}\")\n","    logger.info(f\"🔒 Model Stability: {summary_stats['stability_status']}\")\n","    logger.info(f\"🎖️ Performance Level: {summary_stats['performance_status']}\")\n","    logger.info(f\"📁 Best Fold: {best_fold_idx + 1} (Test F1: {fold_results[best_fold_idx]['test_f1']:.4f})\")\n","\n","    logger.info(f\"\\n✅ Enhanced 5-Fold Cross Validation with 150 Epochs Completed Successfully!\")\n","\n","    # Generate Model Architecture Documentation\n","    logger.info(f\"\\n🏗️ GENERATING MODEL ARCHITECTURE DOCUMENTATION\")\n","    logger.info(\"=\"*80)\n","\n","    # Get the best model for architecture analysis\n","    best_model = fold_trainers[best_fold_idx].model\n","\n","    # Generate complete architecture documentation\n","    generate_complete_architecture_documentation(\n","        best_model,\n","        input_shape=(config['batch_size'], config['sequence_length'], feature_count)\n","    )\n","\n","    return fold_results, fold_trainers, all_fold_predictions, summary_stats, class_names\n","\n","def create_model_architecture_table(model, input_shape=(16, 150, 69)):\n","    \"\"\"Create detailed architecture table for ConvLSTM-ViT Hybrid model\"\"\"\n","    logger.info(\"🏗️ Creating ConvLSTM-ViT Hybrid Model Architecture Table\")\n","    logger.info(\"=\"*80)\n","\n","    try:\n","        # Try to import required packages\n","        from torchinfo import summary as detailed_summary\n","        torchinfo_available = True\n","    except ImportError:\n","        logger.warning(\"⚠️ torchinfo not available. Install with: pip install torchinfo\")\n","        torchinfo_available = False\n","\n","    # Method 1: Using torchinfo for detailed summary (if available)\n","    if torchinfo_available:\n","        logger.info(\"\\n📊 DETAILED MODEL SUMMARY:\")\n","        logger.info(\"-\"*60)\n","        try:\n","            model_stats = detailed_summary(\n","                model,\n","                input_size=input_shape,\n","                col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n","                verbose=0\n","            )\n","            logger.info(str(model_stats))\n","        except Exception as e:\n","            logger.warning(f\"Detailed summary failed: {e}\")\n","\n","    # Method 2: Manual architecture breakdown\n","    logger.info(f\"\\n📋 COMPONENT-WISE ARCHITECTURE BREAKDOWN:\")\n","    logger.info(\"-\"*60)\n","\n","    architecture_data = []\n","    total_params = 0\n","\n","    # Input Processing Layer\n","    input_proj_params = sum(p.numel() for p in model.input_projection.parameters())\n","    architecture_data.append({\n","        'Component': 'Input Projection',\n","        'Layer Type': 'Linear + LayerNorm + GELU + Dropout',\n","        'Input Shape': f'[B, {input_shape[1]}, {input_shape[2]}]',\n","        'Output Shape': f'[B, {input_shape[1]}, 128]',\n","        'Parameters': f'{input_proj_params:,}',\n","        'Description': 'Projects input features to hidden dimension'\n","    })\n","    total_params += input_proj_params\n","\n","    # ConvLSTM Branch\n","    convlstm_params = sum(p.numel() for p in model.convlstm.parameters())\n","    architecture_data.append({\n","        'Component': 'ConvLSTM Branch',\n","        'Layer Type': 'Bidirectional ConvLSTM (2 layers)',\n","        'Input Shape': f'[B, {input_shape[1]}, 128]',\n","        'Output Shape': f'[B, {input_shape[1]}, 256]',\n","        'Parameters': f'{convlstm_params:,}',\n","        'Description': 'Local temporal-spatial pattern extraction'\n","    })\n","    total_params += convlstm_params\n","\n","    # Vision Transformer Branch\n","    vit_params = sum(p.numel() for p in model.vit.parameters())\n","    architecture_data.append({\n","        'Component': 'Vision Transformer',\n","        'Layer Type': 'Multi-head Attention (4 layers, 8 heads)',\n","        'Input Shape': f'[B, {input_shape[1]}, 128]',\n","        'Output Shape': f'[B, {input_shape[1]}, 128]',\n","        'Parameters': f'{vit_params:,}',\n","        'Description': 'Global sequential dependency modeling'\n","    })\n","    total_params += vit_params\n","\n","    # Cross-Modal Fusion\n","    fusion_params = sum(p.numel() for p in model.cross_modal_fusion.parameters())\n","    architecture_data.append({\n","        'Component': 'Cross-Modal Fusion',\n","        'Layer Type': 'Cross-Attention + MLP',\n","        'Input Shape': '[B, 150, 256] + [B, 150, 128]',\n","        'Output Shape': f'[B, {input_shape[1]}, 128]',\n","        'Parameters': f'{fusion_params:,}',\n","        'Description': 'Fuses ConvLSTM and ViT features'\n","    })\n","    total_params += fusion_params\n","\n","    # Adaptive Pooling\n","    pooling_params = sum(p.numel() for p in model.adaptive_pool.parameters()) + \\\n","                     sum(p.numel() for p in model.pool_attention.parameters())\n","    architecture_data.append({\n","        'Component': 'Adaptive Pooling',\n","        'Layer Type': 'Multi-strategy Pooling + Attention',\n","        'Input Shape': f'[B, {input_shape[1]}, 128]',\n","        'Output Shape': '[B, 128]',\n","        'Parameters': f'{pooling_params:,}',\n","        'Description': 'Attention-weighted feature aggregation'\n","    })\n","    total_params += pooling_params\n","\n","    # Classification Head\n","    classifier_params = sum(p.numel() for p in model.classifier.parameters())\n","    architecture_data.append({\n","        'Component': 'Classification Head',\n","        'Layer Type': 'Multi-layer MLP + Dropout',\n","        'Input Shape': '[B, 128]',\n","        'Output Shape': f'[B, {model.num_classes}]',\n","        'Parameters': f'{classifier_params:,}',\n","        'Description': 'Final classification with uncertainty'\n","    })\n","    total_params += classifier_params\n","\n","    # Uncertainty Head\n","    uncertainty_params = sum(p.numel() for p in model.uncertainty_head.parameters())\n","    architecture_data.append({\n","        'Component': 'Uncertainty Head',\n","        'Layer Type': 'MLP + Sigmoid',\n","        'Input Shape': '[B, 128]',\n","        'Output Shape': '[B, 1]',\n","        'Parameters': f'{uncertainty_params:,}',\n","        'Description': 'Prediction confidence estimation'\n","    })\n","    total_params += uncertainty_params\n","\n","    # Create and display architecture table\n","    import pandas as pd\n","    df_arch = pd.DataFrame(architecture_data)\n","    logger.info(\"\\n\" + df_arch.to_string(index=False, max_colwidth=30))\n","\n","    logger.info(f\"\\n🔢 TOTAL PARAMETERS: {total_params:,}\")\n","    logger.info(f\"🎯 PARAMETERS PER CLASS: {total_params // model.num_classes:,}\")\n","\n","    return df_arch, total_params\n","\n","def create_layer_wise_parameter_table(model):\n","    \"\"\"Create detailed layer-wise parameter breakdown\"\"\"\n","    logger.info(f\"\\n📊 LAYER-WISE PARAMETER BREAKDOWN:\")\n","    logger.info(\"-\"*80)\n","\n","    layer_data = []\n","\n","    for name, module in model.named_modules():\n","        if len(list(module.children())) == 0:  # Leaf modules only\n","            num_params = sum(p.numel() for p in module.parameters())\n","            if num_params > 0:\n","                trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n","                layer_data.append({\n","                    'Layer Name': name,\n","                    'Layer Type': module.__class__.__name__,\n","                    'Parameters': f'{num_params:,}',\n","                    'Trainable': f'{trainable_params:,}',\n","                    'Percentage': f'{(num_params/sum(p.numel() for p in model.parameters()))*100:.2f}%'\n","                })\n","\n","    # Sort by parameter count\n","    layer_data.sort(key=lambda x: int(x['Parameters'].replace(',', '')), reverse=True)\n","\n","    # Show top 15 layers\n","    import pandas as pd\n","    df_layers = pd.DataFrame(layer_data[:15])\n","    logger.info(\"TOP 15 LAYERS BY PARAMETER COUNT:\")\n","    logger.info(df_layers.to_string(index=False))\n","\n","    return df_layers\n","\n","def create_computational_complexity_table(model, input_shape=(16, 150, 69)):\n","    \"\"\"Estimate computational complexity\"\"\"\n","    logger.info(f\"\\n⚡ COMPUTATIONAL COMPLEXITY ANALYSIS:\")\n","    logger.info(\"-\"*60)\n","\n","    # Parameter-based estimation\n","    total_params = sum(p.numel() for p in model.parameters())\n","    estimated_flops = total_params * input_shape[1] * 2  # Rough estimate\n","\n","    complexity_data = {\n","        'Total Parameters': f'{total_params:,}',\n","        'Estimated FLOPs': f'{estimated_flops:,}',\n","        'Model Size (MB)': f'{total_params * 4 / (1024**2):.2f}',\n","        'Memory per Sample (MB)': f'{(total_params + input_shape[1] * input_shape[2]) * 4 / (1024**2):.2f}'\n","    }\n","\n","    logger.info(\"COMPUTATIONAL METRICS:\")\n","    for key, value in complexity_data.items():\n","        logger.info(f\"  {key}: {value}\")\n","\n","    return complexity_data\n","\n","def create_academic_table_latex(df_arch, total_params, model):\n","    \"\"\"Generate LaTeX table for academic papers\"\"\"\n","\n","    latex_table = f\"\"\"\n","\\\\begin{{table*}}[ht]\n","\\\\centering\n","\\\\caption{{Architecture of the Proposed ConvLSTM-ViT Hybrid Model}}\n","\\\\label{{tab:model_architecture}}\n","\\\\begin{{tabular}}{{|l|l|l|l|r|l|}}\n","\\\\hline\n","\\\\textbf{{Component}} & \\\\textbf{{Layer Type}} & \\\\textbf{{Input Shape}} & \\\\textbf{{Output Shape}} & \\\\textbf{{Parameters}} & \\\\textbf{{Description}} \\\\\\\\\n","\\\\hline\n","\"\"\"\n","\n","    for _, row in df_arch.iterrows():\n","        # Escape LaTeX special characters\n","        component = row['Component'].replace('&', '\\\\&')\n","        layer_type = row['Layer Type'].replace('&', '\\\\&')\n","        description = row['Description'].replace('&', '\\\\&')\n","\n","        latex_table += f\"{component} & {layer_type} & {row['Input Shape']} & {row['Output Shape']} & {row['Parameters']} & {description} \\\\\\\\\\n\\\\hline\\n\"\n","\n","    latex_table += f\"\"\"\\\\multicolumn{{4}}{{|l|}}{{\\\\textbf{{Total Parameters}}}} & \\\\textbf{{{total_params:,}}} & - \\\\\\\\\n","\\\\hline\n","\\\\multicolumn{{6}}{{|l|}}{{B: Batch size, Input dimensions: [Batch, 150, {model.input_dim}], Output classes: {model.num_classes}}} \\\\\\\\\n","\\\\hline\n","\\\\end{{tabular}}\n","\\\\end{{table*}}\n","\"\"\"\n","\n","    logger.info(f\"\\n📝 LATEX TABLE FOR ACADEMIC PAPER:\")\n","    logger.info(\"-\"*60)\n","    logger.info(latex_table)\n","\n","    # Save to file\n","    try:\n","        with open('model_architecture_table.tex', 'w') as f:\n","            f.write(latex_table)\n","        logger.info(\"💾 LaTeX table saved as 'model_architecture_table.tex'\")\n","    except Exception as e:\n","        logger.warning(f\"Could not save LaTeX file: {e}\")\n","\n","    return latex_table\n","\n","def create_csv_export(df_arch, df_layers, complexity_data):\n","    \"\"\"Export all tables to CSV for easy manipulation\"\"\"\n","\n","    try:\n","        # Export architecture table\n","        df_arch.to_csv('model_architecture_summary.csv', index=False)\n","\n","        # Export layer details\n","        df_layers.to_csv('model_layer_details.csv', index=False)\n","\n","        # Export complexity data\n","        import pandas as pd\n","        complexity_df = pd.DataFrame(list(complexity_data.items()),\n","                                    columns=['Metric', 'Value'])\n","        complexity_df.to_csv('model_complexity_metrics.csv', index=False)\n","\n","        logger.info(f\"\\n💾 EXPORTED FILES:\")\n","        logger.info(\"  - model_architecture_summary.csv\")\n","        logger.info(\"  - model_layer_details.csv\")\n","        logger.info(\"  - model_complexity_metrics.csv\")\n","        logger.info(\"  - model_architecture_table.tex\")\n","\n","    except Exception as e:\n","        logger.warning(f\"Could not export CSV files: {e}\")\n","\n","def generate_complete_architecture_documentation(model, input_shape=(16, 150, 69)):\n","    \"\"\"Generate complete architecture documentation for academic paper\"\"\"\n","\n","    logger.info(\"🚀 GENERATING COMPLETE MODEL ARCHITECTURE DOCUMENTATION\")\n","    logger.info(\"=\"*80)\n","\n","    # 1. Main architecture table\n","    df_arch, total_params = create_model_architecture_table(model, input_shape)\n","\n","    # 2. Layer-wise breakdown\n","    df_layers = create_layer_wise_parameter_table(model)\n","\n","    # 3. Computational complexity\n","    complexity_data = create_computational_complexity_table(model, input_shape)\n","\n","    # 4. LaTeX table for paper\n","    latex_table = create_academic_table_latex(df_arch, total_params, model)\n","\n","    # 5. Export all data\n","    create_csv_export(df_arch, df_layers, complexity_data)\n","\n","    # 6. Component analysis\n","    logger.info(\"\\n📊 COMPONENT ANALYSIS:\")\n","    logger.info(\"-\" * 60)\n","\n","    components = {\n","        'Input Processing': sum(p.numel() for p in model.input_projection.parameters()),\n","        'ConvLSTM Branch': sum(p.numel() for p in model.convlstm.parameters()),\n","        'Vision Transformer': sum(p.numel() for p in model.vit.parameters()),\n","        'Cross-Modal Fusion': sum(p.numel() for p in model.cross_modal_fusion.parameters()),\n","        'Pooling Mechanism': sum(p.numel() for p in model.adaptive_pool.parameters()) +\n","                             sum(p.numel() for p in model.pool_attention.parameters()),\n","        'Classification Head': sum(p.numel() for p in model.classifier.parameters()),\n","        'Uncertainty Head': sum(p.numel() for p in model.uncertainty_head.parameters())\n","    }\n","\n","    total_params_check = sum(components.values())\n","\n","    for component, params in components.items():\n","        percentage = (params / total_params_check) * 100\n","        logger.info(f\"  {component:20}: {params:8,} parameters ({percentage:5.2f}%)\")\n","\n","    logger.info(f\"  {'Total':20}: {total_params_check:8,} parameters (100.00%)\")\n","\n","    # 7. Academic table format for direct use\n","    logger.info(f\"\\n📋 ACADEMIC PAPER TABLE FORMAT:\")\n","    logger.info(\"=\"*80)\n","\n","    academic_table = f\"\"\"\n","Table 1: ConvLSTM-ViT Hybrid Model Architecture\n","\n","Component              | Layer Type                        | Input Shape      | Output Shape     | Parameters\n","-----------------------|-----------------------------------|------------------|------------------|-------------\n","Input Projection      | Linear + LayerNorm + GELU        | [B, 150, {model.input_dim}]    | [B, 150, 128]   | {components['Input Processing']:,}\n","ConvLSTM Branch        | Bidirectional ConvLSTM (2 layers)| [B, 150, 128]   | [B, 150, 256]   | {components['ConvLSTM Branch']:,}\n","Vision Transformer     | Multi-head Attention (4 layers)  | [B, 150, 128]   | [B, 150, 128]   | {components['Vision Transformer']:,}\n","Cross-Modal Fusion     | Cross-Attention + MLP            | [B, 150, 384]   | [B, 150, 128]   | {components['Cross-Modal Fusion']:,}\n","Adaptive Pooling       | Multi-strategy + Attention       | [B, 150, 128]   | [B, 128]        | {components['Pooling Mechanism']:,}\n","Classification Head    | Multi-layer MLP + Dropout        | [B, 128]        | [B, {model.num_classes}]         | {components['Classification Head']:,}\n","Uncertainty Head       | MLP + Sigmoid                     | [B, 128]        | [B, 1]          | {components['Uncertainty Head']:,}\n","-----------------------|-----------------------------------|------------------|------------------|-------------\n","TOTAL                  |                                   |                  |                  | {total_params_check:,}\n","\n","B: Batch size, Sequence length: 150, Input features: {model.input_dim}, Classes: {model.num_classes}\n","Total trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\n","Model size: {sum(p.numel() for p in model.parameters()) * 4 / (1024**2):.2f} MB\n","\"\"\"\n","\n","    logger.info(academic_table)\n","\n","    logger.info(f\"\\n✅ ARCHITECTURE DOCUMENTATION COMPLETE!\")\n","    logger.info(f\"🎯 Model has {total_params:,} parameters across {len(df_arch)} main components\")\n","    logger.info(f\"📊 Documentation files saved for academic publication\")\n","\n","    return df_arch, df_layers, complexity_data, latex_table\n","\n","if __name__ == \"__main__\":\n","    results = main()"],"metadata":{"id":"wCoTyLa4DjD9"},"execution_count":null,"outputs":[]}]}